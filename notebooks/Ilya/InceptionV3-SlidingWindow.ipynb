{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "e36a66744720b577857e6078befe67a0ffcae5a9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "44ebd91b9e21fd06ec4d5d91a947f339cfe498ea",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "823f34828bc5a0d9e2ddd5547ffbad66947c2146",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "d0ec3fb579bd3919cd5192dce2f52dbb2804faeb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "08f3ce570e13c5f88b86872500baa12424078637",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight, shuffle\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "4972b93fcc952139ba8f65916bcdee0d0ce4ce52",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "WINDOW_SIZE = 299\n",
    "IMAGE_SIZE  = 512\n",
    "IMAGE_CHANNELS=3\n",
    "NUM_CLASSES=28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "09b66099ed0509940f12a31e81bebb9a38ca10a3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load dataset info\n",
    "path_to_train = '../input/train/'\n",
    "data = pd.read_csv('../input/train.csv')\n",
    "\n",
    "train_dataset_info = []\n",
    "for name, labels in zip(data['Id'], data['Target'].str.split(' ')):\n",
    "    train_dataset_info.append({\n",
    "        'path':os.path.join(path_to_train, name),\n",
    "        'labels':np.array([int(label) for label in labels])})\n",
    "train_dataset_info = np.array(train_dataset_info)\n",
    "\n",
    "class data_generator:\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "    def __call__(self):\n",
    "        return self.it\n",
    "\n",
    "    def get_dataset(dataset_info, batch_size, shape, augument=True):\n",
    "        gen = data_generator.create_train(dataset_info, batch_size, shape, augument)\n",
    "        gen = data_generator(gen)\n",
    "        types = (tf.float32, tf.float32)\n",
    "        shapes=(tf.TensorShape((WINDOW_SIZE, WINDOW_SIZE, IMAGE_CHANNELS)), tf.TensorShape([NUM_CLASSES]))\n",
    "        dataset = tf.data.Dataset.from_generator(\n",
    "            gen, types, shapes\n",
    "        )\n",
    "        #dataset = dataset.repeat()\n",
    "        dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(batch_size*8)\n",
    "        return dataset\n",
    "\n",
    "    def create_train(dataset_info, batch_size, shape, augument=True):\n",
    "        assert shape[2] == 3\n",
    "        dataset_info = shuffle(dataset_info)\n",
    "        while True:\n",
    "            for xs, xe, ys, ye in data_generator.slice_images():\n",
    "                for idx in range(len(dataset_info)):\n",
    "                    #X_train_batch = dataset_info[start:end]\n",
    "                    batch_labels = np.zeros((NUM_CLASSES))\n",
    "                    image = data_generator.load_image(\n",
    "                            dataset_info[idx]['path'], shape)   \n",
    "                    if augument:\n",
    "                        image = data_generator.augment(image)\n",
    "                    #print(image)\n",
    "                    image=image/255.\n",
    "                    #print(image)\n",
    "                    batch_labels[dataset_info[idx]['labels']] = 1\n",
    "                    yield image[xs:xe, ys:ye, :], batch_labels\n",
    "\n",
    "    def load_image(path, shape):\n",
    "        image_red_ch = Image.open(path+'_red.png')\n",
    "        image_yellow_ch = Image.open(path+'_yellow.png')\n",
    "        image_green_ch = Image.open(path+'_green.png')\n",
    "        image_blue_ch = Image.open(path+'_blue.png')\n",
    "        image = np.stack((\n",
    "        np.array(image_red_ch), \n",
    "        np.array(image_green_ch), \n",
    "        np.array(image_blue_ch)), -1)\n",
    "        #image = cv2.resize(image, (shape[0], shape[1]))\n",
    "        return image\n",
    "\n",
    "    def augment(image):\n",
    "        augment_img = iaa.Sequential([\n",
    "            iaa.OneOf([\n",
    "                iaa.Affine(rotate=0),\n",
    "                iaa.Affine(rotate=90),\n",
    "                iaa.Affine(rotate=180),\n",
    "                iaa.Affine(rotate=270),\n",
    "                iaa.Fliplr(0.5),\n",
    "                iaa.Flipud(0.5),\n",
    "            ])], random_order=True)\n",
    "\n",
    "        image_aug = augment_img.augment_image(image)\n",
    "        return image_aug\n",
    "\n",
    "    def slice_images():\n",
    "        offset = int(IMAGE_SIZE%WINDOW_SIZE)\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                x_start=i*offset\n",
    "                x_end=x_start+WINDOW_SIZE\n",
    "\n",
    "                y_start=j*offset\n",
    "                y_end=y_start+WINDOW_SIZE\n",
    "                \n",
    "                #print(\"x:{xs},{xe},{xd} y:{ys},{ye},{yd}\".format(\n",
    "                #    xs=x_start, xe=x_end, xd=x_end-x_start,\n",
    "                #    ys=y_start, ye=y_end, yd=y_end-y_start\n",
    "                #))\n",
    "\n",
    "                #      batch,  x,                y,            channels\n",
    "                #imgslice = image[x_start:x_end, y_start:y_end, :]\n",
    "                #yield imagslice\n",
    "                yield x_start, x_end, y_start, y_end\n",
    "def iter_image_slices(image):\n",
    "    for x_start, x_end, y_start, y_end in data_generator.slice_images():\n",
    "        yield image[x_start:x_end, y_start:y_end, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "d6617c42f8a7a929d69f29500c7a77b60ebdc93c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Activation, Dropout, Flatten, Reshape, Dense, Concatenate, GlobalMaxPooling2D\n",
    "from keras.layers import BatchNormalization, Input, Conv2D, Lambda, Average\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model\n",
    "\n",
    "    \n",
    "def create_model(n_out):\n",
    "    input_shape=(WINDOW_SIZE,WINDOW_SIZE, IMAGE_CHANNELS)\n",
    "    input_tensor = Input(shape=(WINDOW_SIZE, WINDOW_SIZE, IMAGE_CHANNELS))\n",
    "    base_model = InceptionV3(include_top=False,\n",
    "                             weights='imagenet',\n",
    "                             input_shape=input_shape\n",
    "                             #input_shape=(WINDOW_SIZE, WINDOW_SIZE, IMAGE_CHANNELS)\n",
    "                            )\n",
    "    bn = BatchNormalization()(input_tensor)\n",
    "    x = base_model(bn)\n",
    "    x = Conv2D(32, kernel_size=(1,1), activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(n_out, activation='sigmoid')(x)\n",
    "    model = Model(input_tensor, output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# warm up model\n",
    "model = create_model(n_out=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "b2efc44adcd80fd3dbe7a274e7d169a694ab0af4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create callbacks list\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "epochs = 10; batch_size = 16\n",
    "checkpoint = ModelCheckpoint('../working/InceptionV3.h5', monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, \n",
    "                                   verbose=1, mode='auto', epsilon=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=6)\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]\n",
    "\n",
    "# split data into train, valid\n",
    "indexes = np.arange(train_dataset_info.shape[0])\n",
    "np.random.shuffle(indexes)\n",
    "train_indexes, valid_indexes = train_test_split(indexes, test_size=0.15, random_state=8)\n",
    "\n",
    "# create train and valid datagens\n",
    "train_generator = data_generator.get_dataset(\n",
    "    train_dataset_info[train_indexes], batch_size, (IMAGE_SIZE,IMAGE_SIZE,IMAGE_CHANNELS), augument=True)\n",
    "validation_generator = data_generator.get_dataset(\n",
    "    train_dataset_info[valid_indexes], 32, (IMAGE_SIZE,IMAGE_SIZE,IMAGE_CHANNELS), augument=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "5f661d60ee8fcdc8c8a21f757c4837a8e118bd8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 299, 299, 3)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 299, 299, 3)       12        \n",
      "_________________________________________________________________\n",
      "inception_v3 (Model)         (None, 8, 8, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 8, 8, 32)          65568     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 28)                28700     \n",
      "=================================================================\n",
      "Total params: 23,995,240\n",
      "Trainable params: 23,960,802\n",
      "Non-trainable params: 34,438\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "6a1f35c66b6d4627fdb9ea3fd53c0aa28fbb7777"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"629pt\" viewBox=\"0.00 0.00 274.00 629.00\" width=\"274pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 625)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-625 270,-625 270,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140389559576560 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140389559576560</title>\n",
       "<polygon fill=\"none\" points=\"70.5,-584.5 70.5,-620.5 195.5,-620.5 195.5,-584.5 70.5,-584.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133\" y=\"-598.8\">input_1: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140379970546768 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140379970546768</title>\n",
       "<polygon fill=\"none\" points=\"0,-511.5 0,-547.5 266,-547.5 266,-511.5 0,-511.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133\" y=\"-525.8\">batch_normalization_95: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 140389559576560&#45;&gt;140379970546768 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140389559576560-&gt;140379970546768</title>\n",
       "<path d=\"M133,-584.4551C133,-576.3828 133,-566.6764 133,-557.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"136.5001,-557.5903 133,-547.5904 129.5001,-557.5904 136.5001,-557.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140379970410200 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140379970410200</title>\n",
       "<polygon fill=\"none\" points=\"67.5,-438.5 67.5,-474.5 198.5,-474.5 198.5,-438.5 67.5,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133\" y=\"-452.8\">inception_v3: Model</text>\n",
       "</g>\n",
       "<!-- 140379970546768&#45;&gt;140379970410200 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140379970546768-&gt;140379970410200</title>\n",
       "<path d=\"M133,-511.4551C133,-503.3828 133,-493.6764 133,-484.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"136.5001,-484.5903 133,-474.5904 129.5001,-484.5904 136.5001,-484.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140379969891800 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>140379969891800</title>\n",
       "<polygon fill=\"none\" points=\"68,-365.5 68,-401.5 198,-401.5 198,-365.5 68,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133\" y=\"-379.8\">conv2d_95: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140379970410200&#45;&gt;140379969891800 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>140379970410200-&gt;140379969891800</title>\n",
       "<path d=\"M133,-438.4551C133,-430.3828 133,-420.6764 133,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"136.5001,-411.5903 133,-401.5904 129.5001,-411.5904 136.5001,-411.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140379533994640 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>140379533994640</title>\n",
       "<polygon fill=\"none\" points=\"78,-292.5 78,-328.5 188,-328.5 188,-292.5 78,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133\" y=\"-306.8\">flatten_1: Flatten</text>\n",
       "</g>\n",
       "<!-- 140379969891800&#45;&gt;140379533994640 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>140379969891800-&gt;140379533994640</title>\n",
       "<path d=\"M133,-365.4551C133,-357.3828 133,-347.6764 133,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"136.5001,-338.5903 133,-328.5904 129.5001,-338.5904 136.5001,-338.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140379582710784 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>140379582710784</title>\n",
       "<polygon fill=\"none\" points=\"70.5,-219.5 70.5,-255.5 195.5,-255.5 195.5,-219.5 70.5,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133\" y=\"-233.8\">dropout_1: Dropout</text>\n",
       "</g>\n",
       "<!-- 140379533994640&#45;&gt;140379582710784 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>140379533994640-&gt;140379582710784</title>\n",
       "<path d=\"M133,-292.4551C133,-284.3828 133,-274.6764 133,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"136.5001,-265.5903 133,-255.5904 129.5001,-265.5904 136.5001,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140379582711960 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>140379582711960</title>\n",
       "<polygon fill=\"none\" points=\"82,-146.5 82,-182.5 184,-182.5 184,-146.5 82,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133\" y=\"-160.8\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 140379582710784&#45;&gt;140379582711960 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>140379582710784-&gt;140379582711960</title>\n",
       "<path d=\"M133,-219.4551C133,-211.3828 133,-201.6764 133,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"136.5001,-192.5903 133,-182.5904 129.5001,-192.5904 136.5001,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140379529864416 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>140379529864416</title>\n",
       "<polygon fill=\"none\" points=\"70.5,-73.5 70.5,-109.5 195.5,-109.5 195.5,-73.5 70.5,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133\" y=\"-87.8\">dropout_2: Dropout</text>\n",
       "</g>\n",
       "<!-- 140379582711960&#45;&gt;140379529864416 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>140379582711960-&gt;140379529864416</title>\n",
       "<path d=\"M133,-146.4551C133,-138.3828 133,-128.6764 133,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"136.5001,-119.5903 133,-109.5904 129.5001,-119.5904 136.5001,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140379529465584 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>140379529465584</title>\n",
       "<polygon fill=\"none\" points=\"82,-.5 82,-36.5 184,-36.5 184,-.5 82,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133\" y=\"-14.8\">dense_2: Dense</text>\n",
       "</g>\n",
       "<!-- 140379529864416&#45;&gt;140379529465584 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>140379529864416-&gt;140379529465584</title>\n",
       "<path d=\"M133,-73.4551C133,-65.3828 133,-55.6764 133,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"136.5001,-46.5903 133,-36.5904 129.5001,-46.5904 136.5001,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "print(keras.__version__)\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "01750c613029089779d88fceaa15880fd8d6257a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"IteratorGetNext:0\", shape=(16, 299, 299, 3), dtype=float32) Tensor(\"IteratorGetNext:1\", shape=(16, 28), dtype=float32)\n",
      "Train on 16 samples, validate on 32 samples\n",
      "Epoch 1/2\n",
      "6604/6604 [==============================] - 1594s 241ms/step - loss: 0.1735 - acc: 0.9418 - val_loss: 0.1811 - val_acc: 0.9408\n",
      "Epoch 2/2\n",
      "6604/6604 [==============================] - 1680s 254ms/step - loss: 0.1722 - acc: 0.9419 - val_loss: 0.1750 - val_acc: 0.9412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faca66926a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "model.layers[-1].trainable = True\n",
    "model.layers[-2].trainable = True\n",
    "model.layers[-3].trainable = True\n",
    "model.layers[-4].trainable = True\n",
    "model.layers[-5].trainable = True\n",
    "model.layers[-6].trainable = True\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer=Adam(1e-03),\n",
    "    metrics=['acc'])\n",
    "# model.summary()\n",
    "train_images, train_labels = train_generator.make_one_shot_iterator().get_next()\n",
    "val_images, val_labels = validation_generator.make_one_shot_iterator().get_next()\n",
    "print(train_images, train_labels)\n",
    "model.fit(\n",
    "    x=train_images, y=train_labels,\n",
    "    steps_per_epoch=int(np.ceil(float(len(train_indexes)) / float(batch_size))*4),\n",
    "    validation_data=(val_images, val_labels),\n",
    "    validation_steps=int(np.ceil(float(len(valid_indexes)) / float(batch_size))*4),\n",
    "    epochs=2, \n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "fb6ef7ff778b0b57c658bc3dfbcf7b930c66b3a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples, validate on 32 samples\n",
      "Epoch 1/3\n",
      "6604/6604 [==============================] - 4724s 715ms/step - loss: 0.1481 - acc: 0.9507 - val_loss: 0.1273 - val_acc: 0.9571\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12726, saving model to ../working/InceptionV3.h5\n",
      "Epoch 2/3\n",
      "6604/6604 [==============================] - 4568s 692ms/step - loss: 0.1222 - acc: 0.9587 - val_loss: 0.1176 - val_acc: 0.9600\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.12726 to 0.11756, saving model to ../working/InceptionV3.h5\n",
      "Epoch 3/3\n",
      "6604/6604 [==============================] - 4374s 662ms/step - loss: 0.1102 - acc: 0.9625 - val_loss: 0.1059 - val_acc: 0.9638\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.11756 to 0.10587, saving model to ../working/InceptionV3.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faca672f4e0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train all layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "model.compile(loss='binary_crossentropy',\n",
    "            optimizer=Adam(lr=1e-4),\n",
    "            metrics=['accuracy'])\n",
    "model.fit(\n",
    "    x=train_images, y=train_labels,\n",
    "    steps_per_epoch=int(np.ceil(float(len(train_indexes)) / float(batch_size))*4),\n",
    "    validation_data=(val_images, val_labels),\n",
    "    validation_steps=int(np.ceil(float(len(valid_indexes)) / float(batch_size))*4),\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "c48f403b6410b1d7ac9df973081b8f3fe292fb73"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11702/11702 [19:48<00:00,  9.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create submit\n",
    "submit = pd.read_csv('../input/sample_submission.csv')\n",
    "predicted = []\n",
    "draw_predict = []\n",
    "model.load_weights('../working/InceptionV3.h5')\n",
    "for name in tqdm(submit['Id']):\n",
    "    path = os.path.join('../input/test/', name)\n",
    "    image = data_generator.load_image(path, (IMAGE_SIZE,IMAGE_SIZE,3))/255.\n",
    "    classes=set()\n",
    "    for s in iter_image_slices(image):\n",
    "        score_predict = model.predict(s[np.newaxis])[0]\n",
    "        draw_predict.append(score_predict)\n",
    "        label_predict = np.arange(NUM_CLASSES)[score_predict>=0.2]\n",
    "        classes.update(label_predict)\n",
    "    str_predict_label = ' '.join(str(l) for l in classes)\n",
    "    predicted.append(str_predict_label)\n",
    "\n",
    "submit['Predicted'] = predicted\n",
    "np.save('../output/draw_predict_InceptionV3.npy', score_predict)\n",
    "submit.to_csv('../output/submit_InceptionV3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "50bf6808331f8078cf2472329b738b12c193118a",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f9d8983fcf8ba12caded514e255b5250859641ad",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
