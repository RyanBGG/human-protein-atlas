{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "import keras\n",
    "import warnings\n",
    "from keras.utils import Sequence\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SIZE = 299\n",
    "SEED = 777\n",
    "THRESHOLD = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset info\n",
    "DIR = '../input/'\n",
    "data = pd.read_csv('../input/train.csv')\n",
    "\n",
    "# train_dataset_info = []\n",
    "# for name, labels in zip(data['Id'], data['Target'].str.split(' ')):\n",
    "#     train_dataset_info.append({\n",
    "#         'path':os.path.join(path_to_train, name),\n",
    "#         'labels':np.array([int(label) for label in labels])})\n",
    "# train_dataset_info = np.array(train_dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainDataset():\n",
    "    \n",
    "    path_to_train = DIR + '/train/'\n",
    "    data = pd.read_csv(DIR + '/train.csv')\n",
    "\n",
    "    paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for name, lbl in zip(data['Id'], data['Target'].str.split(' ')):\n",
    "        y = np.zeros(28)\n",
    "        for key in lbl:\n",
    "            y[int(key)] = 1\n",
    "        paths.append(os.path.join(path_to_train, name))\n",
    "        labels.append(y)\n",
    "\n",
    "    return np.array(paths), np.array(labels)\n",
    "\n",
    "def getTestDataset():\n",
    "    \n",
    "    path_to_test = DIR + '/test/'\n",
    "    data = pd.read_csv(DIR + '/sample_submission.csv')\n",
    "\n",
    "    paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for name in data['Id']:\n",
    "        y = np.ones(28)\n",
    "        paths.append(os.path.join(path_to_test, name))\n",
    "        labels.append(y)\n",
    "\n",
    "    return np.array(paths), np.array(labels)\n",
    "paths, labels = getTrainDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credits: https://github.com/keras-team/keras/blob/master/keras/utils/data_utils.py#L302\n",
    "# credits: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "from random import randint\n",
    "class ProteinDataGenerator(keras.utils.Sequence):\n",
    "            \n",
    "    def __init__(self, paths, labels, batch_size, shape, channels = [], shuffle = False, use_cache = False, augmentor = False):\n",
    "        self.paths, self.labels = paths, labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shape = shape\n",
    "        self.shuffle = shuffle\n",
    "        self.use_cache = use_cache\n",
    "        self.channels = channels\n",
    "        self.augmentor = augmentor\n",
    "        self.clahe = cv2.createCLAHE()\n",
    "        if use_cache == True:\n",
    "            self.cache = np.zeros((paths.shape[0], shape[0], shape[1], len(channels)))\n",
    "            self.is_cached = np.zeros((paths.shape[0]))\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.paths) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        indexes = self.indexes[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "\n",
    "        paths = self.paths[indexes]\n",
    "        X = np.zeros((paths.shape[0], self.shape[0], self.shape[1], self.shape[2]))\n",
    "        # Generate data\n",
    "        if self.use_cache == True:\n",
    "            X = self.cache[indexes]\n",
    "            for i, path in enumerate(paths[np.where(self.is_cached[indexes] == 0)]):\n",
    "                image = self.__load_image(path)\n",
    "                self.is_cached[indexes[i]] = 1\n",
    "                self.cache[indexes[i]] = image\n",
    "                X[i] = image\n",
    "        else:\n",
    "            for i, path in enumerate(paths):\n",
    "                X[i] = self.__load_image(path)\n",
    "\n",
    "        y = self.labels[indexes]\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        # Updates indexes after each epoch\n",
    "        self.indexes = np.arange(len(self.paths))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Create a generator that iterate over the Sequence.\"\"\"\n",
    "        for item in (self[i] for i in range(len(self))):\n",
    "            if self.augmentor == True:\n",
    "                item = self.augment(item)\n",
    "            yield item\n",
    "            \n",
    "    def __load_image(self, path):\n",
    "        images = []\n",
    "        for channel in self.channels:\n",
    "            im = np.array(Image.open(path + '_' + channel + '.png'))\n",
    "            \n",
    "#             im = clahe.apply(im)\n",
    "            images.append(im)\n",
    "            \n",
    "        if len(self.channels) >= 2:\n",
    "            im = np.stack((\n",
    "                images\n",
    "            ), -1)\n",
    "            im = cv2.resize(im, (SIZE,SIZE))\n",
    "            im = np.divide(im, 255)\n",
    "\n",
    "        else:\n",
    "            im = images[0]\n",
    "            im = cv2.resize(im, (SIZE,SIZE))\n",
    "            im = np.divide(im, 255)\n",
    "            im = np.expand_dims(im, 2)\n",
    "        return im\n",
    "    def augment(self, image):\n",
    "        if randint(0,1) == 1:\n",
    "            augment_img = iaa.Sequential([\n",
    "                iaa.OneOf([\n",
    "                    iaa.Fliplr(0.5), # horizontal flips\n",
    "                    iaa.Flipud(0.5), # horizontal flips\n",
    "                    iaa.Crop(percent=(0, 0.1)), # random crops\n",
    "                    # Small gaussian blur with random sigma between 0 and 0.5.\n",
    "                    # But we only blur about 50% of all images.\n",
    "                    iaa.Sometimes(0.5,\n",
    "                        iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "                    ),\n",
    "                    # Make some images brighter and some darker.\n",
    "                    # In 20% of all cases, we sample the multiplier once per channel,\n",
    "                    # which can end up changing the color of the images.\n",
    "                    iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
    "                    # Apply affine transformations to each image.\n",
    "                    # Scale/zoom them, translate/move them, rotate them and shear them.\n",
    "                    iaa.Affine(\n",
    "                        scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\n",
    "                        translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n",
    "                        rotate=(-180, 180),\n",
    "                        shear=(-4, 4)\n",
    "                    )\n",
    "                ])], random_order=True)\n",
    "\n",
    "\n",
    "            image_aug = augment_img.augment_image(image)\n",
    "            return image_aug\n",
    "        else:\n",
    "            return image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE = (299, 299, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels = [\"red\", \"green\", \"blue\"]\n",
    "# for path in paths[0:10]:\n",
    "#     images = []\n",
    "#     for channel in channels:\n",
    "#         im = np.array(Image.open(path + '_' + channel + '.png'))\n",
    "# #         im = cv2.equalizeHist(im)\n",
    "#         clahe = cv2.createCLAHE()\n",
    "#         im = clahe.apply(im)\n",
    "# #         plt.imshow(im)\n",
    "#         images.append(im)\n",
    "\n",
    "#     if len(channels) >= 2:\n",
    "#         im = np.stack((\n",
    "#             images\n",
    "#         ), -1)\n",
    "#         im = cv2.resize(im, (SIZE,SIZE))\n",
    "#         im = np.divide(im, 255)\n",
    "        \n",
    "        \n",
    "#     else:\n",
    "#         im = images[0]\n",
    "#         im = cv2.resize(im, (SIZE,SIZE))\n",
    "#         im = np.divide(im, 255)\n",
    "#         im = np.expand_dims(im, 2)\n",
    "#     plt.imshow(augment(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class data_generator:\n",
    "    \n",
    "#     def create_train(dataset_info, batch_size, shape, augument=True):\n",
    "#         assert shape[2] == 3\n",
    "#         while True:\n",
    "#             dataset_info = shuffle(dataset_info)\n",
    "#             for start in range(0, len(dataset_info), batch_size):\n",
    "#                 end = min(start + batch_size, len(dataset_info))\n",
    "#                 batch_images = []\n",
    "#                 X_train_batch = dataset_info[start:end]\n",
    "#                 batch_labels = np.zeros((len(X_train_batch), 28))\n",
    "#                 for i in range(len(X_train_batch)):\n",
    "#                     image = data_generator.load_image(\n",
    "#                         X_train_batch[i]['path'], shape)   \n",
    "#                     if augument:\n",
    "#                         image = data_generator.augment(image)\n",
    "#                     batch_images.append(image/255.)\n",
    "#                     batch_labels[i][X_train_batch[i]['labels']] = 1\n",
    "#                 yield np.array(batch_images, np.float32), batch_labels\n",
    "\n",
    "#     def load_image(path, shape):\n",
    "#         image_red_ch = Image.open(path+'_red.png')\n",
    "#         image_yellow_ch = Image.open(path+'_yellow.png')\n",
    "#         image_green_ch = Image.open(path+'_green.png')\n",
    "#         image_blue_ch = Image.open(path+'_blue.png')\n",
    "#         image = np.stack((\n",
    "#         np.array(image_red_ch), \n",
    "#         np.array(image_green_ch), \n",
    "#         np.array(image_blue_ch)), -1)\n",
    "#         image = cv2.resize(image, (shape[0], shape[1]))\n",
    "#         return image\n",
    "\n",
    "#     def augment(image):\n",
    "#         augment_img = iaa.Sequential([\n",
    "#             iaa.OneOf([\n",
    "#                 iaa.Affine(rotate=0),\n",
    "#                 iaa.Affine(rotate=90),\n",
    "#                 iaa.Affine(rotate=180),\n",
    "#                 iaa.Affine(rotate=270),\n",
    "#                 iaa.Fliplr(0.5),\n",
    "#                 iaa.Flipud(0.5),\n",
    "#             ])], random_order=True)\n",
    "\n",
    "#         image_aug = augment_img.augment_image(image)\n",
    "#         return image_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D, BatchNormalization, Input, Conv2D, MaxPooling2D\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam \n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_out, channels):\n",
    "    input_tensor = Input(shape=(299,299,len(channels)))\n",
    "\n",
    "    base_model = InceptionV3(include_top=False,\n",
    "                   weights='imagenet',\n",
    "                   input_shape=(299,299,3)\n",
    "                            )\n",
    "    bn = BatchNormalization()(input_tensor)\n",
    "    x = Conv2D(3, kernel_size=(1,1), activation='relu', padding = \"same\")(bn)\n",
    "    x = base_model(x)\n",
    "    bn = BatchNormalization()(x)\n",
    "    x = Conv2D(128, kernel_size=(1,1), activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "#     output = Dense(n_out, activation='sigmoid')(x)\n",
    "    output = Dense(n_out, activation='sigmoid')(x)\n",
    "    model = Model(input_tensor, output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model(input_shape, n_out, channels):\n",
    "    input_tensor = Input(shape=(299,299,len(channels)))\n",
    "    bn = BatchNormalization()(input_tensor)\n",
    "    x = Conv2D(8, kernel_size=(3,3), activation='relu', padding = \"same\")(bn)\n",
    "    x = Conv2D(8, kernel_size=(3,3), activation='relu', padding = \"same\")(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2))(x)\n",
    "    x = Conv2D(16, kernel_size=(3,3), activation='relu', padding = \"same\")(x)\n",
    "    x = Conv2D(16, kernel_size=(3,3), activation='relu', padding = \"same\")(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2))(x)\n",
    "    x = Conv2D(32, kernel_size=(3,3), activation='relu', padding = \"same\")(x)\n",
    "    x = Conv2D(32, kernel_size=(3,3), activation='relu', padding = \"same\")(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2))(x)\n",
    "    x = Conv2D(64, kernel_size=(3,3), activation='relu', padding = \"same\")(x)\n",
    "    x = Conv2D(64, kernel_size=(3,3), activation='relu', padding = \"same\")(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2))(x)\n",
    "    x = Conv2D(128, kernel_size=(3,3), activation='relu', padding = \"same\")(x)\n",
    "    x = Conv2D(128, kernel_size=(3,3), activation='relu', padding = \"same\")(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2))(x)\n",
    "    x = Conv2D(256, kernel_size=(3,3), activation='relu', padding = \"valid\")(x)\n",
    "    x = Conv2D(256, kernel_size=(3,3), activation='relu', padding = \"valid\")(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "#     output = Dense(n_out, activation='sigmoid')(x)\n",
    "    output = Dense(n_out, activation=\"sigmoid\")(x)\n",
    "    model = Model(input_tensor, output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    #y_pred = K.round(y_pred)\n",
    "    y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    #y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1-K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31072,) (31072, 28)\n",
      "(27964,) (27964, 28) (3108,) (3108, 28)\n"
     ]
    }
   ],
   "source": [
    "# create callbacks list\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "epochs = 10; batch_size = 32;VAL_RATIO = .1;DEBUG = False\n",
    "# split data into train, valid\n",
    "paths, labels = getTrainDataset()\n",
    "\n",
    "# divide to \n",
    "keys = np.arange(paths.shape[0], dtype=np.int)  \n",
    "np.random.seed(SEED)\n",
    "np.random.shuffle(keys)\n",
    "lastTrainIndex = int((1-VAL_RATIO) * paths.shape[0])\n",
    "\n",
    "if DEBUG == True:  # use only small subset for debugging, Kaggle's RAM is limited\n",
    "    pathsTrain = paths[0:256]\n",
    "    labelsTrain = labels[0:256]\n",
    "    pathsVal = paths[lastTrainIndex:lastTrainIndex+256]\n",
    "    labelsVal = labels[lastTrainIndex:lastTrainIndex+256]\n",
    "    use_cache = True\n",
    "else:\n",
    "    pathsTrain = paths[0:lastTrainIndex]\n",
    "    labelsTrain = labels[0:lastTrainIndex]\n",
    "    pathsVal = paths[lastTrainIndex:]\n",
    "    labelsVal = labels[lastTrainIndex:]\n",
    "    use_cache = False\n",
    "\n",
    "print(paths.shape, labels.shape)\n",
    "print(pathsTrain.shape, labelsTrain.shape, pathsVal.shape, labelsVal.shape)\n",
    "use_cache = True\n",
    "channels = [\"green\", \"blue\", \"red\", \"yellow\"]\n",
    "tg = ProteinDataGenerator(pathsTrain, labelsTrain, batch_size, SHAPE, channels, use_cache=use_cache, augmentor = False)\n",
    "vg = ProteinDataGenerator(pathsVal, labelsVal, batch_size, SHAPE, channels, use_cache=use_cache, augmentor = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and valid datagens\n",
    "# train_generator = data_generator.create_train(\n",
    "#     train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=True)\n",
    "# validation_generator = data_generator.create_train(\n",
    "#     train_dataset_info[valid_indexes], 32, (SIZE,SIZE,3), augument=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('../working/InceptionV3.h5', monitor='val_f1', verbose=1, \n",
    "                             save_best_only=True, mode='max', save_weights_only = False)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_f1', factor=0.5, patience=10, \n",
    "                                   verbose=1, mode='max', epsilon=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_f1\", \n",
    "                      mode=\"max\", \n",
    "                      patience=20)\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "\n",
    "        pt_1 = K.clip(pt_1, 1e-3, .999)\n",
    "        pt_0 = K.clip(pt_0, 1e-3, .999)\n",
    "\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed\n",
    "def KerasFocalLoss(target, input):\n",
    "    \n",
    "    gamma = 2.\n",
    "    input = tf.cast(input, tf.float32)\n",
    "    \n",
    "    max_val = K.clip(-input, 0, 1)\n",
    "    loss = input - input * target + max_val + K.log(K.exp(-max_val) + K.exp(-input - max_val))\n",
    "    invprobs = tf.log_sigmoid(-input * (target * 2.0 - 1.0))\n",
    "    loss = K.exp(invprobs * gamma) * loss\n",
    "    \n",
    "    return K.mean(K.sum(loss, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 299, 299, 4)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 299, 299, 4)       16        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 299, 299, 8)       296       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 299, 299, 8)       584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 149, 149, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 149, 149, 16)      1168      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 149, 149, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 74, 74, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 74, 74, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 74, 74, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 37, 37, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 18, 18, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 18, 18, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 5, 5, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 28)                7196      \n",
      "=================================================================\n",
      "Total params: 1,449,980\n",
      "Trainable params: 1,449,972\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# warm up model\n",
    "import tensorflow as tf\n",
    "# with tf.device('/cpu:0'):\n",
    "model = simple_model(\n",
    "    input_shape=(SIZE,SIZE,len(channels)), \n",
    "    n_out=28, channels = channels)\n",
    "\n",
    "# for layer in model.layers:\n",
    "#     layer.trainable = False\n",
    "# model.layers[1].trainable = True\n",
    "# model.layers[2].trainable = True\n",
    "# model.layers[-1].trainable = True\n",
    "# model.layers[-2].trainable = True\n",
    "# model.layers[-3].trainable = True\n",
    "# model.layers[-4].trainable = True\n",
    "# model.layers[-5].trainable = True\n",
    "# model.layers[-6].trainable = True\n",
    "\n",
    "model.summary()\n",
    "# model = multi_gpu_model(model, gpus = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 299, 299, 4)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 299, 299, 4)       16        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 299, 299, 8)       296       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 299, 299, 8)       584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 149, 149, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 149, 149, 16)      1168      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 149, 149, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 74, 74, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 74, 74, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 74, 74, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 37, 37, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 18, 18, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 18, 18, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 5, 5, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 28)                7196      \n",
      "=================================================================\n",
      "Total params: 1,449,980\n",
      "Trainable params: 1,449,972\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=\"binary_crossentropy\", \n",
    "    optimizer=Adam(1e-03),\n",
    "    metrics=['binary_accuracy', f1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "670/874 [=====================>........] - ETA: 2:47 - loss: 0.1870 - binary_accuracy: 0.9386 - f1: 0.0472"
     ]
    }
   ],
   "source": [
    "hist =  model.fit_generator(\n",
    "        tg,\n",
    "        steps_per_epoch=np.ceil(float(len(pathsTrain)) / float(batch_size)),\n",
    "        validation_data=vg,\n",
    "        validation_steps=np.ceil(float(len(pathsVal)) / float(batch_size)),\n",
    "        epochs=50, \n",
    "        verbose=1,\n",
    "        callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x00000116E045D048>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001201A4D8908>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001201A52AD30>\n",
      "<keras.engine.training.Model object at 0x000001201A4D8C50>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000012022570C18>\n",
      "<keras.layers.core.Flatten object at 0x0000012020C3A588>\n",
      "<keras.layers.core.Dropout object at 0x000001201A67E978>\n",
      "<keras.layers.core.Dense object at 0x000001201A71FB00>\n",
      "<keras.layers.core.Dropout object at 0x00000120205AE6A0>\n",
      "<keras.layers.core.Dense object at 0x00000120205AE4A8>\n"
     ]
    }
   ],
   "source": [
    "# train all layers\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    layer.trainable = True\n",
    "model.compile(loss=focal_loss(),\n",
    "            optimizer=Adam(lr=1e-4),\n",
    "            metrics=['accuracy', f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1166/1165 [==============================] - 606s 520ms/step - loss: 13.8179 - acc: 0.4125 - f1: 0.1311 - val_loss: 13.0988 - val_acc: 0.4613 - val_f1: 0.1407\n",
      "\n",
      "Epoch 00001: val_f1 improved from 0.10443 to 0.14066, saving model to ../working/InceptionV3.h5\n",
      "Epoch 2/200\n",
      "1166/1165 [==============================] - 530s 455ms/step - loss: 12.4071 - acc: 0.4781 - f1: 0.1634 - val_loss: 12.4184 - val_acc: 0.5031 - val_f1: 0.1635\n",
      "\n",
      "Epoch 00002: val_f1 improved from 0.14066 to 0.16350, saving model to ../working/InceptionV3.h5\n",
      "Epoch 3/200\n",
      "1166/1165 [==============================] - 554s 475ms/step - loss: 11.2627 - acc: 0.5278 - f1: 0.1934 - val_loss: 12.4274 - val_acc: 0.4550 - val_f1: 0.1691\n",
      "\n",
      "Epoch 00003: val_f1 improved from 0.16350 to 0.16911, saving model to ../working/InceptionV3.h5\n",
      "Epoch 4/200\n",
      "1166/1165 [==============================] - 593s 508ms/step - loss: 9.4958 - acc: 0.5981 - f1: 0.2390 - val_loss: 13.9004 - val_acc: 0.4100 - val_f1: 0.1862\n",
      "\n",
      "Epoch 00004: val_f1 improved from 0.16911 to 0.18621, saving model to ../working/InceptionV3.h5\n",
      "Epoch 5/200\n",
      "1166/1165 [==============================] - 588s 504ms/step - loss: 8.0883 - acc: 0.6450 - f1: 0.2783 - val_loss: 14.0686 - val_acc: 0.5065 - val_f1: 0.1976\n",
      "\n",
      "Epoch 00005: val_f1 improved from 0.18621 to 0.19758, saving model to ../working/InceptionV3.h5\n",
      "Epoch 6/200\n",
      "1166/1165 [==============================] - 588s 504ms/step - loss: 6.6948 - acc: 0.6852 - f1: 0.3171 - val_loss: 14.5782 - val_acc: 0.4610 - val_f1: 0.2054\n",
      "\n",
      "Epoch 00006: val_f1 improved from 0.19758 to 0.20538, saving model to ../working/InceptionV3.h5\n",
      "Epoch 7/200\n",
      "1166/1165 [==============================] - 576s 494ms/step - loss: 5.0948 - acc: 0.7253 - f1: 0.3681 - val_loss: 17.3627 - val_acc: 0.4627 - val_f1: 0.2089\n",
      "\n",
      "Epoch 00007: val_f1 improved from 0.20538 to 0.20888, saving model to ../working/InceptionV3.h5\n",
      "Epoch 8/200\n",
      " 835/1165 [====================>.........] - ETA: 2:41 - loss: 4.3980 - acc: 0.7327 - f1: 0.3925"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 12\n",
    "hist =  model.fit_generator(\n",
    "        tg,\n",
    "        steps_per_epoch=np.ceil(float(len(pathsTrain)) / float(batch_size))/2,\n",
    "        validation_data=vg,\n",
    "        validation_steps=np.ceil(float(len(pathsVal)) / float(batch_size))/2,\n",
    "        epochs=200, \n",
    "        verbose=1,\n",
    "        callbacks=callbacks_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss=f1_loss,\n",
    "#             optimizer=Adam(lr=1e-4),\n",
    "#             metrics=['accuracy', f1])\n",
    "# hist =  model.fit_generator(\n",
    "#         tg,\n",
    "#         steps_per_epoch=np.ceil(float(len(pathsTrain)) / float(batch_size))/2,\n",
    "#         validation_data=vg,\n",
    "#         validation_steps=np.ceil(float(len(pathsVal)) / float(batch_size))/2,\n",
    "#         epochs=200, \n",
    "#         verbose=1,\n",
    "#         callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax[0].set_title('loss')\n",
    "ax[0].plot(hist.epoch, hist.history[\"loss\"], label=\"Train loss\")\n",
    "ax[0].plot(hist.epoch, hist.history[\"val_loss\"], label=\"Validation loss\")\n",
    "ax[1].set_title('acc')\n",
    "ax[1].plot(hist.epoch, hist.history[\"f1\"], label=\"Train F1\")\n",
    "ax[1].plot(hist.epoch, hist.history[\"val_f1\"], label=\"Validation F1\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "bestModel = load_model('../working/InceptionV3.h5', custom_objects={'f1': f1, 'f1_loss': f1_loss, 'focal_loss_fixed':focal_loss()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "lastFullValPred = np.empty((0, 28))\n",
    "lastFullValLabels = np.empty((0, 28))\n",
    "for i in tqdm(range(len(vg))): \n",
    "    im, lbl = vg[i]\n",
    "    scores = bestModel.predict(im)\n",
    "    lastFullValPred = np.append(lastFullValPred, scores, axis=0)\n",
    "    lastFullValLabels = np.append(lastFullValLabels, lbl, axis=0)\n",
    "print(lastFullValPred.shape, lastFullValLabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score as off1\n",
    "rng = np.arange(0, 1, 0.001)\n",
    "f1s = np.zeros((rng.shape[0], 28))\n",
    "for j,t in enumerate(tqdm(rng)):\n",
    "    for i in range(28):\n",
    "        p = np.array(lastFullValPred[:,i]>t, dtype=np.int8)\n",
    "        scoref1 = off1(lastFullValLabels[:,i], p, average='binary')\n",
    "        f1s[j,i] = scoref1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Individual F1-scores for each class:')\n",
    "print(np.max(f1s, axis=0))\n",
    "print('Macro F1-score CV =', np.mean(np.max(f1s, axis=0)))\n",
    "plt.plot(rng, f1s)\n",
    "T = np.empty(28)\n",
    "for i in range(28):\n",
    "    T[i] = rng[np.where(f1s[:,i] == np.max(f1s[:,i]))[0][0]]\n",
    "print('Probability threshold maximizing CV F1-score for each class:')\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathsTest, labelsTest = getTestDataset()\n",
    "\n",
    "testg = ProteinDataGenerator(pathsTest, labelsTest, batch_size, SHAPE, channels)\n",
    "submit = pd.read_csv(DIR + '/sample_submission.csv')\n",
    "P = np.zeros((pathsTest.shape[0], 28))\n",
    "for i in tqdm(range(len(testg))):\n",
    "    images, labels = testg[i]\n",
    "    score = bestModel.predict(images)\n",
    "    P[i*batch_size:i*batch_size+score.shape[0]] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP = np.array(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "\n",
    "for row in tqdm(range(submit.shape[0])):\n",
    "    \n",
    "    str_label = ''\n",
    "    \n",
    "    for col in range(PP.shape[1]):\n",
    "        if(PP[row, col] < T[col]):\n",
    "            str_label += ''\n",
    "        else:\n",
    "            str_label += str(col) + ' '\n",
    "    prediction.append(str_label.strip())\n",
    "    \n",
    "submit['Predicted'] = np.array(prediction)\n",
    "submit.to_csv('transfer_1x1conv_aug_focal_loss.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# pathsTest, labelsTest = getTestDataset()\n",
    "\n",
    "# testg = ProteinDataGenerator(pathsTest, labelsTest, batch_size, SHAPE)\n",
    "# submit = pd.read_csv(DIR + '/sample_submission.csv')\n",
    "# P = np.zeros((pathsTest.shape[0], 28))\n",
    "# for i in tqdm(range(len(testg))):\n",
    "#     images, labels = testg[i]\n",
    "#     score = bestModel.predict(images)\n",
    "#     P[i*batch_size:i*batch_size+score.shape[0]] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PP = np.array(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = []\n",
    "\n",
    "# for row in tqdm(range(submit.shape[0])):\n",
    "    \n",
    "#     str_label = ''\n",
    "    \n",
    "#     for col in range(PP.shape[1]):\n",
    "#         if(PP[row, col] < .2):   # to account for losing TP is more costly than decreasing FP\n",
    "#             #print(PP[row])\n",
    "#             str_label += ''\n",
    "#         else:\n",
    "#             str_label += str(col) + ' '\n",
    "#     prediction.append(str_label.strip())\n",
    "    \n",
    "# submit['Predicted'] = np.array(prediction)\n",
    "# submit.to_csv('datagenerator_model_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
