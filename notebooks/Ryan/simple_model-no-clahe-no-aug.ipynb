{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "import keras\n",
    "import warnings\n",
    "from keras.utils import Sequence\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SIZE = 299\n",
    "SEED = 777\n",
    "THRESHOLD = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset info\n",
    "DIR = '../input/'\n",
    "data = pd.read_csv('../input/train.csv')\n",
    "\n",
    "# train_dataset_info = []\n",
    "# for name, labels in zip(data['Id'], data['Target'].str.split(' ')):\n",
    "#     train_dataset_info.append({\n",
    "#         'path':os.path.join(path_to_train, name),\n",
    "#         'labels':np.array([int(label) for label in labels])})\n",
    "# train_dataset_info = np.array(train_dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainDataset():\n",
    "    \n",
    "    path_to_train = DIR + '/train/'\n",
    "    data = pd.read_csv(DIR + '/train.csv')\n",
    "\n",
    "    paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for name, lbl in zip(data['Id'], data['Target'].str.split(' ')):\n",
    "        y = np.zeros(28)\n",
    "        for key in lbl:\n",
    "            y[int(key)] = 1\n",
    "        paths.append(os.path.join(path_to_train, name))\n",
    "        labels.append(y)\n",
    "\n",
    "    return np.array(paths), np.array(labels)\n",
    "\n",
    "def getTestDataset():\n",
    "    \n",
    "    path_to_test = DIR + '/test/'\n",
    "    data = pd.read_csv(DIR + '/sample_submission.csv')\n",
    "\n",
    "    paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for name in data['Id']:\n",
    "        y = np.ones(28)\n",
    "        paths.append(os.path.join(path_to_test, name))\n",
    "        labels.append(y)\n",
    "\n",
    "    return np.array(paths), np.array(labels)\n",
    "paths, labels = getTrainDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credits: https://github.com/keras-team/keras/blob/master/keras/utils/data_utils.py#L302\n",
    "# credits: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "from random import randint\n",
    "class ProteinDataGenerator(keras.utils.Sequence):\n",
    "            \n",
    "    def __init__(self, paths, labels, batch_size, shape, channels = [], shuffle = False, use_cache = False, augmentor = False):\n",
    "        self.paths, self.labels = paths, labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shape = shape\n",
    "        self.shuffle = shuffle\n",
    "        self.use_cache = use_cache\n",
    "        self.channels = channels\n",
    "        self.augmentor = augmentor\n",
    "        self.clahe = cv2.createCLAHE()\n",
    "        if use_cache == True:\n",
    "            self.cache = np.zeros((paths.shape[0], shape[0], shape[1], len(channels)))\n",
    "            self.is_cached = np.zeros((paths.shape[0]))\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.paths) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        indexes = self.indexes[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "\n",
    "        paths = self.paths[indexes]\n",
    "        X = np.zeros((paths.shape[0], self.shape[0], self.shape[1], self.shape[2]))\n",
    "        # Generate data\n",
    "        if self.use_cache == True:\n",
    "            X = self.cache[indexes]\n",
    "            for i, path in enumerate(paths[np.where(self.is_cached[indexes] == 0)]):\n",
    "                image = self.__load_image(path)\n",
    "                self.is_cached[indexes[i]] = 1\n",
    "                self.cache[indexes[i]] = image\n",
    "                X[i] = image\n",
    "        else:\n",
    "            for i, path in enumerate(paths):\n",
    "                X[i] = self.__load_image(path)\n",
    "\n",
    "        y = self.labels[indexes]\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        # Updates indexes after each epoch\n",
    "        self.indexes = np.arange(len(self.paths))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Create a generator that iterate over the Sequence.\"\"\"\n",
    "        for item in (self[i] for i in range(len(self))):\n",
    "            if self.augmentor == True:\n",
    "                item = self.augment(item)\n",
    "            yield item\n",
    "            \n",
    "    def __load_image(self, path):\n",
    "        images = []\n",
    "        for channel in self.channels:\n",
    "            im = np.array(Image.open(path + '_' + channel + '.png'))\n",
    "            \n",
    "#             im = clahe.apply(im)\n",
    "            images.append(im)\n",
    "            \n",
    "        if len(self.channels) >= 2:\n",
    "            im = np.stack((\n",
    "                images\n",
    "            ), -1)\n",
    "            im = cv2.resize(im, (SIZE,SIZE))\n",
    "            im = np.divide(im, 255)\n",
    "\n",
    "        else:\n",
    "            im = images[0]\n",
    "            im = cv2.resize(im, (SIZE,SIZE))\n",
    "            im = np.divide(im, 255)\n",
    "            im = np.expand_dims(im, 2)\n",
    "        return im\n",
    "    def augment(self, image):\n",
    "        if randint(0,1) == 1:\n",
    "            augment_img = iaa.Sequential([\n",
    "                iaa.OneOf([\n",
    "                    iaa.Fliplr(0.5), # horizontal flips\n",
    "                    iaa.Flipud(0.5), # horizontal flips\n",
    "                    iaa.Crop(percent=(0, 0.1)), # random crops\n",
    "                    # Small gaussian blur with random sigma between 0 and 0.5.\n",
    "                    # But we only blur about 50% of all images.\n",
    "                    iaa.Sometimes(0.5,\n",
    "                        iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "                    ),\n",
    "                    # Make some images brighter and some darker.\n",
    "                    # In 20% of all cases, we sample the multiplier once per channel,\n",
    "                    # which can end up changing the color of the images.\n",
    "                    iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
    "                    # Apply affine transformations to each image.\n",
    "                    # Scale/zoom them, translate/move them, rotate them and shear them.\n",
    "                    iaa.Affine(\n",
    "                        scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\n",
    "                        translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n",
    "                        rotate=(-180, 180),\n",
    "                        shear=(-4, 4)\n",
    "                    )\n",
    "                ])], random_order=True)\n",
    "\n",
    "\n",
    "            image_aug = augment_img.augment_image(image)\n",
    "            return image_aug\n",
    "        else:\n",
    "            return image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE = (299, 299, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels = [\"red\", \"green\", \"blue\"]\n",
    "# for path in paths[0:10]:\n",
    "#     images = []\n",
    "#     for channel in channels:\n",
    "#         im = np.array(Image.open(path + '_' + channel + '.png'))\n",
    "# #         im = cv2.equalizeHist(im)\n",
    "#         clahe = cv2.createCLAHE()\n",
    "#         im = clahe.apply(im)\n",
    "# #         plt.imshow(im)\n",
    "#         images.append(im)\n",
    "\n",
    "#     if len(channels) >= 2:\n",
    "#         im = np.stack((\n",
    "#             images\n",
    "#         ), -1)\n",
    "#         im = cv2.resize(im, (SIZE,SIZE))\n",
    "#         im = np.divide(im, 255)\n",
    "        \n",
    "        \n",
    "#     else:\n",
    "#         im = images[0]\n",
    "#         im = cv2.resize(im, (SIZE,SIZE))\n",
    "#         im = np.divide(im, 255)\n",
    "#         im = np.expand_dims(im, 2)\n",
    "#     plt.imshow(augment(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class data_generator:\n",
    "    \n",
    "#     def create_train(dataset_info, batch_size, shape, augument=True):\n",
    "#         assert shape[2] == 3\n",
    "#         while True:\n",
    "#             dataset_info = shuffle(dataset_info)\n",
    "#             for start in range(0, len(dataset_info), batch_size):\n",
    "#                 end = min(start + batch_size, len(dataset_info))\n",
    "#                 batch_images = []\n",
    "#                 X_train_batch = dataset_info[start:end]\n",
    "#                 batch_labels = np.zeros((len(X_train_batch), 28))\n",
    "#                 for i in range(len(X_train_batch)):\n",
    "#                     image = data_generator.load_image(\n",
    "#                         X_train_batch[i]['path'], shape)   \n",
    "#                     if augument:\n",
    "#                         image = data_generator.augment(image)\n",
    "#                     batch_images.append(image/255.)\n",
    "#                     batch_labels[i][X_train_batch[i]['labels']] = 1\n",
    "#                 yield np.array(batch_images, np.float32), batch_labels\n",
    "\n",
    "#     def load_image(path, shape):\n",
    "#         image_red_ch = Image.open(path+'_red.png')\n",
    "#         image_yellow_ch = Image.open(path+'_yellow.png')\n",
    "#         image_green_ch = Image.open(path+'_green.png')\n",
    "#         image_blue_ch = Image.open(path+'_blue.png')\n",
    "#         image = np.stack((\n",
    "#         np.array(image_red_ch), \n",
    "#         np.array(image_green_ch), \n",
    "#         np.array(image_blue_ch)), -1)\n",
    "#         image = cv2.resize(image, (shape[0], shape[1]))\n",
    "#         return image\n",
    "\n",
    "#     def augment(image):\n",
    "#         augment_img = iaa.Sequential([\n",
    "#             iaa.OneOf([\n",
    "#                 iaa.Affine(rotate=0),\n",
    "#                 iaa.Affine(rotate=90),\n",
    "#                 iaa.Affine(rotate=180),\n",
    "#                 iaa.Affine(rotate=270),\n",
    "#                 iaa.Fliplr(0.5),\n",
    "#                 iaa.Flipud(0.5),\n",
    "#             ])], random_order=True)\n",
    "\n",
    "#         image_aug = augment_img.augment_image(image)\n",
    "#         return image_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D, BatchNormalization, Input, Conv2D, MaxPooling2D\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam \n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_out, channels):\n",
    "    input_tensor = Input(shape=(299,299,len(channels)))\n",
    "\n",
    "    base_model = InceptionV3(include_top=False,\n",
    "                   weights='imagenet',\n",
    "                   input_shape=(299,299,3)\n",
    "                            )\n",
    "    bn = BatchNormalization()(input_tensor)\n",
    "    x = Conv2D(3, kernel_size=(1,1), activation='relu', padding = \"same\")(bn)\n",
    "    x = base_model(x)\n",
    "    bn = BatchNormalization()(x)\n",
    "    x = Conv2D(128, kernel_size=(1,1), activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "#     output = Dense(n_out, activation='sigmoid')(x)\n",
    "    output = Dense(n_out, activation='sigmoid')(x)\n",
    "    model = Model(input_tensor, output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model(input_shape, n_out, channels):\n",
    "    input_tensor = Input(shape=(299,299,len(channels)))\n",
    "    bn = BatchNormalization()(input_tensor)\n",
    "    x = Conv2D(8, kernel_size=(3,3), activation='relu', padding = \"same\")(bn)\n",
    "    x = Conv2D(8, kernel_size=(3,3), activation='relu', padding = \"same\")(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2))(x)\n",
    "    x = Conv2D(16, kernel_size=(3,3), activation='relu', padding = \"same\")(x)\n",
    "    x = Conv2D(16, kernel_size=(3,3), activation='relu', padding = \"same\")(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2))(x)\n",
    "    x = Conv2D(32, kernel_size=(3,3), activation='relu', padding = \"same\")(x)\n",
    "    x = Conv2D(32, kernel_size=(3,3), activation='relu', padding = \"same\")(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2))(x)\n",
    "    x = Conv2D(64, kernel_size=(3,3), activation='relu', padding = \"same\")(x)\n",
    "    x = Conv2D(64, kernel_size=(3,3), activation='relu', padding = \"same\")(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2))(x)\n",
    "    x = Conv2D(128, kernel_size=(3,3), activation='relu', padding = \"same\")(x)\n",
    "    x = Conv2D(128, kernel_size=(3,3), activation='relu', padding = \"same\")(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2))(x)\n",
    "    x = Conv2D(256, kernel_size=(3,3), activation='relu', padding = \"valid\")(x)\n",
    "    x = Conv2D(256, kernel_size=(3,3), activation='relu', padding = \"valid\")(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "#     output = Dense(n_out, activation='sigmoid')(x)\n",
    "    output = Dense(n_out, activation=\"sigmoid\")(x)\n",
    "    model = Model(input_tensor, output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    #y_pred = K.round(y_pred)\n",
    "    y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    #y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1-K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31072,) (31072, 28)\n",
      "(27964,) (27964, 28) (3108,) (3108, 28)\n"
     ]
    }
   ],
   "source": [
    "# create callbacks list\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "epochs = 10; batch_size = 32;VAL_RATIO = .1;DEBUG = False\n",
    "# split data into train, valid\n",
    "paths, labels = getTrainDataset()\n",
    "\n",
    "# divide to \n",
    "keys = np.arange(paths.shape[0], dtype=np.int)  \n",
    "np.random.seed(SEED)\n",
    "np.random.shuffle(keys)\n",
    "lastTrainIndex = int((1-VAL_RATIO) * paths.shape[0])\n",
    "\n",
    "if DEBUG == True:  # use only small subset for debugging, Kaggle's RAM is limited\n",
    "    pathsTrain = paths[0:256]\n",
    "    labelsTrain = labels[0:256]\n",
    "    pathsVal = paths[lastTrainIndex:lastTrainIndex+256]\n",
    "    labelsVal = labels[lastTrainIndex:lastTrainIndex+256]\n",
    "    use_cache = True\n",
    "else:\n",
    "    pathsTrain = paths[0:lastTrainIndex]\n",
    "    labelsTrain = labels[0:lastTrainIndex]\n",
    "    pathsVal = paths[lastTrainIndex:]\n",
    "    labelsVal = labels[lastTrainIndex:]\n",
    "    use_cache = False\n",
    "\n",
    "print(paths.shape, labels.shape)\n",
    "print(pathsTrain.shape, labelsTrain.shape, pathsVal.shape, labelsVal.shape)\n",
    "use_cache = True\n",
    "channels = [\"green\", \"blue\", \"red\", \"yellow\"]\n",
    "tg = ProteinDataGenerator(pathsTrain, labelsTrain, batch_size, SHAPE, channels, use_cache=use_cache, augmentor = False)\n",
    "vg = ProteinDataGenerator(pathsVal, labelsVal, batch_size, SHAPE, channels, use_cache=use_cache, augmentor = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and valid datagens\n",
    "# train_generator = data_generator.create_train(\n",
    "#     train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=True)\n",
    "# validation_generator = data_generator.create_train(\n",
    "#     train_dataset_info[valid_indexes], 32, (SIZE,SIZE,3), augument=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('../working/InceptionV3.h5', monitor='val_f1', verbose=1, \n",
    "                             save_best_only=True, mode='max', save_weights_only = False)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_f1', factor=0.5, patience=10, \n",
    "                                   verbose=1, mode='max', epsilon=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_f1\", \n",
    "                      mode=\"max\", \n",
    "                      patience=20)\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "\n",
    "        pt_1 = K.clip(pt_1, 1e-3, .999)\n",
    "        pt_0 = K.clip(pt_0, 1e-3, .999)\n",
    "\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed\n",
    "def KerasFocalLoss(target, input):\n",
    "    \n",
    "    gamma = 2.\n",
    "    input = tf.cast(input, tf.float32)\n",
    "    \n",
    "    max_val = K.clip(-input, 0, 1)\n",
    "    loss = input - input * target + max_val + K.log(K.exp(-max_val) + K.exp(-input - max_val))\n",
    "    invprobs = tf.log_sigmoid(-input * (target * 2.0 - 1.0))\n",
    "    loss = K.exp(invprobs * gamma) * loss\n",
    "    \n",
    "    return K.mean(K.sum(loss, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 299, 299, 4)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 299, 299, 4)       16        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 299, 299, 8)       296       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 299, 299, 8)       584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 149, 149, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 149, 149, 16)      1168      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 149, 149, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 74, 74, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 74, 74, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 74, 74, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 37, 37, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 18, 18, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 18, 18, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 5, 5, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 28)                7196      \n",
      "=================================================================\n",
      "Total params: 1,449,980\n",
      "Trainable params: 1,449,972\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# warm up model\n",
    "import tensorflow as tf\n",
    "# with tf.device('/cpu:0'):\n",
    "model = simple_model(\n",
    "    input_shape=(SIZE,SIZE,len(channels)), \n",
    "    n_out=28, channels = channels)\n",
    "\n",
    "# for layer in model.layers:\n",
    "#     layer.trainable = False\n",
    "# model.layers[1].trainable = True\n",
    "# model.layers[2].trainable = True\n",
    "# model.layers[-1].trainable = True\n",
    "# model.layers[-2].trainable = True\n",
    "# model.layers[-3].trainable = True\n",
    "# model.layers[-4].trainable = True\n",
    "# model.layers[-5].trainable = True\n",
    "# model.layers[-6].trainable = True\n",
    "\n",
    "model.summary()\n",
    "# model = multi_gpu_model(model, gpus = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 299, 299, 4)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 299, 299, 4)       16        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 299, 299, 8)       296       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 299, 299, 8)       584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 149, 149, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 149, 149, 16)      1168      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 149, 149, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 74, 74, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 74, 74, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 74, 74, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 37, 37, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 18, 18, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 18, 18, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 5, 5, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 28)                7196      \n",
      "=================================================================\n",
      "Total params: 1,449,980\n",
      "Trainable params: 1,449,972\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=\"binary_crossentropy\", \n",
    "    optimizer=Adam(1e-03),\n",
    "    metrics=['binary_accuracy', f1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "874/874 [==============================] - 847s 969ms/step - loss: 0.1845 - binary_accuracy: 0.9392 - f1: 0.0477 - val_loss: 0.1707 - val_binary_accuracy: 0.9412 - val_f1: 0.0399\n",
      "\n",
      "Epoch 00001: val_f1 improved from -inf to 0.03985, saving model to ../working/InceptionV3.h5\n",
      "Epoch 2/50\n",
      "874/874 [==============================] - 182s 208ms/step - loss: 0.1709 - binary_accuracy: 0.9416 - f1: 0.0556 - val_loss: 0.1660 - val_binary_accuracy: 0.9413 - val_f1: 0.0520\n",
      "\n",
      "Epoch 00002: val_f1 improved from 0.03985 to 0.05200, saving model to ../working/InceptionV3.h5\n",
      "Epoch 3/50\n",
      "874/874 [==============================] - 169s 194ms/step - loss: 0.1639 - binary_accuracy: 0.9451 - f1: 0.0679 - val_loss: 0.1587 - val_binary_accuracy: 0.9466 - val_f1: 0.0678\n",
      "\n",
      "Epoch 00003: val_f1 improved from 0.05200 to 0.06778, saving model to ../working/InceptionV3.h5\n",
      "Epoch 4/50\n",
      "874/874 [==============================] - 164s 188ms/step - loss: 0.1586 - binary_accuracy: 0.9473 - f1: 0.0841 - val_loss: 0.1556 - val_binary_accuracy: 0.9478 - val_f1: 0.0850\n",
      "\n",
      "Epoch 00004: val_f1 improved from 0.06778 to 0.08504, saving model to ../working/InceptionV3.h5\n",
      "Epoch 5/50\n",
      "874/874 [==============================] - 159s 182ms/step - loss: 0.1525 - binary_accuracy: 0.9492 - f1: 0.1098 - val_loss: 0.1476 - val_binary_accuracy: 0.9496 - val_f1: 0.1163\n",
      "\n",
      "Epoch 00005: val_f1 improved from 0.08504 to 0.11631, saving model to ../working/InceptionV3.h5\n",
      "Epoch 6/50\n",
      "874/874 [==============================] - 167s 191ms/step - loss: 0.1478 - binary_accuracy: 0.9503 - f1: 0.1239 - val_loss: 0.1436 - val_binary_accuracy: 0.9504 - val_f1: 0.1318\n",
      "\n",
      "Epoch 00006: val_f1 improved from 0.11631 to 0.13184, saving model to ../working/InceptionV3.h5\n",
      "Epoch 7/50\n",
      "874/874 [==============================] - 161s 184ms/step - loss: 0.1443 - binary_accuracy: 0.9508 - f1: 0.1343 - val_loss: 0.1424 - val_binary_accuracy: 0.9508 - val_f1: 0.1425\n",
      "\n",
      "Epoch 00007: val_f1 improved from 0.13184 to 0.14249, saving model to ../working/InceptionV3.h5\n",
      "Epoch 8/50\n",
      "874/874 [==============================] - 165s 189ms/step - loss: 0.1416 - binary_accuracy: 0.9515 - f1: 0.1440 - val_loss: 0.1388 - val_binary_accuracy: 0.9517 - val_f1: 0.1549\n",
      "\n",
      "Epoch 00008: val_f1 improved from 0.14249 to 0.15489, saving model to ../working/InceptionV3.h5\n",
      "Epoch 9/50\n",
      "874/874 [==============================] - 168s 192ms/step - loss: 0.1389 - binary_accuracy: 0.9525 - f1: 0.1554 - val_loss: 0.1357 - val_binary_accuracy: 0.9533 - val_f1: 0.1618\n",
      "\n",
      "Epoch 00009: val_f1 improved from 0.15489 to 0.16175, saving model to ../working/InceptionV3.h5\n",
      "Epoch 10/50\n",
      "874/874 [==============================] - 167s 191ms/step - loss: 0.1360 - binary_accuracy: 0.9536 - f1: 0.1654 - val_loss: 0.1355 - val_binary_accuracy: 0.9534 - val_f1: 0.1776\n",
      "\n",
      "Epoch 00010: val_f1 improved from 0.16175 to 0.17764, saving model to ../working/InceptionV3.h5\n",
      "Epoch 11/50\n",
      "874/874 [==============================] - 180s 206ms/step - loss: 0.1332 - binary_accuracy: 0.9546 - f1: 0.1773 - val_loss: 0.1331 - val_binary_accuracy: 0.9543 - val_f1: 0.1839\n",
      "\n",
      "Epoch 00011: val_f1 improved from 0.17764 to 0.18392, saving model to ../working/InceptionV3.h5\n",
      "Epoch 12/50\n",
      "874/874 [==============================] - 161s 184ms/step - loss: 0.1311 - binary_accuracy: 0.9552 - f1: 0.1837 - val_loss: 0.1309 - val_binary_accuracy: 0.9548 - val_f1: 0.1879\n",
      "\n",
      "Epoch 00012: val_f1 improved from 0.18392 to 0.18788, saving model to ../working/InceptionV3.h5\n",
      "Epoch 13/50\n",
      "874/874 [==============================] - 158s 181ms/step - loss: 0.1291 - binary_accuracy: 0.9561 - f1: 0.1915 - val_loss: 0.1329 - val_binary_accuracy: 0.9530 - val_f1: 0.1843\n",
      "\n",
      "Epoch 00013: val_f1 did not improve from 0.18788\n",
      "Epoch 14/50\n",
      "874/874 [==============================] - 174s 199ms/step - loss: 0.1274 - binary_accuracy: 0.9564 - f1: 0.1964 - val_loss: 0.1309 - val_binary_accuracy: 0.9543 - val_f1: 0.1970\n",
      "\n",
      "Epoch 00014: val_f1 improved from 0.18788 to 0.19699, saving model to ../working/InceptionV3.h5\n",
      "Epoch 15/50\n",
      "874/874 [==============================] - 170s 195ms/step - loss: 0.1262 - binary_accuracy: 0.9569 - f1: 0.2005 - val_loss: 0.1288 - val_binary_accuracy: 0.9554 - val_f1: 0.1961\n",
      "\n",
      "Epoch 00015: val_f1 did not improve from 0.19699\n",
      "Epoch 16/50\n",
      "874/874 [==============================] - 161s 184ms/step - loss: 0.1244 - binary_accuracy: 0.9573 - f1: 0.2065 - val_loss: 0.1289 - val_binary_accuracy: 0.9550 - val_f1: 0.1954\n",
      "\n",
      "Epoch 00016: val_f1 did not improve from 0.19699\n",
      "Epoch 17/50\n",
      "874/874 [==============================] - 172s 197ms/step - loss: 0.1231 - binary_accuracy: 0.9578 - f1: 0.2103 - val_loss: 0.1301 - val_binary_accuracy: 0.9551 - val_f1: 0.1893\n",
      "\n",
      "Epoch 00017: val_f1 did not improve from 0.19699\n",
      "Epoch 18/50\n",
      "874/874 [==============================] - 157s 180ms/step - loss: 0.1217 - binary_accuracy: 0.9583 - f1: 0.2145 - val_loss: 0.1286 - val_binary_accuracy: 0.9554 - val_f1: 0.2024\n",
      "\n",
      "Epoch 00018: val_f1 improved from 0.19699 to 0.20241, saving model to ../working/InceptionV3.h5\n",
      "Epoch 19/50\n",
      "874/874 [==============================] - 158s 180ms/step - loss: 0.1203 - binary_accuracy: 0.9588 - f1: 0.2186 - val_loss: 0.1282 - val_binary_accuracy: 0.9560 - val_f1: 0.2057\n",
      "\n",
      "Epoch 00019: val_f1 improved from 0.20241 to 0.20566, saving model to ../working/InceptionV3.h5\n",
      "Epoch 20/50\n",
      "874/874 [==============================] - 165s 189ms/step - loss: 0.1197 - binary_accuracy: 0.9588 - f1: 0.2195 - val_loss: 0.1284 - val_binary_accuracy: 0.9552 - val_f1: 0.2057\n",
      "\n",
      "Epoch 00020: val_f1 improved from 0.20566 to 0.20571, saving model to ../working/InceptionV3.h5\n",
      "Epoch 21/50\n",
      "874/874 [==============================] - 167s 191ms/step - loss: 0.1180 - binary_accuracy: 0.9595 - f1: 0.2242 - val_loss: 0.1292 - val_binary_accuracy: 0.9554 - val_f1: 0.2086\n",
      "\n",
      "Epoch 00021: val_f1 improved from 0.20571 to 0.20859, saving model to ../working/InceptionV3.h5\n",
      "Epoch 22/50\n",
      "874/874 [==============================] - 170s 195ms/step - loss: 0.1171 - binary_accuracy: 0.9599 - f1: 0.2271 - val_loss: 0.1324 - val_binary_accuracy: 0.9554 - val_f1: 0.1976\n",
      "\n",
      "Epoch 00022: val_f1 did not improve from 0.20859\n",
      "Epoch 23/50\n",
      "874/874 [==============================] - 175s 200ms/step - loss: 0.1171 - binary_accuracy: 0.9596 - f1: 0.2272 - val_loss: 0.1296 - val_binary_accuracy: 0.9552 - val_f1: 0.2119\n",
      "\n",
      "Epoch 00023: val_f1 improved from 0.20859 to 0.21186, saving model to ../working/InceptionV3.h5\n",
      "Epoch 24/50\n",
      "874/874 [==============================] - 172s 197ms/step - loss: 0.1159 - binary_accuracy: 0.9603 - f1: 0.2295 - val_loss: 0.1294 - val_binary_accuracy: 0.9553 - val_f1: 0.2087\n",
      "\n",
      "Epoch 00024: val_f1 did not improve from 0.21186\n",
      "Epoch 25/50\n",
      "874/874 [==============================] - 163s 186ms/step - loss: 0.1150 - binary_accuracy: 0.9603 - f1: 0.2333 - val_loss: 0.1276 - val_binary_accuracy: 0.9561 - val_f1: 0.2158\n",
      "\n",
      "Epoch 00025: val_f1 improved from 0.21186 to 0.21580, saving model to ../working/InceptionV3.h5\n",
      "Epoch 26/50\n",
      "874/874 [==============================] - 164s 188ms/step - loss: 0.1143 - binary_accuracy: 0.9606 - f1: 0.2332 - val_loss: 0.1319 - val_binary_accuracy: 0.9552 - val_f1: 0.1990\n",
      "\n",
      "Epoch 00026: val_f1 did not improve from 0.21580\n",
      "Epoch 27/50\n",
      "874/874 [==============================] - 161s 184ms/step - loss: 0.1139 - binary_accuracy: 0.9607 - f1: 0.2363 - val_loss: 0.1293 - val_binary_accuracy: 0.9557 - val_f1: 0.2087\n",
      "\n",
      "Epoch 00027: val_f1 did not improve from 0.21580\n",
      "Epoch 28/50\n",
      "874/874 [==============================] - 174s 199ms/step - loss: 0.1129 - binary_accuracy: 0.9611 - f1: 0.2395 - val_loss: 0.1313 - val_binary_accuracy: 0.9546 - val_f1: 0.1984\n",
      "\n",
      "Epoch 00028: val_f1 did not improve from 0.21580\n",
      "Epoch 29/50\n",
      "874/874 [==============================] - 162s 186ms/step - loss: 0.1117 - binary_accuracy: 0.9614 - f1: 0.2401 - val_loss: 0.1307 - val_binary_accuracy: 0.9552 - val_f1: 0.2075\n",
      "\n",
      "Epoch 00029: val_f1 did not improve from 0.21580\n",
      "Epoch 30/50\n",
      "874/874 [==============================] - 149s 171ms/step - loss: 0.1108 - binary_accuracy: 0.9617 - f1: 0.2435 - val_loss: 0.1312 - val_binary_accuracy: 0.9554 - val_f1: 0.1977\n",
      "\n",
      "Epoch 00030: val_f1 did not improve from 0.21580\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "874/874 [==============================] - 174s 199ms/step - loss: 0.1104 - binary_accuracy: 0.9617 - f1: 0.2439 - val_loss: 0.1296 - val_binary_accuracy: 0.9555 - val_f1: 0.2028\n",
      "\n",
      "Epoch 00031: val_f1 did not improve from 0.21580\n",
      "Epoch 32/50\n",
      "874/874 [==============================] - 163s 187ms/step - loss: 0.1100 - binary_accuracy: 0.9619 - f1: 0.2463 - val_loss: 0.1292 - val_binary_accuracy: 0.9560 - val_f1: 0.2100\n",
      "\n",
      "Epoch 00032: val_f1 did not improve from 0.21580\n",
      "Epoch 33/50\n",
      "874/874 [==============================] - 176s 201ms/step - loss: 0.1101 - binary_accuracy: 0.9619 - f1: 0.2458 - val_loss: 0.1309 - val_binary_accuracy: 0.9556 - val_f1: 0.2056\n",
      "\n",
      "Epoch 00033: val_f1 did not improve from 0.21580\n",
      "Epoch 34/50\n",
      "874/874 [==============================] - 174s 199ms/step - loss: 0.1093 - binary_accuracy: 0.9621 - f1: 0.2484 - val_loss: 0.1318 - val_binary_accuracy: 0.9563 - val_f1: 0.2128\n",
      "\n",
      "Epoch 00034: val_f1 did not improve from 0.21580\n",
      "Epoch 35/50\n",
      "874/874 [==============================] - 182s 208ms/step - loss: 0.1078 - binary_accuracy: 0.9625 - f1: 0.2507 - val_loss: 0.1310 - val_binary_accuracy: 0.9552 - val_f1: 0.2094\n",
      "\n",
      "Epoch 00035: val_f1 did not improve from 0.21580\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 36/50\n",
      "874/874 [==============================] - 179s 205ms/step - loss: 0.0992 - binary_accuracy: 0.9654 - f1: 0.2692 - val_loss: 0.1339 - val_binary_accuracy: 0.9552 - val_f1: 0.2169\n",
      "\n",
      "Epoch 00036: val_f1 improved from 0.21580 to 0.21689, saving model to ../working/InceptionV3.h5\n",
      "Epoch 37/50\n",
      "874/874 [==============================] - 163s 186ms/step - loss: 0.0947 - binary_accuracy: 0.9668 - f1: 0.2825 - val_loss: 0.1366 - val_binary_accuracy: 0.9555 - val_f1: 0.2176\n",
      "\n",
      "Epoch 00037: val_f1 improved from 0.21689 to 0.21762, saving model to ../working/InceptionV3.h5\n",
      "Epoch 38/50\n",
      "874/874 [==============================] - 162s 186ms/step - loss: 0.0922 - binary_accuracy: 0.9675 - f1: 0.2887 - val_loss: 0.1367 - val_binary_accuracy: 0.9554 - val_f1: 0.2152\n",
      "\n",
      "Epoch 00038: val_f1 did not improve from 0.21762\n",
      "Epoch 39/50\n",
      "874/874 [==============================] - 144s 165ms/step - loss: 0.0900 - binary_accuracy: 0.9682 - f1: 0.2952 - val_loss: 0.1396 - val_binary_accuracy: 0.9551 - val_f1: 0.2218\n",
      "\n",
      "Epoch 00039: val_f1 improved from 0.21762 to 0.22182, saving model to ../working/InceptionV3.h5\n",
      "Epoch 40/50\n",
      "874/874 [==============================] - 164s 188ms/step - loss: 0.0875 - binary_accuracy: 0.9691 - f1: 0.3010 - val_loss: 0.1412 - val_binary_accuracy: 0.9551 - val_f1: 0.2169\n",
      "\n",
      "Epoch 00040: val_f1 did not improve from 0.22182\n",
      "Epoch 41/50\n",
      "874/874 [==============================] - 160s 183ms/step - loss: 0.0854 - binary_accuracy: 0.9698 - f1: 0.3054 - val_loss: 0.1430 - val_binary_accuracy: 0.9549 - val_f1: 0.2196\n",
      "\n",
      "Epoch 00041: val_f1 did not improve from 0.22182\n",
      "Epoch 42/50\n",
      "874/874 [==============================] - 160s 183ms/step - loss: 0.0841 - binary_accuracy: 0.9702 - f1: 0.3103 - val_loss: 0.1425 - val_binary_accuracy: 0.9549 - val_f1: 0.2220\n",
      "\n",
      "Epoch 00042: val_f1 improved from 0.22182 to 0.22201, saving model to ../working/InceptionV3.h5\n",
      "Epoch 43/50\n",
      "874/874 [==============================] - 163s 187ms/step - loss: 0.0818 - binary_accuracy: 0.9710 - f1: 0.3156 - val_loss: 0.1477 - val_binary_accuracy: 0.9552 - val_f1: 0.2211\n",
      "\n",
      "Epoch 00043: val_f1 did not improve from 0.22201\n",
      "Epoch 44/50\n",
      "874/874 [==============================] - 164s 187ms/step - loss: 0.0803 - binary_accuracy: 0.9715 - f1: 0.3195 - val_loss: 0.1478 - val_binary_accuracy: 0.9551 - val_f1: 0.2166\n",
      "\n",
      "Epoch 00044: val_f1 did not improve from 0.22201\n",
      "Epoch 45/50\n",
      "874/874 [==============================] - 157s 179ms/step - loss: 0.0793 - binary_accuracy: 0.9720 - f1: 0.3231 - val_loss: 0.1500 - val_binary_accuracy: 0.9547 - val_f1: 0.2201\n",
      "\n",
      "Epoch 00045: val_f1 did not improve from 0.22201\n",
      "Epoch 46/50\n",
      "874/874 [==============================] - 167s 191ms/step - loss: 0.0780 - binary_accuracy: 0.9723 - f1: 0.3266 - val_loss: 0.1573 - val_binary_accuracy: 0.9541 - val_f1: 0.2113\n",
      "\n",
      "Epoch 00046: val_f1 did not improve from 0.22201\n",
      "Epoch 47/50\n",
      "874/874 [==============================] - 156s 179ms/step - loss: 0.0760 - binary_accuracy: 0.9728 - f1: 0.3322 - val_loss: 0.1582 - val_binary_accuracy: 0.9548 - val_f1: 0.2149\n",
      "\n",
      "Epoch 00047: val_f1 did not improve from 0.22201\n",
      "Epoch 48/50\n",
      "874/874 [==============================] - 155s 178ms/step - loss: 0.0760 - binary_accuracy: 0.9728 - f1: 0.3330 - val_loss: 0.1554 - val_binary_accuracy: 0.9542 - val_f1: 0.2215\n",
      "\n",
      "Epoch 00048: val_f1 did not improve from 0.22201\n",
      "Epoch 49/50\n",
      "874/874 [==============================] - 170s 194ms/step - loss: 0.0742 - binary_accuracy: 0.9736 - f1: 0.3371 - val_loss: 0.1609 - val_binary_accuracy: 0.9545 - val_f1: 0.2172\n",
      "\n",
      "Epoch 00049: val_f1 did not improve from 0.22201\n",
      "Epoch 50/50\n",
      "874/874 [==============================] - 168s 192ms/step - loss: 0.0734 - binary_accuracy: 0.9736 - f1: 0.3413 - val_loss: 0.1628 - val_binary_accuracy: 0.9546 - val_f1: 0.2185\n",
      "\n",
      "Epoch 00050: val_f1 did not improve from 0.22201\n"
     ]
    }
   ],
   "source": [
    "hist =  model.fit_generator(\n",
    "        tg,\n",
    "        steps_per_epoch=np.ceil(float(len(pathsTrain)) / float(batch_size)),\n",
    "        validation_data=vg,\n",
    "        validation_steps=np.ceil(float(len(pathsVal)) / float(batch_size)),\n",
    "        epochs=50, \n",
    "        verbose=1,\n",
    "        callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x00000116E045D048>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001201A4D8908>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001201A52AD30>\n",
      "<keras.engine.training.Model object at 0x000001201A4D8C50>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000012022570C18>\n",
      "<keras.layers.core.Flatten object at 0x0000012020C3A588>\n",
      "<keras.layers.core.Dropout object at 0x000001201A67E978>\n",
      "<keras.layers.core.Dense object at 0x000001201A71FB00>\n",
      "<keras.layers.core.Dropout object at 0x00000120205AE6A0>\n",
      "<keras.layers.core.Dense object at 0x00000120205AE4A8>\n"
     ]
    }
   ],
   "source": [
    "# train all layers\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    layer.trainable = True\n",
    "model.compile(loss=focal_loss(),\n",
    "            optimizer=Adam(lr=1e-4),\n",
    "            metrics=['accuracy', f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1166/1165 [==============================] - 606s 520ms/step - loss: 13.8179 - acc: 0.4125 - f1: 0.1311 - val_loss: 13.0988 - val_acc: 0.4613 - val_f1: 0.1407\n",
      "\n",
      "Epoch 00001: val_f1 improved from 0.10443 to 0.14066, saving model to ../working/InceptionV3.h5\n",
      "Epoch 2/200\n",
      "1166/1165 [==============================] - 530s 455ms/step - loss: 12.4071 - acc: 0.4781 - f1: 0.1634 - val_loss: 12.4184 - val_acc: 0.5031 - val_f1: 0.1635\n",
      "\n",
      "Epoch 00002: val_f1 improved from 0.14066 to 0.16350, saving model to ../working/InceptionV3.h5\n",
      "Epoch 3/200\n",
      "1166/1165 [==============================] - 554s 475ms/step - loss: 11.2627 - acc: 0.5278 - f1: 0.1934 - val_loss: 12.4274 - val_acc: 0.4550 - val_f1: 0.1691\n",
      "\n",
      "Epoch 00003: val_f1 improved from 0.16350 to 0.16911, saving model to ../working/InceptionV3.h5\n",
      "Epoch 4/200\n",
      "1166/1165 [==============================] - 593s 508ms/step - loss: 9.4958 - acc: 0.5981 - f1: 0.2390 - val_loss: 13.9004 - val_acc: 0.4100 - val_f1: 0.1862\n",
      "\n",
      "Epoch 00004: val_f1 improved from 0.16911 to 0.18621, saving model to ../working/InceptionV3.h5\n",
      "Epoch 5/200\n",
      "1166/1165 [==============================] - 588s 504ms/step - loss: 8.0883 - acc: 0.6450 - f1: 0.2783 - val_loss: 14.0686 - val_acc: 0.5065 - val_f1: 0.1976\n",
      "\n",
      "Epoch 00005: val_f1 improved from 0.18621 to 0.19758, saving model to ../working/InceptionV3.h5\n",
      "Epoch 6/200\n",
      "1166/1165 [==============================] - 588s 504ms/step - loss: 6.6948 - acc: 0.6852 - f1: 0.3171 - val_loss: 14.5782 - val_acc: 0.4610 - val_f1: 0.2054\n",
      "\n",
      "Epoch 00006: val_f1 improved from 0.19758 to 0.20538, saving model to ../working/InceptionV3.h5\n",
      "Epoch 7/200\n",
      "1166/1165 [==============================] - 576s 494ms/step - loss: 5.0948 - acc: 0.7253 - f1: 0.3681 - val_loss: 17.3627 - val_acc: 0.4627 - val_f1: 0.2089\n",
      "\n",
      "Epoch 00007: val_f1 improved from 0.20538 to 0.20888, saving model to ../working/InceptionV3.h5\n",
      "Epoch 8/200\n",
      " 835/1165 [====================>.........] - ETA: 2:41 - loss: 4.3980 - acc: 0.7327 - f1: 0.3925"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 12\n",
    "hist =  model.fit_generator(\n",
    "        tg,\n",
    "        steps_per_epoch=np.ceil(float(len(pathsTrain)) / float(batch_size))/2,\n",
    "        validation_data=vg,\n",
    "        validation_steps=np.ceil(float(len(pathsVal)) / float(batch_size))/2,\n",
    "        epochs=200, \n",
    "        verbose=1,\n",
    "        callbacks=callbacks_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss=f1_loss,\n",
    "#             optimizer=Adam(lr=1e-4),\n",
    "#             metrics=['accuracy', f1])\n",
    "# hist =  model.fit_generator(\n",
    "#         tg,\n",
    "#         steps_per_epoch=np.ceil(float(len(pathsTrain)) / float(batch_size))/2,\n",
    "#         validation_data=vg,\n",
    "#         validation_steps=np.ceil(float(len(pathsVal)) / float(batch_size))/2,\n",
    "#         epochs=200, \n",
    "#         verbose=1,\n",
    "#         callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax[0].set_title('loss')\n",
    "ax[0].plot(hist.epoch, hist.history[\"loss\"], label=\"Train loss\")\n",
    "ax[0].plot(hist.epoch, hist.history[\"val_loss\"], label=\"Validation loss\")\n",
    "ax[1].set_title('acc')\n",
    "ax[1].plot(hist.epoch, hist.history[\"f1\"], label=\"Train F1\")\n",
    "ax[1].plot(hist.epoch, hist.history[\"val_f1\"], label=\"Validation F1\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "bestModel = load_model('../working/InceptionV3.h5', custom_objects={'f1': f1, 'f1_loss': f1_loss, 'focal_loss_fixed':focal_loss()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "lastFullValPred = np.empty((0, 28))\n",
    "lastFullValLabels = np.empty((0, 28))\n",
    "for i in tqdm(range(len(vg))): \n",
    "    im, lbl = vg[i]\n",
    "    scores = bestModel.predict(im)\n",
    "    lastFullValPred = np.append(lastFullValPred, scores, axis=0)\n",
    "    lastFullValLabels = np.append(lastFullValLabels, lbl, axis=0)\n",
    "print(lastFullValPred.shape, lastFullValLabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score as off1\n",
    "rng = np.arange(0, 1, 0.001)\n",
    "f1s = np.zeros((rng.shape[0], 28))\n",
    "for j,t in enumerate(tqdm(rng)):\n",
    "    for i in range(28):\n",
    "        p = np.array(lastFullValPred[:,i]>t, dtype=np.int8)\n",
    "        scoref1 = off1(lastFullValLabels[:,i], p, average='binary')\n",
    "        f1s[j,i] = scoref1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Individual F1-scores for each class:')\n",
    "print(np.max(f1s, axis=0))\n",
    "print('Macro F1-score CV =', np.mean(np.max(f1s, axis=0)))\n",
    "plt.plot(rng, f1s)\n",
    "T = np.empty(28)\n",
    "for i in range(28):\n",
    "    T[i] = rng[np.where(f1s[:,i] == np.max(f1s[:,i]))[0][0]]\n",
    "print('Probability threshold maximizing CV F1-score for each class:')\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathsTest, labelsTest = getTestDataset()\n",
    "\n",
    "testg = ProteinDataGenerator(pathsTest, labelsTest, batch_size, SHAPE, channels)\n",
    "submit = pd.read_csv(DIR + '/sample_submission.csv')\n",
    "P = np.zeros((pathsTest.shape[0], 28))\n",
    "for i in tqdm(range(len(testg))):\n",
    "    images, labels = testg[i]\n",
    "    score = bestModel.predict(images)\n",
    "    P[i*batch_size:i*batch_size+score.shape[0]] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP = np.array(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "\n",
    "for row in tqdm(range(submit.shape[0])):\n",
    "    \n",
    "    str_label = ''\n",
    "    \n",
    "    for col in range(PP.shape[1]):\n",
    "        if(PP[row, col] < T[col]):\n",
    "            str_label += ''\n",
    "        else:\n",
    "            str_label += str(col) + ' '\n",
    "    prediction.append(str_label.strip())\n",
    "    \n",
    "submit['Predicted'] = np.array(prediction)\n",
    "submit.to_csv('transfer_1x1conv_aug_focal_loss.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# pathsTest, labelsTest = getTestDataset()\n",
    "\n",
    "# testg = ProteinDataGenerator(pathsTest, labelsTest, batch_size, SHAPE)\n",
    "# submit = pd.read_csv(DIR + '/sample_submission.csv')\n",
    "# P = np.zeros((pathsTest.shape[0], 28))\n",
    "# for i in tqdm(range(len(testg))):\n",
    "#     images, labels = testg[i]\n",
    "#     score = bestModel.predict(images)\n",
    "#     P[i*batch_size:i*batch_size+score.shape[0]] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PP = np.array(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = []\n",
    "\n",
    "# for row in tqdm(range(submit.shape[0])):\n",
    "    \n",
    "#     str_label = ''\n",
    "    \n",
    "#     for col in range(PP.shape[1]):\n",
    "#         if(PP[row, col] < .2):   # to account for losing TP is more costly than decreasing FP\n",
    "#             #print(PP[row])\n",
    "#             str_label += ''\n",
    "#         else:\n",
    "#             str_label += str(col) + ' '\n",
    "#     prediction.append(str_label.strip())\n",
    "    \n",
    "# submit['Predicted'] = np.array(prediction)\n",
    "# submit.to_csv('datagenerator_model_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
