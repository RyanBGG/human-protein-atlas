{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "import keras\n",
    "import warnings\n",
    "from keras.utils import Sequence\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SIZE = 299\n",
    "SEED = 777\n",
    "THRESHOLD = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset info\n",
    "DIR = '../input/'\n",
    "data = pd.read_csv('../input/train.csv')\n",
    "\n",
    "# train_dataset_info = []\n",
    "# for name, labels in zip(data['Id'], data['Target'].str.split(' ')):\n",
    "#     train_dataset_info.append({\n",
    "#         'path':os.path.join(path_to_train, name),\n",
    "#         'labels':np.array([int(label) for label in labels])})\n",
    "# train_dataset_info = np.array(train_dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainDataset():\n",
    "    \n",
    "    path_to_train = DIR + '/train/'\n",
    "    data = pd.read_csv(DIR + '/train.csv')\n",
    "\n",
    "    paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for name, lbl in zip(data['Id'], data['Target'].str.split(' ')):\n",
    "        y = np.zeros(28)\n",
    "        for key in lbl:\n",
    "            y[int(key)] = 1\n",
    "        paths.append(os.path.join(path_to_train, name))\n",
    "        labels.append(y)\n",
    "\n",
    "    return np.array(paths), np.array(labels)\n",
    "\n",
    "def getTestDataset():\n",
    "    \n",
    "    path_to_test = DIR + '/test/'\n",
    "    data = pd.read_csv(DIR + '/sample_submission.csv')\n",
    "\n",
    "    paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for name in data['Id']:\n",
    "        y = np.ones(28)\n",
    "        paths.append(os.path.join(path_to_test, name))\n",
    "        labels.append(y)\n",
    "\n",
    "    return np.array(paths), np.array(labels)\n",
    "paths, labels = getTrainDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credits: https://github.com/keras-team/keras/blob/master/keras/utils/data_utils.py#L302\n",
    "# credits: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "from random import randint\n",
    "class ProteinDataGenerator(keras.utils.Sequence):\n",
    "            \n",
    "    def __init__(self, paths, labels, batch_size, shape, channels = [], shuffle = False, use_cache = False, augmentor = False):\n",
    "        self.paths, self.labels = paths, labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shape = shape\n",
    "        self.shuffle = shuffle\n",
    "        self.use_cache = use_cache\n",
    "        self.channels = channels\n",
    "        self.augmentor = augmentor\n",
    "        self.clahe = cv2.createCLAHE()\n",
    "        if use_cache == True:\n",
    "            self.cache = np.zeros((paths.shape[0], shape[0], shape[1], len(channels)))\n",
    "            self.is_cached = np.zeros((paths.shape[0]))\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.paths) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        indexes = self.indexes[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "\n",
    "        paths = self.paths[indexes]\n",
    "        X = np.zeros((paths.shape[0], self.shape[0], self.shape[1], self.shape[2]))\n",
    "        # Generate data\n",
    "        if self.use_cache == True:\n",
    "            X = self.cache[indexes]\n",
    "            for i, path in enumerate(paths[np.where(self.is_cached[indexes] == 0)]):\n",
    "                image = self.__load_image(path)\n",
    "                self.is_cached[indexes[i]] = 1\n",
    "                self.cache[indexes[i]] = image\n",
    "                X[i] = image\n",
    "        else:\n",
    "            for i, path in enumerate(paths):\n",
    "                X[i] = self.__load_image(path)\n",
    "        if self.augmentor == True:\n",
    "            for i, item in enumerate(X):\n",
    "                X[i] = self.augment(item)\n",
    "        y = self.labels[indexes]\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        # Updates indexes after each epoch\n",
    "        self.indexes = np.arange(len(self.paths))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Create a generator that iterate over the Sequence.\"\"\"\n",
    "        for item in (self[i] for i in range(len(self))):\n",
    "            yield item\n",
    "            \n",
    "    def __load_image(self, path):\n",
    "        images = []\n",
    "        for channel in self.channels:\n",
    "            im = np.array(Image.open(path + '_' + channel + '.png'))\n",
    "            \n",
    "#             im = clahe.apply(im)\n",
    "            images.append(im)\n",
    "            \n",
    "        if len(self.channels) >= 2:\n",
    "            im = np.stack((\n",
    "                images\n",
    "            ), -1)\n",
    "            im = cv2.resize(im, (SIZE,SIZE))\n",
    "            im = np.divide(im, 255)\n",
    "\n",
    "        else:\n",
    "            im = images[0]\n",
    "            im = cv2.resize(im, (SIZE,SIZE))\n",
    "            im = np.divide(im, 255)\n",
    "            im = np.expand_dims(im, 2)\n",
    "        return im\n",
    "    def augment(self, image):\n",
    "        if randint(0,1) == 1:\n",
    "            augment_img = iaa.Sequential([\n",
    "                iaa.OneOf([\n",
    "                    iaa.Fliplr(0.5), # horizontal flips\n",
    "                    iaa.Flipud(0.5), # horizontal flips\n",
    "                    iaa.Crop(percent=(0, 0.1)), # random crops\n",
    "                    # Small gaussian blur with random sigma between 0 and 0.5.\n",
    "                    # But we only blur about 50% of all images.\n",
    "                    iaa.Sometimes(0.5,\n",
    "                        iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "                    ),\n",
    "                    # Make some images brighter and some darker.\n",
    "                    # In 20% of all cases, we sample the multiplier once per channel,\n",
    "                    # which can end up changing the color of the images.\n",
    "                    iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
    "                    # Apply affine transformations to each image.\n",
    "                    # Scale/zoom them, translate/move them, rotate them and shear them.\n",
    "                    iaa.Affine(\n",
    "                        scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\n",
    "                        translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n",
    "                        rotate=(-180, 180),\n",
    "                        shear=(-4, 4)\n",
    "                    )\n",
    "                ])], random_order=True)\n",
    "\n",
    "\n",
    "            image_aug = augment_img.augment_image(image)\n",
    "            return image_aug\n",
    "        else:\n",
    "            return image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE = (299, 299, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels = [\"red\", \"green\", \"blue\"]\n",
    "# for path in paths[0:10]:\n",
    "#     images = []\n",
    "#     for channel in channels:\n",
    "#         im = np.array(Image.open(path + '_' + channel + '.png'))\n",
    "# #         im = cv2.equalizeHist(im)\n",
    "#         clahe = cv2.createCLAHE()\n",
    "#         im = clahe.apply(im)\n",
    "# #         plt.imshow(im)\n",
    "#         images.append(im)\n",
    "\n",
    "#     if len(channels) >= 2:\n",
    "#         im = np.stack((\n",
    "#             images\n",
    "#         ), -1)\n",
    "#         im = cv2.resize(im, (SIZE,SIZE))\n",
    "#         im = np.divide(im, 255)\n",
    "        \n",
    "        \n",
    "#     else:\n",
    "#         im = images[0]\n",
    "#         im = cv2.resize(im, (SIZE,SIZE))\n",
    "#         im = np.divide(im, 255)\n",
    "#         im = np.expand_dims(im, 2)\n",
    "#     plt.imshow(augment(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class data_generator:\n",
    "    \n",
    "#     def create_train(dataset_info, batch_size, shape, augument=True):\n",
    "#         assert shape[2] == 3\n",
    "#         while True:\n",
    "#             dataset_info = shuffle(dataset_info)\n",
    "#             for start in range(0, len(dataset_info), batch_size):\n",
    "#                 end = min(start + batch_size, len(dataset_info))\n",
    "#                 batch_images = []\n",
    "#                 X_train_batch = dataset_info[start:end]\n",
    "#                 batch_labels = np.zeros((len(X_train_batch), 28))\n",
    "#                 for i in range(len(X_train_batch)):\n",
    "#                     image = data_generator.load_image(\n",
    "#                         X_train_batch[i]['path'], shape)   \n",
    "#                     if augument:\n",
    "#                         image = data_generator.augment(image)\n",
    "#                     batch_images.append(image/255.)\n",
    "#                     batch_labels[i][X_train_batch[i]['labels']] = 1\n",
    "#                 yield np.array(batch_images, np.float32), batch_labels\n",
    "\n",
    "#     def load_image(path, shape):\n",
    "#         image_red_ch = Image.open(path+'_red.png')\n",
    "#         image_yellow_ch = Image.open(path+'_yellow.png')\n",
    "#         image_green_ch = Image.open(path+'_green.png')\n",
    "#         image_blue_ch = Image.open(path+'_blue.png')\n",
    "#         image = np.stack((\n",
    "#         np.array(image_red_ch), \n",
    "#         np.array(image_green_ch), \n",
    "#         np.array(image_blue_ch)), -1)\n",
    "#         image = cv2.resize(image, (shape[0], shape[1]))\n",
    "#         return image\n",
    "\n",
    "#     def augment(image):\n",
    "#         augment_img = iaa.Sequential([\n",
    "#             iaa.OneOf([\n",
    "#                 iaa.Affine(rotate=0),\n",
    "#                 iaa.Affine(rotate=90),\n",
    "#                 iaa.Affine(rotate=180),\n",
    "#                 iaa.Affine(rotate=270),\n",
    "#                 iaa.Fliplr(0.5),\n",
    "#                 iaa.Flipud(0.5),\n",
    "#             ])], random_order=True)\n",
    "\n",
    "#         image_aug = augment_img.augment_image(image)\n",
    "#         return image_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D, BatchNormalization, Input, Conv2D, MaxPooling2D\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam \n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_out, channels):\n",
    "    input_tensor = Input(shape=(299,299,len(channels)))\n",
    "\n",
    "    base_model = InceptionV3(include_top=False,\n",
    "                   weights='imagenet',\n",
    "                   input_shape=(299,299,3)\n",
    "                            )\n",
    "    bn = BatchNormalization()(input_tensor)\n",
    "    x = Conv2D(3, kernel_size=(1,1), activation='relu', padding = \"same\")(bn)\n",
    "    x = base_model(x)\n",
    "    bn = BatchNormalization()(x)\n",
    "    x = Conv2D(128, kernel_size=(1,1), activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "#     output = Dense(n_out, activation='sigmoid')(x)\n",
    "    output = Dense(n_out, activation='sigmoid')(x)\n",
    "    model = Model(input_tensor, output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model(input_shape, n_out, channels):\n",
    "    input_tensor = Input(shape=(299,299,len(channels)))\n",
    "    bn = BatchNormalization()(input_tensor)\n",
    "    x = Conv2D(8, kernel_size=(3,3), activation='relu', padding = \"same\")(bn)\n",
    "    x = Conv2D(8, kernel_size=(3,3), activation='relu', padding = \"same\")(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2))(x)\n",
    "    x = Conv2D(16, kernel_size=(3,3), activation='relu', padding = \"same\")(x)\n",
    "    x = Conv2D(16, kernel_size=(3,3), activation='relu', padding = \"same\")(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2))(x)\n",
    "    x = Conv2D(32, kernel_size=(3,3), activation='relu', padding = \"same\")(x)\n",
    "    x = Conv2D(32, kernel_size=(3,3), activation='relu', padding = \"same\")(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2))(x)\n",
    "    x = Conv2D(64, kernel_size=(3,3), activation='relu', padding = \"same\")(x)\n",
    "    x = Conv2D(64, kernel_size=(3,3), activation='relu', padding = \"same\")(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2))(x)\n",
    "    x = Conv2D(128, kernel_size=(3,3), activation='relu', padding = \"same\")(x)\n",
    "    x = Conv2D(128, kernel_size=(3,3), activation='relu', padding = \"same\")(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2))(x)\n",
    "    x = Conv2D(256, kernel_size=(3,3), activation='relu', padding = \"valid\")(x)\n",
    "    x = Conv2D(256, kernel_size=(3,3), activation='relu', padding = \"valid\")(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "#     output = Dense(n_out, activation='sigmoid')(x)\n",
    "    output = Dense(n_out, activation=\"sigmoid\")(x)\n",
    "    model = Model(input_tensor, output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    #y_pred = K.round(y_pred)\n",
    "    y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    #y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1-K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31072,) (31072, 28)\n",
      "(27964,) (27964, 28) (3108,) (3108, 28)\n"
     ]
    }
   ],
   "source": [
    "# create callbacks list\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "epochs = 10; batch_size = 32;VAL_RATIO = .1;DEBUG = False\n",
    "# split data into train, valid\n",
    "paths, labels = getTrainDataset()\n",
    "\n",
    "# divide to \n",
    "keys = np.arange(paths.shape[0], dtype=np.int)  \n",
    "np.random.seed(SEED)\n",
    "np.random.shuffle(keys)\n",
    "lastTrainIndex = int((1-VAL_RATIO) * paths.shape[0])\n",
    "\n",
    "if DEBUG == True:  # use only small subset for debugging, Kaggle's RAM is limited\n",
    "    pathsTrain = paths[0:256]\n",
    "    labelsTrain = labels[0:256]\n",
    "    pathsVal = paths[lastTrainIndex:lastTrainIndex+256]\n",
    "    labelsVal = labels[lastTrainIndex:lastTrainIndex+256]\n",
    "    use_cache = True\n",
    "else:\n",
    "    pathsTrain = paths[0:lastTrainIndex]\n",
    "    labelsTrain = labels[0:lastTrainIndex]\n",
    "    pathsVal = paths[lastTrainIndex:]\n",
    "    labelsVal = labels[lastTrainIndex:]\n",
    "    use_cache = False\n",
    "\n",
    "print(paths.shape, labels.shape)\n",
    "print(pathsTrain.shape, labelsTrain.shape, pathsVal.shape, labelsVal.shape)\n",
    "use_cache = True\n",
    "channels = [\"green\", \"blue\", \"red\", \"yellow\"]\n",
    "tg = ProteinDataGenerator(pathsTrain, labelsTrain, batch_size, SHAPE, channels, use_cache=use_cache, augmentor = True)\n",
    "vg = ProteinDataGenerator(pathsVal, labelsVal, batch_size, SHAPE, channels, use_cache=use_cache, augmentor = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and valid datagens\n",
    "# train_generator = data_generator.create_train(\n",
    "#     train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=True)\n",
    "# validation_generator = data_generator.create_train(\n",
    "#     train_dataset_info[valid_indexes], 32, (SIZE,SIZE,3), augument=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('../working/InceptionV3.h5', monitor='val_f1', verbose=1, \n",
    "                             save_best_only=True, mode='max', save_weights_only = False)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_f1', factor=0.5, patience=10, \n",
    "                                   verbose=1, mode='max', epsilon=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_f1\", \n",
    "                      mode=\"max\", \n",
    "                      patience=20)\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "\n",
    "        pt_1 = K.clip(pt_1, 1e-3, .999)\n",
    "        pt_0 = K.clip(pt_0, 1e-3, .999)\n",
    "\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed\n",
    "def KerasFocalLoss(target, input):\n",
    "    \n",
    "    gamma = 2.\n",
    "    input = tf.cast(input, tf.float32)\n",
    "    \n",
    "    max_val = K.clip(-input, 0, 1)\n",
    "    loss = input - input * target + max_val + K.log(K.exp(-max_val) + K.exp(-input - max_val))\n",
    "    invprobs = tf.log_sigmoid(-input * (target * 2.0 - 1.0))\n",
    "    loss = K.exp(invprobs * gamma) * loss\n",
    "    \n",
    "    return K.mean(K.sum(loss, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 299, 299, 4)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 299, 299, 4)       16        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 299, 299, 8)       296       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 299, 299, 8)       584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 149, 149, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 149, 149, 16)      1168      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 149, 149, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 74, 74, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 74, 74, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 74, 74, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 37, 37, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 18, 18, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 18, 18, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 5, 5, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 28)                7196      \n",
      "=================================================================\n",
      "Total params: 1,449,980\n",
      "Trainable params: 1,449,972\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# warm up model\n",
    "import tensorflow as tf\n",
    "# with tf.device('/cpu:0'):\n",
    "model = simple_model(\n",
    "    input_shape=(SIZE,SIZE,len(channels)), \n",
    "    n_out=28, channels = channels)\n",
    "\n",
    "# for layer in model.layers:\n",
    "#     layer.trainable = False\n",
    "# model.layers[1].trainable = True\n",
    "# model.layers[2].trainable = True\n",
    "# model.layers[-1].trainable = True\n",
    "# model.layers[-2].trainable = True\n",
    "# model.layers[-3].trainable = True\n",
    "# model.layers[-4].trainable = True\n",
    "# model.layers[-5].trainable = True\n",
    "# model.layers[-6].trainable = True\n",
    "\n",
    "model.summary()\n",
    "# model = multi_gpu_model(model, gpus = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 299, 299, 4)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 299, 299, 4)       16        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 299, 299, 8)       296       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 299, 299, 8)       584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 149, 149, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 149, 149, 16)      1168      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 149, 149, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 74, 74, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 74, 74, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 74, 74, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 37, 37, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 18, 18, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 18, 18, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 5, 5, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 28)                7196      \n",
      "=================================================================\n",
      "Total params: 1,449,980\n",
      "Trainable params: 1,449,972\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=\"binary_crossentropy\", \n",
    "    optimizer=Adam(1e-03),\n",
    "    metrics=['binary_accuracy', f1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "874/874 [==============================] - 353s 403ms/step - loss: 0.1148 - binary_accuracy: 0.9601 - f1: 0.2571 - val_loss: 0.1174 - val_binary_accuracy: 0.9598 - val_f1: 0.2438\n",
      "\n",
      "Epoch 00001: val_f1 did not improve from 0.25719\n",
      "Epoch 2/100\n",
      "874/874 [==============================] - 337s 385ms/step - loss: 0.1165 - binary_accuracy: 0.9597 - f1: 0.2514 - val_loss: 0.1193 - val_binary_accuracy: 0.9585 - val_f1: 0.2388\n",
      "\n",
      "Epoch 00002: val_f1 did not improve from 0.25719\n",
      "Epoch 3/100\n",
      "874/874 [==============================] - 340s 389ms/step - loss: 0.1157 - binary_accuracy: 0.9599 - f1: 0.2537 - val_loss: 0.1176 - val_binary_accuracy: 0.9593 - val_f1: 0.2435\n",
      "\n",
      "Epoch 00003: val_f1 did not improve from 0.25719\n",
      "Epoch 4/100\n",
      "874/874 [==============================] - 313s 358ms/step - loss: 0.1152 - binary_accuracy: 0.9600 - f1: 0.2566 - val_loss: 0.1165 - val_binary_accuracy: 0.9589 - val_f1: 0.2571\n",
      "\n",
      "Epoch 00004: val_f1 did not improve from 0.25719\n",
      "Epoch 5/100\n",
      "874/874 [==============================] - 332s 379ms/step - loss: 0.1157 - binary_accuracy: 0.9600 - f1: 0.2564 - val_loss: 0.1181 - val_binary_accuracy: 0.9582 - val_f1: 0.2440\n",
      "\n",
      "Epoch 00005: val_f1 did not improve from 0.25719\n",
      "Epoch 6/100\n",
      "874/874 [==============================] - 311s 356ms/step - loss: 0.1161 - binary_accuracy: 0.9597 - f1: 0.2543 - val_loss: 0.1160 - val_binary_accuracy: 0.9594 - val_f1: 0.2490\n",
      "\n",
      "Epoch 00006: val_f1 did not improve from 0.25719\n",
      "Epoch 7/100\n",
      "874/874 [==============================] - 324s 371ms/step - loss: 0.1150 - binary_accuracy: 0.9603 - f1: 0.2570 - val_loss: 0.1177 - val_binary_accuracy: 0.9591 - val_f1: 0.2409\n",
      "\n",
      "Epoch 00007: val_f1 did not improve from 0.25719\n",
      "Epoch 8/100\n",
      "874/874 [==============================] - 336s 385ms/step - loss: 0.1153 - binary_accuracy: 0.9600 - f1: 0.2558 - val_loss: 0.1173 - val_binary_accuracy: 0.9592 - val_f1: 0.2504\n",
      "\n",
      "Epoch 00008: val_f1 did not improve from 0.25719\n",
      "Epoch 9/100\n",
      "874/874 [==============================] - 328s 375ms/step - loss: 0.1141 - binary_accuracy: 0.9605 - f1: 0.2600 - val_loss: 0.1151 - val_binary_accuracy: 0.9596 - val_f1: 0.2621\n",
      "\n",
      "Epoch 00009: val_f1 improved from 0.25719 to 0.26210, saving model to ../working/InceptionV3.h5\n",
      "Epoch 10/100\n",
      "874/874 [==============================] - 308s 352ms/step - loss: 0.1151 - binary_accuracy: 0.9601 - f1: 0.2567 - val_loss: 0.1167 - val_binary_accuracy: 0.9587 - val_f1: 0.2554\n",
      "\n",
      "Epoch 00010: val_f1 did not improve from 0.26210\n",
      "Epoch 11/100\n",
      "874/874 [==============================] - 324s 370ms/step - loss: 0.1152 - binary_accuracy: 0.9601 - f1: 0.2547 - val_loss: 0.1194 - val_binary_accuracy: 0.9579 - val_f1: 0.2364\n",
      "\n",
      "Epoch 00011: val_f1 did not improve from 0.26210\n",
      "Epoch 12/100\n",
      "874/874 [==============================] - 308s 353ms/step - loss: 0.1148 - binary_accuracy: 0.9600 - f1: 0.2567 - val_loss: 0.1184 - val_binary_accuracy: 0.9584 - val_f1: 0.2425\n",
      "\n",
      "Epoch 00012: val_f1 did not improve from 0.26210\n",
      "Epoch 13/100\n",
      "874/874 [==============================] - 305s 349ms/step - loss: 0.1148 - binary_accuracy: 0.9601 - f1: 0.2564 - val_loss: 0.1160 - val_binary_accuracy: 0.9590 - val_f1: 0.2551\n",
      "\n",
      "Epoch 00013: val_f1 did not improve from 0.26210\n",
      "Epoch 14/100\n",
      "874/874 [==============================] - 578s 661ms/step - loss: 0.1149 - binary_accuracy: 0.9603 - f1: 0.2585 - val_loss: 0.1190 - val_binary_accuracy: 0.9584 - val_f1: 0.2404\n",
      "\n",
      "Epoch 00014: val_f1 did not improve from 0.26210\n",
      "Epoch 15/100\n",
      "874/874 [==============================] - 330s 377ms/step - loss: 0.1148 - binary_accuracy: 0.9602 - f1: 0.2564 - val_loss: 0.1173 - val_binary_accuracy: 0.9590 - val_f1: 0.2549\n",
      "\n",
      "Epoch 00015: val_f1 did not improve from 0.26210\n",
      "Epoch 16/100\n",
      "874/874 [==============================] - 331s 378ms/step - loss: 0.1141 - binary_accuracy: 0.9603 - f1: 0.2592 - val_loss: 0.1186 - val_binary_accuracy: 0.9587 - val_f1: 0.2421\n",
      "\n",
      "Epoch 00016: val_f1 did not improve from 0.26210\n",
      "Epoch 17/100\n",
      "874/874 [==============================] - 305s 349ms/step - loss: 0.1156 - binary_accuracy: 0.9598 - f1: 0.2537 - val_loss: 0.1193 - val_binary_accuracy: 0.9585 - val_f1: 0.2477\n",
      "\n",
      "Epoch 00017: val_f1 did not improve from 0.26210\n",
      "Epoch 18/100\n",
      "874/874 [==============================] - 311s 356ms/step - loss: 0.1157 - binary_accuracy: 0.9600 - f1: 0.2540 - val_loss: 0.1168 - val_binary_accuracy: 0.9586 - val_f1: 0.2492\n",
      "\n",
      "Epoch 00018: val_f1 did not improve from 0.26210\n",
      "Epoch 19/100\n",
      "874/874 [==============================] - 287s 329ms/step - loss: 0.1147 - binary_accuracy: 0.9603 - f1: 0.2555 - val_loss: 0.1189 - val_binary_accuracy: 0.9585 - val_f1: 0.2535\n",
      "\n",
      "Epoch 00019: val_f1 did not improve from 0.26210\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 20/100\n",
      "874/874 [==============================] - 324s 370ms/step - loss: 0.1093 - binary_accuracy: 0.9621 - f1: 0.2718 - val_loss: 0.1131 - val_binary_accuracy: 0.9606 - val_f1: 0.2656\n",
      "\n",
      "Epoch 00020: val_f1 improved from 0.26210 to 0.26561, saving model to ../working/InceptionV3.h5\n",
      "Epoch 21/100\n",
      "874/874 [==============================] - 523s 599ms/step - loss: 0.1075 - binary_accuracy: 0.9625 - f1: 0.2758 - val_loss: 0.1136 - val_binary_accuracy: 0.9604 - val_f1: 0.2613\n",
      "\n",
      "Epoch 00021: val_f1 did not improve from 0.26561\n",
      "Epoch 22/100\n",
      "874/874 [==============================] - 306s 350ms/step - loss: 0.1064 - binary_accuracy: 0.9628 - f1: 0.2817 - val_loss: 0.1131 - val_binary_accuracy: 0.9603 - val_f1: 0.2635\n",
      "\n",
      "Epoch 00022: val_f1 did not improve from 0.26561\n",
      "Epoch 23/100\n",
      "874/874 [==============================] - 298s 341ms/step - loss: 0.1053 - binary_accuracy: 0.9631 - f1: 0.2834 - val_loss: 0.1125 - val_binary_accuracy: 0.9607 - val_f1: 0.2608\n",
      "\n",
      "Epoch 00023: val_f1 did not improve from 0.26561\n",
      "Epoch 24/100\n",
      "874/874 [==============================] - 328s 376ms/step - loss: 0.1045 - binary_accuracy: 0.9635 - f1: 0.2837 - val_loss: 0.1131 - val_binary_accuracy: 0.9600 - val_f1: 0.2675\n",
      "\n",
      "Epoch 00024: val_f1 improved from 0.26561 to 0.26746, saving model to ../working/InceptionV3.h5\n",
      "Epoch 25/100\n",
      "874/874 [==============================] - 305s 348ms/step - loss: 0.1035 - binary_accuracy: 0.9640 - f1: 0.2876 - val_loss: 0.1141 - val_binary_accuracy: 0.9607 - val_f1: 0.2612\n",
      "\n",
      "Epoch 00025: val_f1 did not improve from 0.26746\n",
      "Epoch 26/100\n",
      "874/874 [==============================] - 335s 383ms/step - loss: 0.1028 - binary_accuracy: 0.9641 - f1: 0.2886 - val_loss: 0.1132 - val_binary_accuracy: 0.9603 - val_f1: 0.2654\n",
      "\n",
      "Epoch 00026: val_f1 did not improve from 0.26746\n",
      "Epoch 27/100\n",
      "874/874 [==============================] - 332s 380ms/step - loss: 0.1029 - binary_accuracy: 0.9640 - f1: 0.2886 - val_loss: 0.1121 - val_binary_accuracy: 0.9601 - val_f1: 0.2646\n",
      "\n",
      "Epoch 00027: val_f1 did not improve from 0.26746\n",
      "Epoch 28/100\n",
      "874/874 [==============================] - 305s 349ms/step - loss: 0.1015 - binary_accuracy: 0.9644 - f1: 0.2943 - val_loss: 0.1126 - val_binary_accuracy: 0.9604 - val_f1: 0.2641\n",
      "\n",
      "Epoch 00028: val_f1 did not improve from 0.26746\n",
      "Epoch 29/100\n",
      "874/874 [==============================] - 326s 373ms/step - loss: 0.1010 - binary_accuracy: 0.9647 - f1: 0.2940 - val_loss: 0.1132 - val_binary_accuracy: 0.9611 - val_f1: 0.2673\n",
      "\n",
      "Epoch 00029: val_f1 did not improve from 0.26746\n",
      "Epoch 30/100\n",
      "874/874 [==============================] - 314s 359ms/step - loss: 0.1010 - binary_accuracy: 0.9648 - f1: 0.2948 - val_loss: 0.1130 - val_binary_accuracy: 0.9610 - val_f1: 0.2724\n",
      "\n",
      "Epoch 00030: val_f1 improved from 0.26746 to 0.27244, saving model to ../working/InceptionV3.h5\n",
      "Epoch 31/100\n",
      "874/874 [==============================] - 328s 376ms/step - loss: 0.0994 - binary_accuracy: 0.9651 - f1: 0.2979 - val_loss: 0.1138 - val_binary_accuracy: 0.9600 - val_f1: 0.2732\n",
      "\n",
      "Epoch 00031: val_f1 improved from 0.27244 to 0.27323, saving model to ../working/InceptionV3.h5\n",
      "Epoch 32/100\n",
      "874/874 [==============================] - 318s 364ms/step - loss: 0.0993 - binary_accuracy: 0.9654 - f1: 0.2985 - val_loss: 0.1129 - val_binary_accuracy: 0.9608 - val_f1: 0.2709\n",
      "\n",
      "Epoch 00032: val_f1 did not improve from 0.27323\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "874/874 [==============================] - 291s 333ms/step - loss: 0.0989 - binary_accuracy: 0.9654 - f1: 0.2994 - val_loss: 0.1134 - val_binary_accuracy: 0.9608 - val_f1: 0.2721\n",
      "\n",
      "Epoch 00033: val_f1 did not improve from 0.27323\n",
      "Epoch 34/100\n",
      "874/874 [==============================] - 325s 372ms/step - loss: 0.0992 - binary_accuracy: 0.9653 - f1: 0.2983 - val_loss: 0.1133 - val_binary_accuracy: 0.9613 - val_f1: 0.2656\n",
      "\n",
      "Epoch 00034: val_f1 did not improve from 0.27323\n",
      "Epoch 35/100\n",
      "874/874 [==============================] - 307s 351ms/step - loss: 0.0982 - binary_accuracy: 0.9657 - f1: 0.2993 - val_loss: 0.1130 - val_binary_accuracy: 0.9609 - val_f1: 0.2693\n",
      "\n",
      "Epoch 00035: val_f1 did not improve from 0.27323\n",
      "Epoch 36/100\n",
      "874/874 [==============================] - 320s 366ms/step - loss: 0.0981 - binary_accuracy: 0.9656 - f1: 0.3020 - val_loss: 0.1132 - val_binary_accuracy: 0.9606 - val_f1: 0.2682\n",
      "\n",
      "Epoch 00036: val_f1 did not improve from 0.27323\n",
      "Epoch 37/100\n",
      "874/874 [==============================] - 300s 343ms/step - loss: 0.0972 - binary_accuracy: 0.9660 - f1: 0.3030 - val_loss: 0.1126 - val_binary_accuracy: 0.9611 - val_f1: 0.2748\n",
      "\n",
      "Epoch 00037: val_f1 improved from 0.27323 to 0.27480, saving model to ../working/InceptionV3.h5\n",
      "Epoch 38/100\n",
      "874/874 [==============================] - 335s 383ms/step - loss: 0.0974 - binary_accuracy: 0.9659 - f1: 0.3025 - val_loss: 0.1136 - val_binary_accuracy: 0.9607 - val_f1: 0.2689\n",
      "\n",
      "Epoch 00038: val_f1 did not improve from 0.27480\n",
      "Epoch 39/100\n",
      "874/874 [==============================] - 302s 345ms/step - loss: 0.0971 - binary_accuracy: 0.9662 - f1: 0.3029 - val_loss: 0.1132 - val_binary_accuracy: 0.9610 - val_f1: 0.2743\n",
      "\n",
      "Epoch 00039: val_f1 did not improve from 0.27480\n",
      "Epoch 40/100\n",
      "874/874 [==============================] - 350s 400ms/step - loss: 0.0971 - binary_accuracy: 0.9662 - f1: 0.3033 - val_loss: 0.1142 - val_binary_accuracy: 0.9605 - val_f1: 0.2638\n",
      "\n",
      "Epoch 00040: val_f1 did not improve from 0.27480\n",
      "Epoch 41/100\n",
      "874/874 [==============================] - 290s 332ms/step - loss: 0.0956 - binary_accuracy: 0.9665 - f1: 0.3081 - val_loss: 0.1134 - val_binary_accuracy: 0.9613 - val_f1: 0.2687\n",
      "\n",
      "Epoch 00041: val_f1 did not improve from 0.27480\n",
      "Epoch 42/100\n",
      "874/874 [==============================] - 298s 341ms/step - loss: 0.0950 - binary_accuracy: 0.9668 - f1: 0.3082 - val_loss: 0.1139 - val_binary_accuracy: 0.9607 - val_f1: 0.2704\n",
      "\n",
      "Epoch 00042: val_f1 did not improve from 0.27480\n",
      "Epoch 43/100\n",
      "874/874 [==============================] - 286s 327ms/step - loss: 0.0954 - binary_accuracy: 0.9667 - f1: 0.3084 - val_loss: 0.1153 - val_binary_accuracy: 0.9604 - val_f1: 0.2684\n",
      "\n",
      "Epoch 00043: val_f1 did not improve from 0.27480\n",
      "Epoch 44/100\n",
      "874/874 [==============================] - 305s 349ms/step - loss: 0.0947 - binary_accuracy: 0.9671 - f1: 0.3121 - val_loss: 0.1137 - val_binary_accuracy: 0.9608 - val_f1: 0.2653\n",
      "\n",
      "Epoch 00044: val_f1 did not improve from 0.27480\n",
      "Epoch 45/100\n",
      "874/874 [==============================] - 306s 350ms/step - loss: 0.0943 - binary_accuracy: 0.9671 - f1: 0.3095 - val_loss: 0.1167 - val_binary_accuracy: 0.9601 - val_f1: 0.2755\n",
      "\n",
      "Epoch 00045: val_f1 improved from 0.27480 to 0.27553, saving model to ../working/InceptionV3.h5\n",
      "Epoch 46/100\n",
      "874/874 [==============================] - 301s 344ms/step - loss: 0.0945 - binary_accuracy: 0.9673 - f1: 0.3110 - val_loss: 0.1144 - val_binary_accuracy: 0.9606 - val_f1: 0.2743\n",
      "\n",
      "Epoch 00046: val_f1 did not improve from 0.27553\n",
      "Epoch 47/100\n",
      "874/874 [==============================] - 314s 360ms/step - loss: 0.0945 - binary_accuracy: 0.9672 - f1: 0.3110 - val_loss: 0.1146 - val_binary_accuracy: 0.9606 - val_f1: 0.2731\n",
      "\n",
      "Epoch 00047: val_f1 did not improve from 0.27553\n",
      "Epoch 48/100\n",
      "874/874 [==============================] - 325s 371ms/step - loss: 0.0938 - binary_accuracy: 0.9673 - f1: 0.3134 - val_loss: 0.1162 - val_binary_accuracy: 0.9602 - val_f1: 0.2584\n",
      "\n",
      "Epoch 00048: val_f1 did not improve from 0.27553\n",
      "Epoch 49/100\n",
      "874/874 [==============================] - 465s 532ms/step - loss: 0.0940 - binary_accuracy: 0.9672 - f1: 0.3120 - val_loss: 0.1128 - val_binary_accuracy: 0.9605 - val_f1: 0.2730\n",
      "\n",
      "Epoch 00049: val_f1 did not improve from 0.27553\n",
      "Epoch 50/100\n",
      "874/874 [==============================] - 321s 367ms/step - loss: 0.0924 - binary_accuracy: 0.9678 - f1: 0.3142 - val_loss: 0.1153 - val_binary_accuracy: 0.9603 - val_f1: 0.2704\n",
      "\n",
      "Epoch 00050: val_f1 did not improve from 0.27553\n",
      "Epoch 51/100\n",
      "874/874 [==============================] - 291s 334ms/step - loss: 0.0925 - binary_accuracy: 0.9677 - f1: 0.3161 - val_loss: 0.1142 - val_binary_accuracy: 0.9610 - val_f1: 0.2766\n",
      "\n",
      "Epoch 00051: val_f1 improved from 0.27553 to 0.27660, saving model to ../working/InceptionV3.h5\n",
      "Epoch 52/100\n",
      "874/874 [==============================] - 321s 368ms/step - loss: 0.0921 - binary_accuracy: 0.9677 - f1: 0.3172 - val_loss: 0.1136 - val_binary_accuracy: 0.9614 - val_f1: 0.2796\n",
      "\n",
      "Epoch 00052: val_f1 improved from 0.27660 to 0.27957, saving model to ../working/InceptionV3.h5\n",
      "Epoch 53/100\n",
      "874/874 [==============================] - 324s 370ms/step - loss: 0.0913 - binary_accuracy: 0.9681 - f1: 0.3198 - val_loss: 0.1134 - val_binary_accuracy: 0.9607 - val_f1: 0.2726\n",
      "\n",
      "Epoch 00053: val_f1 did not improve from 0.27957\n",
      "Epoch 54/100\n",
      "874/874 [==============================] - 298s 341ms/step - loss: 0.0924 - binary_accuracy: 0.9677 - f1: 0.3177 - val_loss: 0.1161 - val_binary_accuracy: 0.9609 - val_f1: 0.2751\n",
      "\n",
      "Epoch 00054: val_f1 did not improve from 0.27957\n",
      "Epoch 55/100\n",
      "874/874 [==============================] - 297s 339ms/step - loss: 0.0908 - binary_accuracy: 0.9683 - f1: 0.3200 - val_loss: 0.1140 - val_binary_accuracy: 0.9607 - val_f1: 0.2751\n",
      "\n",
      "Epoch 00055: val_f1 did not improve from 0.27957\n",
      "Epoch 56/100\n",
      "874/874 [==============================] - 299s 342ms/step - loss: 0.0904 - binary_accuracy: 0.9685 - f1: 0.3227 - val_loss: 0.1153 - val_binary_accuracy: 0.9599 - val_f1: 0.2689\n",
      "\n",
      "Epoch 00056: val_f1 did not improve from 0.27957\n",
      "Epoch 57/100\n",
      "874/874 [==============================] - 326s 373ms/step - loss: 0.0909 - binary_accuracy: 0.9684 - f1: 0.3215 - val_loss: 0.1142 - val_binary_accuracy: 0.9603 - val_f1: 0.2711\n",
      "\n",
      "Epoch 00057: val_f1 did not improve from 0.27957\n",
      "Epoch 58/100\n",
      "874/874 [==============================] - 297s 340ms/step - loss: 0.0904 - binary_accuracy: 0.9685 - f1: 0.3221 - val_loss: 0.1136 - val_binary_accuracy: 0.9602 - val_f1: 0.2713\n",
      "\n",
      "Epoch 00058: val_f1 did not improve from 0.27957\n",
      "Epoch 59/100\n",
      "874/874 [==============================] - 336s 384ms/step - loss: 0.0896 - binary_accuracy: 0.9685 - f1: 0.3250 - val_loss: 0.1163 - val_binary_accuracy: 0.9608 - val_f1: 0.2747\n",
      "\n",
      "Epoch 00059: val_f1 did not improve from 0.27957\n",
      "Epoch 60/100\n",
      "874/874 [==============================] - 309s 354ms/step - loss: 0.0898 - binary_accuracy: 0.9688 - f1: 0.3242 - val_loss: 0.1155 - val_binary_accuracy: 0.9606 - val_f1: 0.2773\n",
      "\n",
      "Epoch 00060: val_f1 did not improve from 0.27957\n",
      "Epoch 61/100\n",
      "874/874 [==============================] - 311s 356ms/step - loss: 0.0895 - binary_accuracy: 0.9689 - f1: 0.3225 - val_loss: 0.1165 - val_binary_accuracy: 0.9606 - val_f1: 0.2797\n",
      "\n",
      "Epoch 00061: val_f1 improved from 0.27957 to 0.27974, saving model to ../working/InceptionV3.h5\n",
      "Epoch 62/100\n",
      "874/874 [==============================] - 513s 587ms/step - loss: 0.0889 - binary_accuracy: 0.9690 - f1: 0.3275 - val_loss: 0.1146 - val_binary_accuracy: 0.9599 - val_f1: 0.2741\n",
      "\n",
      "Epoch 00062: val_f1 did not improve from 0.27974\n",
      "Epoch 63/100\n",
      "874/874 [==============================] - 308s 353ms/step - loss: 0.0888 - binary_accuracy: 0.9689 - f1: 0.3289 - val_loss: 0.1157 - val_binary_accuracy: 0.9611 - val_f1: 0.2719\n",
      "\n",
      "Epoch 00063: val_f1 did not improve from 0.27974\n",
      "Epoch 64/100\n",
      "874/874 [==============================] - 296s 339ms/step - loss: 0.0889 - binary_accuracy: 0.9693 - f1: 0.3285 - val_loss: 0.1165 - val_binary_accuracy: 0.9610 - val_f1: 0.2758\n",
      "\n",
      "Epoch 00064: val_f1 did not improve from 0.27974\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "874/874 [==============================] - 303s 346ms/step - loss: 0.0885 - binary_accuracy: 0.9692 - f1: 0.3269 - val_loss: 0.1160 - val_binary_accuracy: 0.9611 - val_f1: 0.2790\n",
      "\n",
      "Epoch 00065: val_f1 did not improve from 0.27974\n",
      "Epoch 66/100\n",
      "874/874 [==============================] - 291s 332ms/step - loss: 0.0881 - binary_accuracy: 0.9694 - f1: 0.3268 - val_loss: 0.1158 - val_binary_accuracy: 0.9609 - val_f1: 0.2701\n",
      "\n",
      "Epoch 00066: val_f1 did not improve from 0.27974\n",
      "Epoch 67/100\n",
      "874/874 [==============================] - 318s 364ms/step - loss: 0.0876 - binary_accuracy: 0.9697 - f1: 0.3299 - val_loss: 0.1186 - val_binary_accuracy: 0.9603 - val_f1: 0.2706\n",
      "\n",
      "Epoch 00067: val_f1 did not improve from 0.27974\n",
      "Epoch 68/100\n",
      "874/874 [==============================] - 300s 343ms/step - loss: 0.0874 - binary_accuracy: 0.9697 - f1: 0.3319 - val_loss: 0.1150 - val_binary_accuracy: 0.9610 - val_f1: 0.2731\n",
      "\n",
      "Epoch 00068: val_f1 did not improve from 0.27974\n",
      "Epoch 69/100\n",
      "874/874 [==============================] - 316s 361ms/step - loss: 0.0874 - binary_accuracy: 0.9697 - f1: 0.3298 - val_loss: 0.1175 - val_binary_accuracy: 0.9608 - val_f1: 0.2732\n",
      "\n",
      "Epoch 00069: val_f1 did not improve from 0.27974\n",
      "Epoch 70/100\n",
      "874/874 [==============================] - 307s 351ms/step - loss: 0.0871 - binary_accuracy: 0.9697 - f1: 0.3303 - val_loss: 0.1165 - val_binary_accuracy: 0.9608 - val_f1: 0.2735\n",
      "\n",
      "Epoch 00070: val_f1 did not improve from 0.27974\n",
      "Epoch 71/100\n",
      "874/874 [==============================] - 342s 392ms/step - loss: 0.0867 - binary_accuracy: 0.9701 - f1: 0.3332 - val_loss: 0.1168 - val_binary_accuracy: 0.9611 - val_f1: 0.2722\n",
      "\n",
      "Epoch 00071: val_f1 did not improve from 0.27974\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 72/100\n",
      "874/874 [==============================] - 342s 392ms/step - loss: 0.0826 - binary_accuracy: 0.9714 - f1: 0.3434 - val_loss: 0.1159 - val_binary_accuracy: 0.9615 - val_f1: 0.2761\n",
      "\n",
      "Epoch 00072: val_f1 did not improve from 0.27974\n",
      "Epoch 73/100\n",
      "874/874 [==============================] - 337s 385ms/step - loss: 0.0809 - binary_accuracy: 0.9719 - f1: 0.3464 - val_loss: 0.1171 - val_binary_accuracy: 0.9606 - val_f1: 0.2743\n",
      "\n",
      "Epoch 00073: val_f1 did not improve from 0.27974\n",
      "Epoch 74/100\n",
      "874/874 [==============================] - 345s 395ms/step - loss: 0.0801 - binary_accuracy: 0.9722 - f1: 0.3481 - val_loss: 0.1169 - val_binary_accuracy: 0.9611 - val_f1: 0.2794\n",
      "\n",
      "Epoch 00074: val_f1 did not improve from 0.27974\n",
      "Epoch 75/100\n",
      "874/874 [==============================] - 310s 354ms/step - loss: 0.0793 - binary_accuracy: 0.9725 - f1: 0.3528 - val_loss: 0.1173 - val_binary_accuracy: 0.9610 - val_f1: 0.2764\n",
      "\n",
      "Epoch 00075: val_f1 did not improve from 0.27974\n",
      "Epoch 76/100\n",
      "874/874 [==============================] - 322s 368ms/step - loss: 0.0790 - binary_accuracy: 0.9727 - f1: 0.3523 - val_loss: 0.1169 - val_binary_accuracy: 0.9607 - val_f1: 0.2787\n",
      "\n",
      "Epoch 00076: val_f1 did not improve from 0.27974\n",
      "Epoch 77/100\n",
      "874/874 [==============================] - 309s 353ms/step - loss: 0.0782 - binary_accuracy: 0.9730 - f1: 0.3544 - val_loss: 0.1181 - val_binary_accuracy: 0.9609 - val_f1: 0.2757\n",
      "\n",
      "Epoch 00077: val_f1 did not improve from 0.27974\n",
      "Epoch 78/100\n",
      "874/874 [==============================] - 319s 365ms/step - loss: 0.0775 - binary_accuracy: 0.9732 - f1: 0.3590 - val_loss: 0.1193 - val_binary_accuracy: 0.9610 - val_f1: 0.2784\n",
      "\n",
      "Epoch 00078: val_f1 did not improve from 0.27974\n",
      "Epoch 79/100\n",
      "874/874 [==============================] - 327s 374ms/step - loss: 0.0774 - binary_accuracy: 0.9734 - f1: 0.3574 - val_loss: 0.1176 - val_binary_accuracy: 0.9606 - val_f1: 0.2736\n",
      "\n",
      "Epoch 00079: val_f1 did not improve from 0.27974\n",
      "Epoch 80/100\n",
      "874/874 [==============================] - 321s 367ms/step - loss: 0.0764 - binary_accuracy: 0.9738 - f1: 0.3565 - val_loss: 0.1175 - val_binary_accuracy: 0.9605 - val_f1: 0.2823\n",
      "\n",
      "Epoch 00080: val_f1 improved from 0.27974 to 0.28227, saving model to ../working/InceptionV3.h5\n",
      "Epoch 81/100\n",
      "874/874 [==============================] - 296s 339ms/step - loss: 0.0763 - binary_accuracy: 0.9737 - f1: 0.3594 - val_loss: 0.1182 - val_binary_accuracy: 0.9611 - val_f1: 0.2828\n",
      "\n",
      "Epoch 00081: val_f1 improved from 0.28227 to 0.28275, saving model to ../working/InceptionV3.h5\n",
      "Epoch 82/100\n",
      "874/874 [==============================] - 307s 352ms/step - loss: 0.0759 - binary_accuracy: 0.9740 - f1: 0.3611 - val_loss: 0.1181 - val_binary_accuracy: 0.9613 - val_f1: 0.2805\n",
      "\n",
      "Epoch 00082: val_f1 did not improve from 0.28275\n",
      "Epoch 83/100\n",
      "874/874 [==============================] - 325s 372ms/step - loss: 0.0755 - binary_accuracy: 0.9740 - f1: 0.3635 - val_loss: 0.1184 - val_binary_accuracy: 0.9607 - val_f1: 0.2817\n",
      "\n",
      "Epoch 00083: val_f1 did not improve from 0.28275\n",
      "Epoch 84/100\n",
      "874/874 [==============================] - 447s 511ms/step - loss: 0.0756 - binary_accuracy: 0.9741 - f1: 0.3610 - val_loss: 0.1182 - val_binary_accuracy: 0.9608 - val_f1: 0.2788\n",
      "\n",
      "Epoch 00084: val_f1 did not improve from 0.28275\n",
      "Epoch 85/100\n",
      "874/874 [==============================] - 295s 337ms/step - loss: 0.0754 - binary_accuracy: 0.9741 - f1: 0.3638 - val_loss: 0.1193 - val_binary_accuracy: 0.9608 - val_f1: 0.2737\n",
      "\n",
      "Epoch 00085: val_f1 did not improve from 0.28275\n",
      "Epoch 86/100\n",
      "874/874 [==============================] - 317s 363ms/step - loss: 0.0746 - binary_accuracy: 0.9745 - f1: 0.3636 - val_loss: 0.1182 - val_binary_accuracy: 0.9613 - val_f1: 0.2758\n",
      "\n",
      "Epoch 00086: val_f1 did not improve from 0.28275\n",
      "Epoch 87/100\n",
      "874/874 [==============================] - 335s 383ms/step - loss: 0.0736 - binary_accuracy: 0.9746 - f1: 0.3670 - val_loss: 0.1182 - val_binary_accuracy: 0.9606 - val_f1: 0.2830\n",
      "\n",
      "Epoch 00087: val_f1 improved from 0.28275 to 0.28296, saving model to ../working/InceptionV3.h5\n",
      "Epoch 88/100\n",
      "874/874 [==============================] - 322s 368ms/step - loss: 0.0740 - binary_accuracy: 0.9747 - f1: 0.3651 - val_loss: 0.1192 - val_binary_accuracy: 0.9605 - val_f1: 0.2779\n",
      "\n",
      "Epoch 00088: val_f1 did not improve from 0.28296\n",
      "Epoch 89/100\n",
      "874/874 [==============================] - 318s 364ms/step - loss: 0.0735 - binary_accuracy: 0.9747 - f1: 0.3687 - val_loss: 0.1201 - val_binary_accuracy: 0.9609 - val_f1: 0.2786\n",
      "\n",
      "Epoch 00089: val_f1 did not improve from 0.28296\n",
      "Epoch 90/100\n",
      "874/874 [==============================] - 302s 345ms/step - loss: 0.0735 - binary_accuracy: 0.9751 - f1: 0.3691 - val_loss: 0.1196 - val_binary_accuracy: 0.9608 - val_f1: 0.2760\n",
      "\n",
      "Epoch 00090: val_f1 did not improve from 0.28296\n",
      "Epoch 91/100\n",
      "874/874 [==============================] - 293s 336ms/step - loss: 0.0732 - binary_accuracy: 0.9752 - f1: 0.3708 - val_loss: 0.1209 - val_binary_accuracy: 0.9602 - val_f1: 0.2803\n",
      "\n",
      "Epoch 00091: val_f1 did not improve from 0.28296\n",
      "Epoch 92/100\n",
      "874/874 [==============================] - 328s 375ms/step - loss: 0.0729 - binary_accuracy: 0.9753 - f1: 0.3708 - val_loss: 0.1201 - val_binary_accuracy: 0.9606 - val_f1: 0.2766\n",
      "\n",
      "Epoch 00092: val_f1 did not improve from 0.28296\n",
      "Epoch 93/100\n",
      "874/874 [==============================] - 338s 386ms/step - loss: 0.0726 - binary_accuracy: 0.9752 - f1: 0.3722 - val_loss: 0.1217 - val_binary_accuracy: 0.9605 - val_f1: 0.2750\n",
      "\n",
      "Epoch 00093: val_f1 did not improve from 0.28296\n",
      "Epoch 94/100\n",
      "874/874 [==============================] - 314s 359ms/step - loss: 0.0721 - binary_accuracy: 0.9754 - f1: 0.3712 - val_loss: 0.1206 - val_binary_accuracy: 0.9610 - val_f1: 0.2821\n",
      "\n",
      "Epoch 00094: val_f1 did not improve from 0.28296\n",
      "Epoch 95/100\n",
      "874/874 [==============================] - 334s 383ms/step - loss: 0.0716 - binary_accuracy: 0.9756 - f1: 0.3741 - val_loss: 0.1212 - val_binary_accuracy: 0.9600 - val_f1: 0.2778\n",
      "\n",
      "Epoch 00095: val_f1 did not improve from 0.28296\n",
      "Epoch 96/100\n",
      "874/874 [==============================] - 311s 356ms/step - loss: 0.0715 - binary_accuracy: 0.9755 - f1: 0.3741 - val_loss: 0.1212 - val_binary_accuracy: 0.9607 - val_f1: 0.2766\n",
      "\n",
      "Epoch 00096: val_f1 did not improve from 0.28296\n",
      "Epoch 97/100\n",
      "874/874 [==============================] - 313s 359ms/step - loss: 0.0716 - binary_accuracy: 0.9755 - f1: 0.3736 - val_loss: 0.1204 - val_binary_accuracy: 0.9614 - val_f1: 0.2823\n",
      "\n",
      "Epoch 00097: val_f1 did not improve from 0.28296\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "874/874 [==============================] - 290s 332ms/step - loss: 0.0686 - binary_accuracy: 0.9767 - f1: 0.3804 - val_loss: 0.1224 - val_binary_accuracy: 0.9611 - val_f1: 0.2793\n",
      "\n",
      "Epoch 00098: val_f1 did not improve from 0.28296\n",
      "Epoch 99/100\n",
      "874/874 [==============================] - 332s 380ms/step - loss: 0.0677 - binary_accuracy: 0.9770 - f1: 0.3836 - val_loss: 0.1222 - val_binary_accuracy: 0.9603 - val_f1: 0.2813\n",
      "\n",
      "Epoch 00099: val_f1 did not improve from 0.28296\n",
      "Epoch 100/100\n",
      "874/874 [==============================] - 291s 333ms/step - loss: 0.0678 - binary_accuracy: 0.9771 - f1: 0.3843 - val_loss: 0.1218 - val_binary_accuracy: 0.9607 - val_f1: 0.2763\n",
      "\n",
      "Epoch 00100: val_f1 did not improve from 0.28296\n"
     ]
    }
   ],
   "source": [
    "hist =  model.fit_generator(\n",
    "        tg,\n",
    "        steps_per_epoch=np.ceil(float(len(pathsTrain)) / float(batch_size)),\n",
    "        validation_data=vg,\n",
    "        validation_steps=np.ceil(float(len(pathsVal)) / float(batch_size)),\n",
    "        epochs=100, \n",
    "        verbose=1,\n",
    "        callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x00000116E045D048>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001201A4D8908>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001201A52AD30>\n",
      "<keras.engine.training.Model object at 0x000001201A4D8C50>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000012022570C18>\n",
      "<keras.layers.core.Flatten object at 0x0000012020C3A588>\n",
      "<keras.layers.core.Dropout object at 0x000001201A67E978>\n",
      "<keras.layers.core.Dense object at 0x000001201A71FB00>\n",
      "<keras.layers.core.Dropout object at 0x00000120205AE6A0>\n",
      "<keras.layers.core.Dense object at 0x00000120205AE4A8>\n"
     ]
    }
   ],
   "source": [
    "# train all layers\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    layer.trainable = True\n",
    "model.compile(loss=focal_loss(),\n",
    "            optimizer=Adam(lr=1e-4),\n",
    "            metrics=['accuracy', f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1166/1165 [==============================] - 606s 520ms/step - loss: 13.8179 - acc: 0.4125 - f1: 0.1311 - val_loss: 13.0988 - val_acc: 0.4613 - val_f1: 0.1407\n",
      "\n",
      "Epoch 00001: val_f1 improved from 0.10443 to 0.14066, saving model to ../working/InceptionV3.h5\n",
      "Epoch 2/200\n",
      "1166/1165 [==============================] - 530s 455ms/step - loss: 12.4071 - acc: 0.4781 - f1: 0.1634 - val_loss: 12.4184 - val_acc: 0.5031 - val_f1: 0.1635\n",
      "\n",
      "Epoch 00002: val_f1 improved from 0.14066 to 0.16350, saving model to ../working/InceptionV3.h5\n",
      "Epoch 3/200\n",
      "1166/1165 [==============================] - 554s 475ms/step - loss: 11.2627 - acc: 0.5278 - f1: 0.1934 - val_loss: 12.4274 - val_acc: 0.4550 - val_f1: 0.1691\n",
      "\n",
      "Epoch 00003: val_f1 improved from 0.16350 to 0.16911, saving model to ../working/InceptionV3.h5\n",
      "Epoch 4/200\n",
      "1166/1165 [==============================] - 593s 508ms/step - loss: 9.4958 - acc: 0.5981 - f1: 0.2390 - val_loss: 13.9004 - val_acc: 0.4100 - val_f1: 0.1862\n",
      "\n",
      "Epoch 00004: val_f1 improved from 0.16911 to 0.18621, saving model to ../working/InceptionV3.h5\n",
      "Epoch 5/200\n",
      "1166/1165 [==============================] - 588s 504ms/step - loss: 8.0883 - acc: 0.6450 - f1: 0.2783 - val_loss: 14.0686 - val_acc: 0.5065 - val_f1: 0.1976\n",
      "\n",
      "Epoch 00005: val_f1 improved from 0.18621 to 0.19758, saving model to ../working/InceptionV3.h5\n",
      "Epoch 6/200\n",
      "1166/1165 [==============================] - 588s 504ms/step - loss: 6.6948 - acc: 0.6852 - f1: 0.3171 - val_loss: 14.5782 - val_acc: 0.4610 - val_f1: 0.2054\n",
      "\n",
      "Epoch 00006: val_f1 improved from 0.19758 to 0.20538, saving model to ../working/InceptionV3.h5\n",
      "Epoch 7/200\n",
      "1166/1165 [==============================] - 576s 494ms/step - loss: 5.0948 - acc: 0.7253 - f1: 0.3681 - val_loss: 17.3627 - val_acc: 0.4627 - val_f1: 0.2089\n",
      "\n",
      "Epoch 00007: val_f1 improved from 0.20538 to 0.20888, saving model to ../working/InceptionV3.h5\n",
      "Epoch 8/200\n",
      " 835/1165 [====================>.........] - ETA: 2:41 - loss: 4.3980 - acc: 0.7327 - f1: 0.3925"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 12\n",
    "hist =  model.fit_generator(\n",
    "        tg,\n",
    "        steps_per_epoch=np.ceil(float(len(pathsTrain)) / float(batch_size))/2,\n",
    "        validation_data=vg,\n",
    "        validation_steps=np.ceil(float(len(pathsVal)) / float(batch_size))/2,\n",
    "        epochs=200, \n",
    "        verbose=1,\n",
    "        callbacks=callbacks_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss=f1_loss,\n",
    "#             optimizer=Adam(lr=1e-4),\n",
    "#             metrics=['accuracy', f1])\n",
    "# hist =  model.fit_generator(\n",
    "#         tg,\n",
    "#         steps_per_epoch=np.ceil(float(len(pathsTrain)) / float(batch_size))/2,\n",
    "#         validation_data=vg,\n",
    "#         validation_steps=np.ceil(float(len(pathsVal)) / float(batch_size))/2,\n",
    "#         epochs=200, \n",
    "#         verbose=1,\n",
    "#         callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax[0].set_title('loss')\n",
    "ax[0].plot(hist.epoch, hist.history[\"loss\"], label=\"Train loss\")\n",
    "ax[0].plot(hist.epoch, hist.history[\"val_loss\"], label=\"Validation loss\")\n",
    "ax[1].set_title('acc')\n",
    "ax[1].plot(hist.epoch, hist.history[\"f1\"], label=\"Train F1\")\n",
    "ax[1].plot(hist.epoch, hist.history[\"val_f1\"], label=\"Validation F1\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "bestModel = load_model('../working/InceptionV3.h5', custom_objects={'f1': f1, 'f1_loss': f1_loss, 'focal_loss_fixed':focal_loss()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "lastFullValPred = np.empty((0, 28))\n",
    "lastFullValLabels = np.empty((0, 28))\n",
    "for i in tqdm(range(len(vg))): \n",
    "    im, lbl = vg[i]\n",
    "    scores = bestModel.predict(im)\n",
    "    lastFullValPred = np.append(lastFullValPred, scores, axis=0)\n",
    "    lastFullValLabels = np.append(lastFullValLabels, lbl, axis=0)\n",
    "print(lastFullValPred.shape, lastFullValLabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score as off1\n",
    "rng = np.arange(0, 1, 0.001)\n",
    "f1s = np.zeros((rng.shape[0], 28))\n",
    "for j,t in enumerate(tqdm(rng)):\n",
    "    for i in range(28):\n",
    "        p = np.array(lastFullValPred[:,i]>t, dtype=np.int8)\n",
    "        scoref1 = off1(lastFullValLabels[:,i], p, average='binary')\n",
    "        f1s[j,i] = scoref1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Individual F1-scores for each class:')\n",
    "print(np.max(f1s, axis=0))\n",
    "print('Macro F1-score CV =', np.mean(np.max(f1s, axis=0)))\n",
    "plt.plot(rng, f1s)\n",
    "T = np.empty(28)\n",
    "for i in range(28):\n",
    "    T[i] = rng[np.where(f1s[:,i] == np.max(f1s[:,i]))[0][0]]\n",
    "print('Probability threshold maximizing CV F1-score for each class:')\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathsTest, labelsTest = getTestDataset()\n",
    "\n",
    "testg = ProteinDataGenerator(pathsTest, labelsTest, batch_size, SHAPE, channels)\n",
    "submit = pd.read_csv(DIR + '/sample_submission.csv')\n",
    "P = np.zeros((pathsTest.shape[0], 28))\n",
    "for i in tqdm(range(len(testg))):\n",
    "    images, labels = testg[i]\n",
    "    score = bestModel.predict(images)\n",
    "    P[i*batch_size:i*batch_size+score.shape[0]] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP = np.array(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "\n",
    "for row in tqdm(range(submit.shape[0])):\n",
    "    \n",
    "    str_label = ''\n",
    "    \n",
    "    for col in range(PP.shape[1]):\n",
    "        if(PP[row, col] < T[col]):\n",
    "            str_label += ''\n",
    "        else:\n",
    "            str_label += str(col) + ' '\n",
    "    prediction.append(str_label.strip())\n",
    "    \n",
    "submit['Predicted'] = np.array(prediction)\n",
    "submit.to_csv('transfer_1x1conv_aug_focal_loss.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# pathsTest, labelsTest = getTestDataset()\n",
    "\n",
    "# testg = ProteinDataGenerator(pathsTest, labelsTest, batch_size, SHAPE)\n",
    "# submit = pd.read_csv(DIR + '/sample_submission.csv')\n",
    "# P = np.zeros((pathsTest.shape[0], 28))\n",
    "# for i in tqdm(range(len(testg))):\n",
    "#     images, labels = testg[i]\n",
    "#     score = bestModel.predict(images)\n",
    "#     P[i*batch_size:i*batch_size+score.shape[0]] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PP = np.array(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = []\n",
    "\n",
    "# for row in tqdm(range(submit.shape[0])):\n",
    "    \n",
    "#     str_label = ''\n",
    "    \n",
    "#     for col in range(PP.shape[1]):\n",
    "#         if(PP[row, col] < .2):   # to account for losing TP is more costly than decreasing FP\n",
    "#             #print(PP[row])\n",
    "#             str_label += ''\n",
    "#         else:\n",
    "#             str_label += str(col) + ' '\n",
    "#     prediction.append(str_label.strip())\n",
    "    \n",
    "# submit['Predicted'] = np.array(prediction)\n",
    "# submit.to_csv('datagenerator_model_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
