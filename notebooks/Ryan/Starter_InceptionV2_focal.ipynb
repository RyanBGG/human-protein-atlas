{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "import keras\n",
    "import warnings\n",
    "from keras.utils import Sequence\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SIZE = 299\n",
    "SEED = 777\n",
    "THRESHOLD = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset info\n",
    "DIR = '../input/'\n",
    "data = pd.read_csv('../input/train.csv')\n",
    "\n",
    "# train_dataset_info = []\n",
    "# for name, labels in zip(data['Id'], data['Target'].str.split(' ')):\n",
    "#     train_dataset_info.append({\n",
    "#         'path':os.path.join(path_to_train, name),\n",
    "#         'labels':np.array([int(label) for label in labels])})\n",
    "# train_dataset_info = np.array(train_dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainDataset():\n",
    "    \n",
    "    path_to_train = DIR + '/train/'\n",
    "    data = pd.read_csv(DIR + '/train.csv')\n",
    "\n",
    "    paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for name, lbl in zip(data['Id'], data['Target'].str.split(' ')):\n",
    "        y = np.zeros(28)\n",
    "        for key in lbl:\n",
    "            y[int(key)] = 1\n",
    "        paths.append(os.path.join(path_to_train, name))\n",
    "        labels.append(y)\n",
    "\n",
    "    return np.array(paths), np.array(labels)\n",
    "\n",
    "def getTestDataset():\n",
    "    \n",
    "    path_to_test = DIR + '/test/'\n",
    "    data = pd.read_csv(DIR + '/sample_submission.csv')\n",
    "\n",
    "    paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for name in data['Id']:\n",
    "        y = np.ones(28)\n",
    "        paths.append(os.path.join(path_to_test, name))\n",
    "        labels.append(y)\n",
    "\n",
    "    return np.array(paths), np.array(labels)\n",
    "paths, labels = getTrainDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credits: https://github.com/keras-team/keras/blob/master/keras/utils/data_utils.py#L302\n",
    "# credits: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "\n",
    "class ProteinDataGenerator(keras.utils.Sequence):\n",
    "            \n",
    "    def __init__(self, paths, labels, batch_size, shape, shuffle = False, use_cache = False):\n",
    "        self.paths, self.labels = paths, labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shape = shape\n",
    "        self.shuffle = shuffle\n",
    "        self.use_cache = use_cache\n",
    "        if use_cache == True:\n",
    "            self.cache = np.zeros((paths.shape[0], shape[0], shape[1], shape[2]))\n",
    "            self.is_cached = np.zeros((paths.shape[0]))\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.paths) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        indexes = self.indexes[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "\n",
    "        paths = self.paths[indexes]\n",
    "        X = np.zeros((paths.shape[0], self.shape[0], self.shape[1], self.shape[2]))\n",
    "        # Generate data\n",
    "        if self.use_cache == True:\n",
    "            X = self.cache[indexes]\n",
    "            for i, path in enumerate(paths[np.where(self.is_cached[indexes] == 0)]):\n",
    "                image = self.__load_image(path)\n",
    "                self.is_cached[indexes[i]] = 1\n",
    "                self.cache[indexes[i]] = image\n",
    "                X[i] = image\n",
    "        else:\n",
    "            for i, path in enumerate(paths):\n",
    "                X[i] = self.__load_image(path)\n",
    "\n",
    "        y = self.labels[indexes]\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        # Updates indexes after each epoch\n",
    "        self.indexes = np.arange(len(self.paths))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Create a generator that iterate over the Sequence.\"\"\"\n",
    "        for item in (self[i] for i in range(len(self))):\n",
    "            item = self.augment(item)\n",
    "            yield item\n",
    "            \n",
    "    def __load_image(self, path):\n",
    "        R = Image.open(path + '_red.png')\n",
    "        G = Image.open(path + '_green.png')\n",
    "        B = Image.open(path + '_blue.png')\n",
    "        Y = Image.open(path + '_yellow.png')\n",
    "\n",
    "        im = np.stack((\n",
    "            np.array(R), \n",
    "            np.array(G), \n",
    "            np.array(B),\n",
    "            np.array(Y)\n",
    "        ), -1)\n",
    "        im = cv2.resize(im, (SIZE,SIZE))\n",
    "        im = np.divide(im, 255)\n",
    "        return im\n",
    "    def augment(self, image):\n",
    "        augment_img = iaa.Sequential([\n",
    "            iaa.OneOf([\n",
    "                iaa.Affine(rotate=0),\n",
    "                iaa.Affine(rotate=90),\n",
    "                iaa.Affine(rotate=180),\n",
    "                iaa.Affine(rotate=270),\n",
    "                iaa.Fliplr(0.5),\n",
    "                iaa.Flipud(0.5),\n",
    "            ])], random_order=True)\n",
    "\n",
    "        image_aug = augment_img.augment_image(image)\n",
    "        return image_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE = (299, 299, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class data_generator:\n",
    "    \n",
    "#     def create_train(dataset_info, batch_size, shape, augument=True):\n",
    "#         assert shape[2] == 3\n",
    "#         while True:\n",
    "#             dataset_info = shuffle(dataset_info)\n",
    "#             for start in range(0, len(dataset_info), batch_size):\n",
    "#                 end = min(start + batch_size, len(dataset_info))\n",
    "#                 batch_images = []\n",
    "#                 X_train_batch = dataset_info[start:end]\n",
    "#                 batch_labels = np.zeros((len(X_train_batch), 28))\n",
    "#                 for i in range(len(X_train_batch)):\n",
    "#                     image = data_generator.load_image(\n",
    "#                         X_train_batch[i]['path'], shape)   \n",
    "#                     if augument:\n",
    "#                         image = data_generator.augment(image)\n",
    "#                     batch_images.append(image/255.)\n",
    "#                     batch_labels[i][X_train_batch[i]['labels']] = 1\n",
    "#                 yield np.array(batch_images, np.float32), batch_labels\n",
    "\n",
    "#     def load_image(path, shape):\n",
    "#         image_red_ch = Image.open(path+'_red.png')\n",
    "#         image_yellow_ch = Image.open(path+'_yellow.png')\n",
    "#         image_green_ch = Image.open(path+'_green.png')\n",
    "#         image_blue_ch = Image.open(path+'_blue.png')\n",
    "#         image = np.stack((\n",
    "#         np.array(image_red_ch), \n",
    "#         np.array(image_green_ch), \n",
    "#         np.array(image_blue_ch)), -1)\n",
    "#         image = cv2.resize(image, (shape[0], shape[1]))\n",
    "#         return image\n",
    "\n",
    "#     def augment(image):\n",
    "#         augment_img = iaa.Sequential([\n",
    "#             iaa.OneOf([\n",
    "#                 iaa.Affine(rotate=0),\n",
    "#                 iaa.Affine(rotate=90),\n",
    "#                 iaa.Affine(rotate=180),\n",
    "#                 iaa.Affine(rotate=270),\n",
    "#                 iaa.Fliplr(0.5),\n",
    "#                 iaa.Flipud(0.5),\n",
    "#             ])], random_order=True)\n",
    "\n",
    "#         image_aug = augment_img.augment_image(image)\n",
    "#         return image_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D, BatchNormalization, Input, Conv2D, MaxPooling2D\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam \n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_out):\n",
    "    input_tensor = Input(shape=(299,299,4))\n",
    "\n",
    "    base_model = InceptionV3(include_top=False,\n",
    "                   weights='imagenet',\n",
    "                   input_shape=(299,299,3)\n",
    "                            )\n",
    "    bn = BatchNormalization()(input_tensor)\n",
    "    x = Conv2D(3, kernel_size=(1,1), activation='relu', padding = \"same\")(bn)\n",
    "    x = base_model(x)\n",
    "    x = Conv2D(128, kernel_size=(3,3), activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(n_out, activation='sigmoid')(x)\n",
    "    model = Model(input_tensor, output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    #y_pred = K.round(y_pred)\n",
    "    y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31072,) (31072, 28)\n",
      "(27964,) (27964, 28) (3108,) (3108, 28)\n"
     ]
    }
   ],
   "source": [
    "# create callbacks list\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "epochs = 10; batch_size = 32;VAL_RATIO = .1;DEBUG = False\n",
    "# split data into train, valid\n",
    "paths, labels = getTrainDataset()\n",
    "\n",
    "# divide to \n",
    "keys = np.arange(paths.shape[0], dtype=np.int)  \n",
    "np.random.seed(SEED)\n",
    "np.random.shuffle(keys)\n",
    "lastTrainIndex = int((1-VAL_RATIO) * paths.shape[0])\n",
    "\n",
    "if DEBUG == True:  # use only small subset for debugging, Kaggle's RAM is limited\n",
    "    pathsTrain = paths[0:256]\n",
    "    labelsTrain = labels[0:256]\n",
    "    pathsVal = paths[lastTrainIndex:lastTrainIndex+256]\n",
    "    labelsVal = labels[lastTrainIndex:lastTrainIndex+256]\n",
    "    use_cache = True\n",
    "else:\n",
    "    pathsTrain = paths[0:lastTrainIndex]\n",
    "    labelsTrain = labels[0:lastTrainIndex]\n",
    "    pathsVal = paths[lastTrainIndex:]\n",
    "    labelsVal = labels[lastTrainIndex:]\n",
    "    use_cache = False\n",
    "\n",
    "print(paths.shape, labels.shape)\n",
    "print(pathsTrain.shape, labelsTrain.shape, pathsVal.shape, labelsVal.shape)\n",
    "use_cache = True\n",
    "tg = ProteinDataGenerator(pathsTrain, labelsTrain, batch_size, SHAPE, use_cache=use_cache)\n",
    "vg = ProteinDataGenerator(pathsVal, labelsVal, batch_size, SHAPE, use_cache=use_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and valid datagens\n",
    "# train_generator = data_generator.create_train(\n",
    "#     train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=True)\n",
    "# validation_generator = data_generator.create_train(\n",
    "#     train_dataset_info[valid_indexes], 32, (SIZE,SIZE,3), augument=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('../working/InceptionV3.h5', monitor='val_f1', verbose=1, \n",
    "                             save_best_only=True, mode='max', save_weights_only = False)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_f1', factor=0.1, patience=3, \n",
    "                                   verbose=1, mode='max', epsilon=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_f1\", \n",
    "                      mode=\"max\", \n",
    "                      patience=6)\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Compatible with tensorflow backend\n",
    "'''\n",
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 299, 299, 4)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 299, 299, 4)       16        \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 299, 299, 3)       15        \n",
      "_________________________________________________________________\n",
      "inception_v3 (Model)         (None, 8, 8, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 6, 6, 128)         2359424   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              4719616   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 28)                28700     \n",
      "=================================================================\n",
      "Total params: 28,910,555\n",
      "Trainable params: 7,107,763\n",
      "Non-trainable params: 21,802,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# warm up model\n",
    "import tensorflow as tf\n",
    "# with tf.device('/cpu:0'):\n",
    "model = create_model(\n",
    "    input_shape=(SIZE,SIZE,4), \n",
    "    n_out=28)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "model.layers[1].trainable = True\n",
    "model.layers[2].trainable = True\n",
    "model.layers[-1].trainable = True\n",
    "model.layers[-2].trainable = True\n",
    "model.layers[-3].trainable = True\n",
    "model.layers[-4].trainable = True\n",
    "model.layers[-5].trainable = True\n",
    "model.layers[-6].trainable = True\n",
    "\n",
    "model.summary()\n",
    "# model = multi_gpu_model(model, gpus = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 299, 299, 4)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 299, 299, 4)       16        \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 299, 299, 3)       15        \n",
      "_________________________________________________________________\n",
      "inception_v3 (Model)         (None, 8, 8, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 6, 6, 128)         2359424   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              4719616   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 28)                28700     \n",
      "=================================================================\n",
      "Total params: 28,910,555\n",
      "Trainable params: 7,107,763\n",
      "Non-trainable params: 21,802,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=focal_loss(), \n",
    "    optimizer=Adam(1e-03),\n",
    "    metrics=['acc', f1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg = ProteinDataGenerator(pathsTrain, labelsTrain, batch_size, SHAPE, use_cache=use_cache)\n",
    "vg = ProteinDataGenerator(pathsVal, labelsVal, batch_size, SHAPE, use_cache=use_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "874/874 [==============================] - 874s 999ms/step - loss: 17.7333 - acc: 0.3322 - f1: 0.0902 - val_loss: 15.4056 - val_acc: 0.3967 - val_f1: 0.0808\n",
      "\n",
      "Epoch 00001: val_f1 improved from -inf to 0.08081, saving model to ../working/InceptionV3.h5\n",
      "Epoch 2/25\n",
      "874/874 [==============================] - 319s 365ms/step - loss: 15.1609 - acc: 0.3942 - f1: 0.0821 - val_loss: 15.2054 - val_acc: 0.4109 - val_f1: 0.0757\n",
      "\n",
      "Epoch 00002: val_f1 did not improve from 0.08081\n",
      "Epoch 3/25\n",
      "874/874 [==============================] - 309s 354ms/step - loss: 15.0737 - acc: 0.3857 - f1: 0.0840 - val_loss: 15.2773 - val_acc: 0.4041 - val_f1: 0.0715\n",
      "\n",
      "Epoch 00003: val_f1 did not improve from 0.08081\n",
      "Epoch 4/25\n",
      "874/874 [==============================] - 307s 352ms/step - loss: 15.0577 - acc: 0.3870 - f1: 0.0843 - val_loss: 15.2605 - val_acc: 0.4106 - val_f1: 0.0771\n",
      "\n",
      "Epoch 00004: val_f1 did not improve from 0.08081\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 5/25\n",
      "874/874 [==============================] - 301s 345ms/step - loss: 14.8626 - acc: 0.3803 - f1: 0.0878 - val_loss: 15.1966 - val_acc: 0.4093 - val_f1: 0.0850\n",
      "\n",
      "Epoch 00005: val_f1 improved from 0.08081 to 0.08500, saving model to ../working/InceptionV3.h5\n",
      "Epoch 6/25\n",
      "874/874 [==============================] - 314s 359ms/step - loss: 14.6901 - acc: 0.3599 - f1: 0.0924 - val_loss: 15.1794 - val_acc: 0.2831 - val_f1: 0.0868\n",
      "\n",
      "Epoch 00006: val_f1 improved from 0.08500 to 0.08683, saving model to ../working/InceptionV3.h5\n",
      "Epoch 7/25\n",
      "874/874 [==============================] - 306s 350ms/step - loss: 14.5604 - acc: 0.3580 - f1: 0.0964 - val_loss: 15.1779 - val_acc: 0.2957 - val_f1: 0.0861\n",
      "\n",
      "Epoch 00007: val_f1 did not improve from 0.08683\n",
      "Epoch 8/25\n",
      "874/874 [==============================] - 318s 364ms/step - loss: 14.4693 - acc: 0.3573 - f1: 0.0982 - val_loss: 15.2270 - val_acc: 0.3234 - val_f1: 0.0904\n",
      "\n",
      "Epoch 00008: val_f1 improved from 0.08683 to 0.09040, saving model to ../working/InceptionV3.h5\n",
      "Epoch 9/25\n",
      "874/874 [==============================] - 321s 368ms/step - loss: 14.3445 - acc: 0.3588 - f1: 0.1011 - val_loss: 15.1485 - val_acc: 0.3166 - val_f1: 0.0870\n",
      "\n",
      "Epoch 00009: val_f1 did not improve from 0.09040\n",
      "Epoch 10/25\n",
      "874/874 [==============================] - 308s 352ms/step - loss: 14.2499 - acc: 0.3625 - f1: 0.1035 - val_loss: 15.3181 - val_acc: 0.3243 - val_f1: 0.0882\n",
      "\n",
      "Epoch 00010: val_f1 did not improve from 0.09040\n",
      "Epoch 11/25\n",
      "874/874 [==============================] - 291s 333ms/step - loss: 14.1804 - acc: 0.3652 - f1: 0.1048 - val_loss: 15.2618 - val_acc: 0.2918 - val_f1: 0.0904\n",
      "\n",
      "Epoch 00011: val_f1 did not improve from 0.09040\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 12/25\n",
      "874/874 [==============================] - 318s 364ms/step - loss: 14.0093 - acc: 0.3752 - f1: 0.1074 - val_loss: 15.3121 - val_acc: 0.3012 - val_f1: 0.0904\n",
      "\n",
      "Epoch 00012: val_f1 did not improve from 0.09040\n",
      "Epoch 13/25\n",
      "874/874 [==============================] - 302s 346ms/step - loss: 14.0044 - acc: 0.3757 - f1: 0.1078 - val_loss: 15.3124 - val_acc: 0.3098 - val_f1: 0.0900\n",
      "\n",
      "Epoch 00013: val_f1 did not improve from 0.09040\n",
      "Epoch 14/25\n",
      "874/874 [==============================] - 312s 357ms/step - loss: 13.9851 - acc: 0.3745 - f1: 0.1084 - val_loss: 15.2821 - val_acc: 0.3044 - val_f1: 0.0911\n",
      "\n",
      "Epoch 00014: val_f1 improved from 0.09040 to 0.09114, saving model to ../working/InceptionV3.h5\n",
      "Epoch 15/25\n",
      "874/874 [==============================] - 302s 345ms/step - loss: 13.9734 - acc: 0.3752 - f1: 0.1085 - val_loss: 15.3532 - val_acc: 0.2931 - val_f1: 0.0914\n",
      "\n",
      "Epoch 00015: val_f1 improved from 0.09114 to 0.09143, saving model to ../working/InceptionV3.h5\n",
      "Epoch 16/25\n",
      "874/874 [==============================] - 300s 343ms/step - loss: 13.9485 - acc: 0.3776 - f1: 0.1093 - val_loss: 15.3235 - val_acc: 0.3037 - val_f1: 0.0916\n",
      "\n",
      "Epoch 00016: val_f1 improved from 0.09143 to 0.09156, saving model to ../working/InceptionV3.h5\n",
      "Epoch 17/25\n",
      "874/874 [==============================] - 313s 358ms/step - loss: 13.9445 - acc: 0.3751 - f1: 0.1087 - val_loss: 15.3135 - val_acc: 0.3037 - val_f1: 0.0908\n",
      "\n",
      "Epoch 00017: val_f1 did not improve from 0.09156\n",
      "Epoch 18/25\n",
      "874/874 [==============================] - 309s 354ms/step - loss: 13.9159 - acc: 0.3768 - f1: 0.1096 - val_loss: 15.3306 - val_acc: 0.2963 - val_f1: 0.0919\n",
      "\n",
      "Epoch 00018: val_f1 improved from 0.09156 to 0.09186, saving model to ../working/InceptionV3.h5\n",
      "Epoch 19/25\n",
      "874/874 [==============================] - 313s 358ms/step - loss: 13.9075 - acc: 0.3771 - f1: 0.1094 - val_loss: 15.3593 - val_acc: 0.3073 - val_f1: 0.0917\n",
      "\n",
      "Epoch 00019: val_f1 did not improve from 0.09186\n",
      "Epoch 20/25\n",
      "874/874 [==============================] - 304s 347ms/step - loss: 13.9241 - acc: 0.3785 - f1: 0.1101 - val_loss: 15.3941 - val_acc: 0.3008 - val_f1: 0.0916\n",
      "\n",
      "Epoch 00020: val_f1 did not improve from 0.09186\n",
      "Epoch 21/25\n",
      "874/874 [==============================] - 310s 354ms/step - loss: 13.9196 - acc: 0.3761 - f1: 0.1096 - val_loss: 15.4337 - val_acc: 0.3034 - val_f1: 0.0920\n",
      "\n",
      "Epoch 00021: val_f1 improved from 0.09186 to 0.09196, saving model to ../working/InceptionV3.h5\n",
      "Epoch 22/25\n",
      "874/874 [==============================] - 314s 359ms/step - loss: 13.8742 - acc: 0.3797 - f1: 0.1107 - val_loss: 15.4119 - val_acc: 0.3041 - val_f1: 0.0913\n",
      "\n",
      "Epoch 00022: val_f1 did not improve from 0.09196\n",
      "Epoch 23/25\n",
      "874/874 [==============================] - 308s 353ms/step - loss: 13.8733 - acc: 0.3761 - f1: 0.1107 - val_loss: 15.4412 - val_acc: 0.2992 - val_f1: 0.0922\n",
      "\n",
      "Epoch 00023: val_f1 improved from 0.09196 to 0.09224, saving model to ../working/InceptionV3.h5\n",
      "Epoch 24/25\n",
      "874/874 [==============================] - 314s 359ms/step - loss: 13.8487 - acc: 0.3790 - f1: 0.1110 - val_loss: 15.4534 - val_acc: 0.2979 - val_f1: 0.0920\n",
      "\n",
      "Epoch 00024: val_f1 did not improve from 0.09224\n",
      "Epoch 25/25\n",
      "874/874 [==============================] - 308s 352ms/step - loss: 13.8378 - acc: 0.3791 - f1: 0.1114 - val_loss: 15.4171 - val_acc: 0.3008 - val_f1: 0.0914\n",
      "\n",
      "Epoch 00025: val_f1 did not improve from 0.09224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x150a4ada630>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    tg,\n",
    "    steps_per_epoch=np.ceil(float(len(pathsTrain)) / float(batch_size)),\n",
    "    validation_data=vg,\n",
    "    validation_steps=np.ceil(float(len(pathsVal)) / float(batch_size)),\n",
    "    epochs=25, \n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 = model.layers[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x00000137835F9C18>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001509EA1F780>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001509EABCA20>\n",
      "<keras.engine.training.Model object at 0x000001509EA0FBA8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000150A6A8BA58>\n",
      "<keras.layers.core.Flatten object at 0x00000150A51D8A20>\n",
      "<keras.layers.core.Dropout object at 0x000001509EC5CE48>\n",
      "<keras.layers.core.Dense object at 0x000001509EC5C4A8>\n",
      "<keras.layers.core.Dropout object at 0x00000150A4B77358>\n",
      "<keras.layers.core.Dense object at 0x00000150A4B774A8>\n"
     ]
    }
   ],
   "source": [
    "# train all layers\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    layer.trainable = True\n",
    "# model1 = multi_gpu_model(model1, gpus = 2)\n",
    "model.compile(loss=focal_loss(),\n",
    "            optimizer=Adam(lr=1e-4),\n",
    "            metrics=['accuracy', f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/874 [====>.........................] - ETA: 8:21 - loss: 1.9004 - acc: 0.7500 - f1: 0.39 - ETA: 7:06 - loss: 1.2960 - acc: 0.7969 - f1: 0.47 - ETA: 6:39 - loss: 1.0761 - acc: 0.7708 - f1: 0.51 - ETA: 6:27 - loss: 0.9373 - acc: 0.7578 - f1: 0.49 - ETA: 6:17 - loss: 0.7718 - acc: 0.7875 - f1: 0.50 - ETA: 6:12 - loss: 0.6926 - acc: 0.7604 - f1: 0.51 - ETA: 6:08 - loss: 0.6782 - acc: 0.7768 - f1: 0.51 - ETA: 6:05 - loss: 0.6326 - acc: 0.7734 - f1: 0.52 - ETA: 6:01 - loss: 0.6035 - acc: 0.7778 - f1: 0.52 - ETA: 6:00 - loss: 0.5577 - acc: 0.7750 - f1: 0.52 - ETA: 5:58 - loss: 0.5153 - acc: 0.7784 - f1: 0.51 - ETA: 5:56 - loss: 0.4804 - acc: 0.7812 - f1: 0.52 - ETA: 5:54 - loss: 0.4772 - acc: 0.7837 - f1: 0.53 - ETA: 5:52 - loss: 0.4558 - acc: 0.7835 - f1: 0.52 - ETA: 5:51 - loss: 0.4289 - acc: 0.7792 - f1: 0.51 - ETA: 5:49 - loss: 0.4305 - acc: 0.7793 - f1: 0.51 - ETA: 5:48 - loss: 0.4150 - acc: 0.7868 - f1: 0.51 - ETA: 5:48 - loss: 0.4013 - acc: 0.7865 - f1: 0.51 - ETA: 5:47 - loss: 0.3842 - acc: 0.7845 - f1: 0.52 - ETA: 5:46 - loss: 0.3958 - acc: 0.7797 - f1: 0.52 - ETA: 5:45 - loss: 0.3918 - acc: 0.7783 - f1: 0.52 - ETA: 5:45 - loss: 0.4151 - acc: 0.7770 - f1: 0.52 - ETA: 5:44 - loss: 0.4245 - acc: 0.7785 - f1: 0.53 - ETA: 5:43 - loss: 0.4161 - acc: 0.7799 - f1: 0.53 - ETA: 5:42 - loss: 0.4127 - acc: 0.7812 - f1: 0.53 - ETA: 5:42 - loss: 0.4277 - acc: 0.7825 - f1: 0.53 - ETA: 5:41 - loss: 0.4215 - acc: 0.7824 - f1: 0.53 - ETA: 5:41 - loss: 0.4078 - acc: 0.7846 - f1: 0.52 - ETA: 5:40 - loss: 0.3990 - acc: 0.7845 - f1: 0.53 - ETA: 5:39 - loss: 0.4086 - acc: 0.7865 - f1: 0.53 - ETA: 5:38 - loss: 0.4930 - acc: 0.7843 - f1: 0.53 - ETA: 5:38 - loss: 0.4997 - acc: 0.7822 - f1: 0.53 - ETA: 5:37 - loss: 0.5041 - acc: 0.7794 - f1: 0.53 - ETA: 5:37 - loss: 0.4950 - acc: 0.7794 - f1: 0.53 - ETA: 5:36 - loss: 0.4861 - acc: 0.7795 - f1: 0.54 - ETA: 5:35 - loss: 0.4934 - acc: 0.7795 - f1: 0.54 - ETA: 5:35 - loss: 0.5266 - acc: 0.7787 - f1: 0.54 - ETA: 5:34 - loss: 0.5274 - acc: 0.7780 - f1: 0.54 - ETA: 5:34 - loss: 0.5171 - acc: 0.7796 - f1: 0.54 - ETA: 5:33 - loss: 0.5223 - acc: 0.7812 - f1: 0.54 - ETA: 5:33 - loss: 0.5928 - acc: 0.7820 - f1: 0.54 - ETA: 5:32 - loss: 0.5874 - acc: 0.7827 - f1: 0.54 - ETA: 5:32 - loss: 0.5773 - acc: 0.7820 - f1: 0.54 - ETA: 5:31 - loss: 0.5893 - acc: 0.7834 - f1: 0.54 - ETA: 5:31 - loss: 0.5905 - acc: 0.7826 - f1: 0.54 - ETA: 5:30 - loss: 0.5847 - acc: 0.7806 - f1: 0.54 - ETA: 5:30 - loss: 0.5729 - acc: 0.7793 - f1: 0.54 - ETA: 5:30 - loss: 0.5620 - acc: 0.7754 - f1: 0.54 - ETA: 5:30 - loss: 0.5657 - acc: 0.7768 - f1: 0.54 - ETA: 5:29 - loss: 0.5626 - acc: 0.7775 - f1: 0.54 - ETA: 5:29 - loss: 0.5639 - acc: 0.7788 - f1: 0.54 - ETA: 5:28 - loss: 0.5555 - acc: 0.7800 - f1: 0.54 - ETA: 5:28 - loss: 0.5552 - acc: 0.7818 - f1: 0.54 - ETA: 5:27 - loss: 0.5471 - acc: 0.7778 - f1: 0.54 - ETA: 5:27 - loss: 0.5542 - acc: 0.7767 - f1: 0.54 - ETA: 5:26 - loss: 0.5610 - acc: 0.7773 - f1: 0.54 - ETA: 5:26 - loss: 0.5577 - acc: 0.7769 - f1: 0.54 - ETA: 5:25 - loss: 0.5502 - acc: 0.7786 - f1: 0.54 - ETA: 5:25 - loss: 0.5467 - acc: 0.7791 - f1: 0.54 - ETA: 5:24 - loss: 0.5531 - acc: 0.7781 - f1: 0.54 - ETA: 5:24 - loss: 0.5556 - acc: 0.7777 - f1: 0.54 - ETA: 5:23 - loss: 0.5493 - acc: 0.7762 - f1: 0.54 - ETA: 5:23 - loss: 0.5645 - acc: 0.7763 - f1: 0.54 - ETA: 5:22 - loss: 0.5714 - acc: 0.7764 - f1: 0.54 - ETA: 5:22 - loss: 0.5953 - acc: 0.7769 - f1: 0.54 - ETA: 5:21 - loss: 0.5881 - acc: 0.7775 - f1: 0.53 - ETA: 5:21 - loss: 0.5875 - acc: 0.7757 - f1: 0.53 - ETA: 5:20 - loss: 0.5841 - acc: 0.7771 - f1: 0.53 - ETA: 5:20 - loss: 0.5867 - acc: 0.7772 - f1: 0.53 - ETA: 5:19 - loss: 0.5850 - acc: 0.7768 - f1: 0.53 - ETA: 5:19 - loss: 0.5793 - acc: 0.7768 - f1: 0.53 - ETA: 5:18 - loss: 0.5750 - acc: 0.7769 - f1: 0.53 - ETA: 5:18 - loss: 0.5732 - acc: 0.7770 - f1: 0.54 - ETA: 5:18 - loss: 0.5680 - acc: 0.7770 - f1: 0.54 - ETA: 5:17 - loss: 0.5680 - acc: 0.7779 - f1: 0.54 - ETA: 5:17 - loss: 0.5691 - acc: 0.7763 - f1: 0.54 - ETA: 5:16 - loss: 0.5648 - acc: 0.7764 - f1: 0.54 - ETA: 5:16 - loss: 0.5602 - acc: 0.7764 - f1: 0.54 - ETA: 5:16 - loss: 0.5543 - acc: 0.7769 - f1: 0.54 - ETA: 5:15 - loss: 0.5499 - acc: 0.7766 - f1: 0.54 - ETA: 5:15 - loss: 0.5455 - acc: 0.7762 - f1: 0.54 - ETA: 5:14 - loss: 0.5408 - acc: 0.7763 - f1: 0.54 - ETA: 5:14 - loss: 0.5394 - acc: 0.7764 - f1: 0.54 - ETA: 5:14 - loss: 0.5369 - acc: 0.7764 - f1: 0.54 - ETA: 5:13 - loss: 0.5336 - acc: 0.7772 - f1: 0.54 - ETA: 5:13 - loss: 0.5321 - acc: 0.7776 - f1: 0.54 - ETA: 5:12 - loss: 0.5266 - acc: 0.7791 - f1: 0.54 - ETA: 5:12 - loss: 0.5214 - acc: 0.7791 - f1: 0.53 - ETA: 5:11 - loss: 0.5175 - acc: 0.7788 - f1: 0.53 - ETA: 5:11 - loss: 0.5212 - acc: 0.7788 - f1: 0.53 - ETA: 5:11 - loss: 0.5158 - acc: 0.7785 - f1: 0.53 - ETA: 5:10 - loss: 0.5152 - acc: 0.7799 - f1: 0.54 - ETA: 5:10 - loss: 0.5166 - acc: 0.7799 - f1: 0.54 - ETA: 5:09 - loss: 0.5115 - acc: 0.7796 - f1: 0.54 - ETA: 5:09 - loss: 0.5084 - acc: 0.7786 - f1: 0.54 - ETA: 5:09 - loss: 0.5081 - acc: 0.7777 - f1: 0.53 - ETA: 5:08 - loss: 0.5064 - acc: 0.7777 - f1: 0.53 - ETA: 5:08 - loss: 0.5030 - acc: 0.7790 - f1: 0.53 - ETA: 5:07 - loss: 0.4986 - acc: 0.7787 - f1: 0.53 - ETA: 5:07 - loss: 0.4939 - acc: 0.7791 - f1: 0.53 - ETA: 5:06 - loss: 0.4921 - acc: 0.7794 - f1: 0.53 - ETA: 5:06 - loss: 0.4924 - acc: 0.7800 - f1: 0.53 - ETA: 5:06 - loss: 0.4902 - acc: 0.7797 - f1: 0.53 - ETA: 5:05 - loss: 0.4871 - acc: 0.7791 - f1: 0.53 - ETA: 5:05 - loss: 0.4919 - acc: 0.7786 - f1: 0.53 - ETA: 5:04 - loss: 0.4903 - acc: 0.7792 - f1: 0.53 - ETA: 5:04 - loss: 0.4879 - acc: 0.7783 - f1: 0.53 - ETA: 5:04 - loss: 0.4857 - acc: 0.7781 - f1: 0.53 - ETA: 5:03 - loss: 0.4854 - acc: 0.7781 - f1: 0.53 - ETA: 5:03 - loss: 0.4824 - acc: 0.7790 - f1: 0.53 - ETA: 5:02 - loss: 0.4787 - acc: 0.7790 - f1: 0.53 - ETA: 5:02 - loss: 0.4762 - acc: 0.7793 - f1: 0.53 - ETA: 5:02 - loss: 0.4779 - acc: 0.7788 - f1: 0.53 - ETA: 5:01 - loss: 0.4755 - acc: 0.7796 - f1: 0.53 - ETA: 5:01 - loss: 0.4750 - acc: 0.7799 - f1: 0.53 - ETA: 5:00 - loss: 0.4771 - acc: 0.7796 - f1: 0.53 - ETA: 5:00 - loss: 0.4759 - acc: 0.7802 - f1: 0.53 - ETA: 5:00 - loss: 0.4737 - acc: 0.7794 - f1: 0.53 - ETA: 4:59 - loss: 0.4737 - acc: 0.7794 - f1: 0.53 - ETA: 4:59 - loss: 0.4792 - acc: 0.7794 - f1: 0.53 - ETA: 4:58 - loss: 0.4774 - acc: 0.7797 - f1: 0.53 - ETA: 4:58 - loss: 0.4758 - acc: 0.7792 - f1: 0.53 - ETA: 4:58 - loss: 0.4782 - acc: 0.7792 - f1: 0.53 - ETA: 4:57 - loss: 0.4783 - acc: 0.7805 - f1: 0.53 - ETA: 4:57 - loss: 0.4753 - acc: 0.7808 - f1: 0.53 - ETA: 4:56 - loss: 0.4906 - acc: 0.7805 - f1: 0.53 - ETA: 4:56 - loss: 0.4925 - acc: 0.7800 - f1: 0.54 - ETA: 4:55 - loss: 0.4914 - acc: 0.7798 - f1: 0.54 - ETA: 4:55 - loss: 0.4892 - acc: 0.7796 - f1: 0.53 - ETA: 4:55 - loss: 0.4897 - acc: 0.7796 - f1: 0.53 - ETA: 4:54 - loss: 0.4894 - acc: 0.7791 - f1: 0.53 - ETA: 4:54 - loss: 0.4863 - acc: 0.7798 - f1: 0.54 - ETA: 4:53 - loss: 0.4851 - acc: 0.7796 - f1: 0.53 - ETA: 4:53 - loss: 0.4842 - acc: 0.7803 - f1: 0.53 - ETA: 4:53 - loss: 0.4858 - acc: 0.7799 - f1: 0.53 - ETA: 4:52 - loss: 0.4849 - acc: 0.7801 - f1: 0.53 - ETA: 4:52 - loss: 0.4824 - acc: 0.7797 - f1: 0.53 - ETA: 4:51 - loss: 0.4824 - acc: 0.7799 - f1: 0.53 - ETA: 4:51 - loss: 0.4799 - acc: 0.7804 - f1: 0.54 - ETA: 4:51 - loss: 0.4814 - acc: 0.7799 - f1: 0.54 - ETA: 4:50 - loss: 0.4836 - acc: 0.7804 - f1: 0.54 - ETA: 4:50 - loss: 0.4868 - acc: 0.7795 - f1: 0.54 - ETA: 4:49 - loss: 0.4856 - acc: 0.7793 - f1: 0.54 - ETA: 4:49 - loss: 0.4872 - acc: 0.7791 - f1: 0.54 - ETA: 4:49 - loss: 0.4862 - acc: 0.7782 - f1: 0.54 - ETA: 4:48 - loss: 0.4848 - acc: 0.7783 - f1: 0.54 - ETA: 4:48 - loss: 0.4846 - acc: 0.7787 - f1: 0.54 - ETA: 4:47 - loss: 0.4839 - acc: 0.7796 - f1: 0.54 - ETA: 4:47 - loss: 0.4826 - acc: 0.7792 - f1: 0.54 - ETA: 4:47 - loss: 0.4817 - acc: 0.7794 - f1: 0.54 - ETA: 4:46 - loss: 0.4793 - acc: 0.7800 - f1: 0.53 - ETA: 4:46 - loss: 0.4774 - acc: 0.7806 - f1: 0.54 - ETA: 4:45 - loss: 0.4754 - acc: 0.7806 - f1: 0.53 - ETA: 4:45 - loss: 0.4843 - acc: 0.7798 - f1: 0.53 - ETA: 4:45 - loss: 0.4816 - acc: 0.7798 - f1: 0.53 - ETA: 4:44 - loss: 0.4868 - acc: 0.7790 - f1: 0.53 - ETA: 4:44 - loss: 0.4868 - acc: 0.7797 - f1: 0.5398\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/874 [======>.......................] - ETA: 4:43 - loss: 0.4902 - acc: 0.7805 - f1: 0.53 - ETA: 4:43 - loss: 0.4922 - acc: 0.7797 - f1: 0.54 - ETA: 4:43 - loss: 0.4892 - acc: 0.7793 - f1: 0.54 - ETA: 4:42 - loss: 0.4975 - acc: 0.7791 - f1: 0.54 - ETA: 4:42 - loss: 0.4971 - acc: 0.7789 - f1: 0.54 - ETA: 4:41 - loss: 0.4954 - acc: 0.7780 - f1: 0.54 - ETA: 4:41 - loss: 0.4942 - acc: 0.7788 - f1: 0.54 - ETA: 4:41 - loss: 0.4948 - acc: 0.7786 - f1: 0.54 - ETA: 4:40 - loss: 0.4947 - acc: 0.7788 - f1: 0.54 - ETA: 4:40 - loss: 0.4982 - acc: 0.7781 - f1: 0.54 - ETA: 4:40 - loss: 0.4983 - acc: 0.7779 - f1: 0.54 - ETA: 4:39 - loss: 0.4988 - acc: 0.7770 - f1: 0.54 - ETA: 4:39 - loss: 0.4970 - acc: 0.7767 - f1: 0.54 - ETA: 4:38 - loss: 0.4980 - acc: 0.7770 - f1: 0.54 - ETA: 4:38 - loss: 0.4975 - acc: 0.7769 - f1: 0.54 - ETA: 4:38 - loss: 0.4957 - acc: 0.7776 - f1: 0.54 - ETA: 4:37 - loss: 0.4956 - acc: 0.7778 - f1: 0.54 - ETA: 4:37 - loss: 0.4941 - acc: 0.7773 - f1: 0.54 - ETA: 4:36 - loss: 0.4922 - acc: 0.7773 - f1: 0.54 - ETA: 4:36 - loss: 0.4901 - acc: 0.7772 - f1: 0.54 - ETA: 4:36 - loss: 0.4894 - acc: 0.7781 - f1: 0.54 - ETA: 4:35 - loss: 0.4879 - acc: 0.7783 - f1: 0.53 - ETA: 4:35 - loss: 0.4872 - acc: 0.7781 - f1: 0.53 - ETA: 4:34 - loss: 0.4855 - acc: 0.7790 - f1: 0.54 - ETA: 4:34 - loss: 0.4832 - acc: 0.7788 - f1: 0.54 - ETA: 4:34 - loss: 0.4845 - acc: 0.7790 - f1: 0.54 - ETA: 4:33 - loss: 0.4864 - acc: 0.7789 - f1: 0.54 - ETA: 4:33 - loss: 0.4878 - acc: 0.7789 - f1: 0.54 - ETA: 4:32 - loss: 0.4861 - acc: 0.7792 - f1: 0.54 - ETA: 4:32 - loss: 0.4963 - acc: 0.7791 - f1: 0.54 - ETA: 4:32 - loss: 0.4959 - acc: 0.7789 - f1: 0.54 - ETA: 4:31 - loss: 0.4935 - acc: 0.7789 - f1: 0.54 - ETA: 4:31 - loss: 0.4915 - acc: 0.7791 - f1: 0.54 - ETA: 4:31 - loss: 0.4905 - acc: 0.7795 - f1: 0.54 - ETA: 4:30 - loss: 0.4936 - acc: 0.7796 - f1: 0.54 - ETA: 4:30 - loss: 0.4955 - acc: 0.7793 - f1: 0.54 - ETA: 4:29 - loss: 0.4981 - acc: 0.7796 - f1: 0.54 - ETA: 4:29 - loss: 0.4989 - acc: 0.7798 - f1: 0.54 - ETA: 4:28 - loss: 0.4980 - acc: 0.7798 - f1: 0.54 - ETA: 4:28 - loss: 0.4957 - acc: 0.7800 - f1: 0.54 - ETA: 4:28 - loss: 0.4952 - acc: 0.7801 - f1: 0.54 - ETA: 4:27 - loss: 0.4941 - acc: 0.7805 - f1: 0.54 - ETA: 4:27 - loss: 0.4927 - acc: 0.7806 - f1: 0.54 - ETA: 4:26 - loss: 0.4915 - acc: 0.7802 - f1: 0.54 - ETA: 4:26 - loss: 0.4898 - acc: 0.7800 - f1: 0.54 - ETA: 4:26 - loss: 0.4886 - acc: 0.7800 - f1: 0.54 - ETA: 4:25 - loss: 0.4939 - acc: 0.7796 - f1: 0.54 - ETA: 4:25 - loss: 0.4936 - acc: 0.7797 - f1: 0.54 - ETA: 4:24 - loss: 0.4956 - acc: 0.7802 - f1: 0.54 - ETA: 4:24 - loss: 0.4951 - acc: 0.7799 - f1: 0.54 - ETA: 4:24 - loss: 0.4998 - acc: 0.7794 - f1: 0.54 - ETA: 4:23 - loss: 0.5025 - acc: 0.7793 - f1: 0.54 - ETA: 4:23 - loss: 0.5008 - acc: 0.7792 - f1: 0.53 - ETA: 4:22 - loss: 0.5001 - acc: 0.7796 - f1: 0.53 - ETA: 4:22 - loss: 0.5018 - acc: 0.7805 - f1: 0.53 - ETA: 4:22 - loss: 0.5003 - acc: 0.7804 - f1: 0.53 - ETA: 4:21 - loss: 0.4999 - acc: 0.7795 - f1: 0.53 - ETA: 4:21 - loss: 0.5013 - acc: 0.7789 - f1: 0.53 - ETA: 4:20 - loss: 0.4999 - acc: 0.7788 - f1: 0.54 - ETA: 4:20 - loss: 0.4980 - acc: 0.7791 - f1: 0.54 - ETA: 4:20 - loss: 0.4979 - acc: 0.7788 - f1: 0.54 - ETA: 4:19 - loss: 0.4999 - acc: 0.7775 - f1: 0.53 - ETA: 4:19 - loss: 0.5005 - acc: 0.7774 - f1: 0.54 - ETA: 4:18 - loss: 0.5002 - acc: 0.7769 - f1: 0.54 - ETA: 4:18 - loss: 0.4992 - acc: 0.7776 - f1: 0.54 - ETA: 4:18 - loss: 0.4972 - acc: 0.7775 - f1: 0.54 - ETA: 4:17 - loss: 0.4957 - acc: 0.7775 - f1: 0.54 - ETA: 4:17 - loss: 0.4965 - acc: 0.7781 - f1: 0.54 - ETA: 4:16 - loss: 0.4951 - acc: 0.7778 - f1: 0.54 - ETA: 4:16 - loss: 0.4938 - acc: 0.7786 - f1: 0.54 - ETA: 4:16 - loss: 0.4923 - acc: 0.7791 - f1: 0.54 - ETA: 4:15 - loss: 0.4920 - acc: 0.7792 - f1: 0.5399"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-14e14a825dd5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     callbacks=callbacks_list)\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1424\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1425\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1426\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    189\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    190\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1218\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1220\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1221\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2661\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2662\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m                                 session)\n\u001b[1;32m-> 2631\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2632\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    tg,\n",
    "    steps_per_epoch=np.ceil(float(len(pathsTrain)) / float(batch_size)),\n",
    "    validation_data=vg,\n",
    "    validation_steps=np.ceil(float(len(pathsVal)) / float(batch_size)),\n",
    "    epochs=50, \n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "# bestModel = load_model('../working/InceptionV3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fullValGen = ProteinDataGenerator(paths[lastTrainIndex:], labels[lastTrainIndex:], BATCH_SIZE, SHAPE)\n",
    "#fullValPred = np.zeros((paths[lastTrainIndex:].shape[0], 28))\n",
    "#for i in tqdm(range(len(fullValGen))):\n",
    "bestModel = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 366/366 [06:14<00:00,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "pathsTest, labelsTest = getTestDataset()\n",
    "\n",
    "testg = ProteinDataGenerator(pathsTest, labelsTest, batch_size, SHAPE)\n",
    "submit = pd.read_csv(DIR + '/sample_submission.csv')\n",
    "P = np.zeros((pathsTest.shape[0], 28))\n",
    "for i in tqdm(range(len(testg))):\n",
    "    images, labels = testg[i]\n",
    "    score = bestModel.predict(images)\n",
    "    P[i*batch_size:i*batch_size+score.shape[0]] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP = np.array(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 11702/11702 [00:00<00:00, 60661.03it/s]\n"
     ]
    }
   ],
   "source": [
    "prediction = []\n",
    "\n",
    "for row in tqdm(range(submit.shape[0])):\n",
    "    \n",
    "    str_label = ''\n",
    "    \n",
    "    for col in range(PP.shape[1]):\n",
    "        if(PP[row, col] < .2):   # to account for losing TP is more costly than decreasing FP\n",
    "            #print(PP[row])\n",
    "            str_label += ''\n",
    "        else:\n",
    "            str_label += str(col) + ' '\n",
    "    prediction.append(str_label.strip())\n",
    "    \n",
    "submit['Predicted'] = np.array(prediction)\n",
    "submit.to_csv('datagenerator_model_focal_loss.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
