{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "import keras\n",
    "import warnings\n",
    "from keras.utils import Sequence\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SIZE = 299\n",
    "SEED = 777\n",
    "THRESHOLD = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset info\n",
    "DIR = '../input/'\n",
    "data = pd.read_csv('../input/train.csv')\n",
    "\n",
    "# train_dataset_info = []\n",
    "# for name, labels in zip(data['Id'], data['Target'].str.split(' ')):\n",
    "#     train_dataset_info.append({\n",
    "#         'path':os.path.join(path_to_train, name),\n",
    "#         'labels':np.array([int(label) for label in labels])})\n",
    "# train_dataset_info = np.array(train_dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainDataset():\n",
    "    \n",
    "    path_to_train = DIR + '/train/'\n",
    "    data = pd.read_csv(DIR + '/train.csv')\n",
    "\n",
    "    paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for name, lbl in zip(data['Id'], data['Target'].str.split(' ')):\n",
    "        y = np.zeros(28)\n",
    "        for key in lbl:\n",
    "            y[int(key)] = 1\n",
    "        paths.append(os.path.join(path_to_train, name))\n",
    "        labels.append(y)\n",
    "\n",
    "    return np.array(paths), np.array(labels)\n",
    "\n",
    "def getTestDataset():\n",
    "    \n",
    "    path_to_test = DIR + '/test/'\n",
    "    data = pd.read_csv(DIR + '/sample_submission.csv')\n",
    "\n",
    "    paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for name in data['Id']:\n",
    "        y = np.ones(28)\n",
    "        paths.append(os.path.join(path_to_test, name))\n",
    "        labels.append(y)\n",
    "\n",
    "    return np.array(paths), np.array(labels)\n",
    "paths, labels = getTrainDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credits: https://github.com/keras-team/keras/blob/master/keras/utils/data_utils.py#L302\n",
    "# credits: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "from random import randint\n",
    "class ProteinDataGenerator(keras.utils.Sequence):\n",
    "            \n",
    "    def __init__(self, paths, labels, batch_size, shape, channels = [], shuffle = False, use_cache = False):\n",
    "        self.paths, self.labels = paths, labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shape = shape\n",
    "        self.shuffle = shuffle\n",
    "        self.use_cache = use_cache\n",
    "        self.channels = channels\n",
    "        if use_cache == True:\n",
    "            self.cache = np.zeros((paths.shape[0], shape[0], shape[1], len(channels)))\n",
    "            self.is_cached = np.zeros((paths.shape[0]))\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.paths) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        indexes = self.indexes[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "\n",
    "        paths = self.paths[indexes]\n",
    "        X = np.zeros((paths.shape[0], self.shape[0], self.shape[1], self.shape[2]))\n",
    "        # Generate data\n",
    "        if self.use_cache == True:\n",
    "            X = self.cache[indexes]\n",
    "            for i, path in enumerate(paths[np.where(self.is_cached[indexes] == 0)]):\n",
    "                image = self.__load_image(path)\n",
    "                self.is_cached[indexes[i]] = 1\n",
    "                self.cache[indexes[i]] = image\n",
    "                X[i] = image\n",
    "        else:\n",
    "            for i, path in enumerate(paths):\n",
    "                X[i] = self.__load_image(path)\n",
    "\n",
    "        y = self.labels[indexes]\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        # Updates indexes after each epoch\n",
    "        self.indexes = np.arange(len(self.paths))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Create a generator that iterate over the Sequence.\"\"\"\n",
    "        for item in (self[i] for i in range(len(self))):\n",
    "            item = self.augment(item)\n",
    "            yield item\n",
    "            \n",
    "    def __load_image(self, path):\n",
    "        images = []\n",
    "        for channel in self.channels:\n",
    "            images.append(np.array(Image.open(path + '_' + channel + '.png')))\n",
    "\n",
    "        if len(self.channels) >= 2:\n",
    "            im = np.stack((\n",
    "                images\n",
    "            ), -1)\n",
    "            im = cv2.resize(im, (SIZE,SIZE))\n",
    "            im = np.divide(im, 255)\n",
    "\n",
    "        else:\n",
    "            im = images[0]\n",
    "            im = cv2.resize(im, (SIZE,SIZE))\n",
    "            im = np.divide(im, 255)\n",
    "            im = np.expand_dims(im, 2)\n",
    "        return im\n",
    "    def augment(self, image):\n",
    "        if 0 == 1:\n",
    "            augment_img = iaa.Sequential([\n",
    "                iaa.OneOf([\n",
    "                    iaa.Fliplr(0.5), # horizontal flips\n",
    "                    iaa.Flipud(0.5), # horizontal flips\n",
    "                    iaa.Crop(percent=(0, 0.1)), # random crops\n",
    "                    # Small gaussian blur with random sigma between 0 and 0.5.\n",
    "                    # But we only blur about 50% of all images.\n",
    "                    iaa.Sometimes(0.5,\n",
    "                        iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "                    ),\n",
    "                    # Strengthen or weaken the contrast in each image.\n",
    "                    iaa.ContrastNormalization((0.75, 1.5)),\n",
    "                    # Add gaussian noise.\n",
    "                    # For 50% of all images, we sample the noise once per pixel.\n",
    "                    # For the other 50% of all images, we sample the noise per pixel AND\n",
    "                    # channel. This can change the color (not only brightness) of the\n",
    "                    # pixels.\n",
    "                    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05), per_channel=0.5),\n",
    "                    # Make some images brighter and some darker.\n",
    "                    # In 20% of all cases, we sample the multiplier once per channel,\n",
    "                    # which can end up changing the color of the images.\n",
    "                    iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
    "                    # Apply affine transformations to each image.\n",
    "                    # Scale/zoom them, translate/move them, rotate them and shear them.\n",
    "                    iaa.Affine(\n",
    "                        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "                        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "                        rotate=(-180, 180),\n",
    "                        shear=(-8, 8)\n",
    "                    )\n",
    "                ])], random_order=True)\n",
    "\n",
    "\n",
    "            image_aug = augment_img.augment_image(image)\n",
    "            return image_aug\n",
    "        else:\n",
    "            return image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE = (299, 299, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red\n",
      "(299, 299, 1)\n",
      "red\n",
      "(299, 299, 1)\n",
      "red\n",
      "(299, 299, 1)\n",
      "red\n",
      "(299, 299, 1)\n",
      "red\n",
      "(299, 299, 1)\n",
      "red\n",
      "(299, 299, 1)\n",
      "red\n",
      "(299, 299, 1)\n",
      "red\n",
      "(299, 299, 1)\n",
      "red\n",
      "(299, 299, 1)\n",
      "red\n",
      "(299, 299, 1)\n"
     ]
    }
   ],
   "source": [
    "channels = [\"red\"]\n",
    "for path in paths[0:10]:\n",
    "    images = []\n",
    "    for channel in channels:\n",
    "        print(channel)\n",
    "        images.append(np.array(Image.open(path + '_' + channel + '.png')))\n",
    "\n",
    "    if len(channels) >= 2:\n",
    "        im = np.stack((\n",
    "            images\n",
    "        ), -1)\n",
    "        im = cv2.resize(im, (SIZE,SIZE))\n",
    "        im = np.divide(im, 255)\n",
    "        \n",
    "    else:\n",
    "        im = images[0]\n",
    "        im = cv2.resize(im, (SIZE,SIZE))\n",
    "        im = np.divide(im, 255)\n",
    "        im = np.expand_dims(im, 2)\n",
    "    print(im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class data_generator:\n",
    "    \n",
    "#     def create_train(dataset_info, batch_size, shape, augument=True):\n",
    "#         assert shape[2] == 3\n",
    "#         while True:\n",
    "#             dataset_info = shuffle(dataset_info)\n",
    "#             for start in range(0, len(dataset_info), batch_size):\n",
    "#                 end = min(start + batch_size, len(dataset_info))\n",
    "#                 batch_images = []\n",
    "#                 X_train_batch = dataset_info[start:end]\n",
    "#                 batch_labels = np.zeros((len(X_train_batch), 28))\n",
    "#                 for i in range(len(X_train_batch)):\n",
    "#                     image = data_generator.load_image(\n",
    "#                         X_train_batch[i]['path'], shape)   \n",
    "#                     if augument:\n",
    "#                         image = data_generator.augment(image)\n",
    "#                     batch_images.append(image/255.)\n",
    "#                     batch_labels[i][X_train_batch[i]['labels']] = 1\n",
    "#                 yield np.array(batch_images, np.float32), batch_labels\n",
    "\n",
    "#     def load_image(path, shape):\n",
    "#         image_red_ch = Image.open(path+'_red.png')\n",
    "#         image_yellow_ch = Image.open(path+'_yellow.png')\n",
    "#         image_green_ch = Image.open(path+'_green.png')\n",
    "#         image_blue_ch = Image.open(path+'_blue.png')\n",
    "#         image = np.stack((\n",
    "#         np.array(image_red_ch), \n",
    "#         np.array(image_green_ch), \n",
    "#         np.array(image_blue_ch)), -1)\n",
    "#         image = cv2.resize(image, (shape[0], shape[1]))\n",
    "#         return image\n",
    "\n",
    "#     def augment(image):\n",
    "#         augment_img = iaa.Sequential([\n",
    "#             iaa.OneOf([\n",
    "#                 iaa.Affine(rotate=0),\n",
    "#                 iaa.Affine(rotate=90),\n",
    "#                 iaa.Affine(rotate=180),\n",
    "#                 iaa.Affine(rotate=270),\n",
    "#                 iaa.Fliplr(0.5),\n",
    "#                 iaa.Flipud(0.5),\n",
    "#             ])], random_order=True)\n",
    "\n",
    "#         image_aug = augment_img.augment_image(image)\n",
    "#         return image_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D, BatchNormalization, Input, Conv2D, MaxPooling2D\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam \n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_out, channels):\n",
    "    input_tensor = Input(shape=(299,299,len(channels)))\n",
    "\n",
    "    base_model = InceptionV3(include_top=False,\n",
    "                   weights='imagenet',\n",
    "                   input_shape=(299,299,3)\n",
    "                            )\n",
    "    bn = BatchNormalization()(input_tensor)\n",
    "    x = Conv2D(3, kernel_size=(1,1), activation='relu', padding = \"same\")(bn)\n",
    "    x = base_model(x)\n",
    "    x = Conv2D(128, kernel_size=(3,3), activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(n_out, activation='sigmoid')(x)\n",
    "    model = Model(input_tensor, output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    #y_pred = K.round(y_pred)\n",
    "    y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    #y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1-K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31072,) (31072, 28)\n",
      "(27964,) (27964, 28) (3108,) (3108, 28)\n"
     ]
    }
   ],
   "source": [
    "# create callbacks list\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "epochs = 10; batch_size = 32;VAL_RATIO = .1;DEBUG = False\n",
    "# split data into train, valid\n",
    "paths, labels = getTrainDataset()\n",
    "\n",
    "# divide to \n",
    "keys = np.arange(paths.shape[0], dtype=np.int)  \n",
    "np.random.seed(SEED)\n",
    "np.random.shuffle(keys)\n",
    "lastTrainIndex = int((1-VAL_RATIO) * paths.shape[0])\n",
    "\n",
    "if DEBUG == True:  # use only small subset for debugging, Kaggle's RAM is limited\n",
    "    pathsTrain = paths[0:256]\n",
    "    labelsTrain = labels[0:256]\n",
    "    pathsVal = paths[lastTrainIndex:lastTrainIndex+256]\n",
    "    labelsVal = labels[lastTrainIndex:lastTrainIndex+256]\n",
    "    use_cache = True\n",
    "else:\n",
    "    pathsTrain = paths[0:lastTrainIndex]\n",
    "    labelsTrain = labels[0:lastTrainIndex]\n",
    "    pathsVal = paths[lastTrainIndex:]\n",
    "    labelsVal = labels[lastTrainIndex:]\n",
    "    use_cache = False\n",
    "\n",
    "print(paths.shape, labels.shape)\n",
    "print(pathsTrain.shape, labelsTrain.shape, pathsVal.shape, labelsVal.shape)\n",
    "use_cache = True\n",
    "tg = ProteinDataGenerator(pathsTrain, labelsTrain, batch_size, SHAPE, channels, use_cache=use_cache)\n",
    "vg = ProteinDataGenerator(pathsVal, labelsVal, batch_size, SHAPE, channels, use_cache=use_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and valid datagens\n",
    "# train_generator = data_generator.create_train(\n",
    "#     train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=True)\n",
    "# validation_generator = data_generator.create_train(\n",
    "#     train_dataset_info[valid_indexes], 32, (SIZE,SIZE,3), augument=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('../working/InceptionV3.h5', monitor='val_f1', verbose=1, \n",
    "                             save_best_only=True, mode='max', save_weights_only = False)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_f1', factor=0.5, patience=10, \n",
    "                                   verbose=1, mode='max', epsilon=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_f1\", \n",
    "                      mode=\"max\", \n",
    "                      patience=20)\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "\n",
    "        pt_1 = K.clip(pt_1, 1e-3, .999)\n",
    "        pt_0 = K.clip(pt_0, 1e-3, .999)\n",
    "\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 299, 299, 4)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 299, 299, 4)       16        \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 299, 299, 3)       15        \n",
      "_________________________________________________________________\n",
      "inception_v3 (Model)         (None, 8, 8, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 6, 6, 128)         2359424   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              4719616   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 28)                28700     \n",
      "=================================================================\n",
      "Total params: 28,910,555\n",
      "Trainable params: 7,107,763\n",
      "Non-trainable params: 21,802,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# warm up model\n",
    "import tensorflow as tf\n",
    "channels = [\"green\", \"blue\", \"red\", \"yellow\"]\n",
    "# with tf.device('/cpu:0'):\n",
    "model = create_model(\n",
    "    input_shape=(SIZE,SIZE,4), \n",
    "    n_out=28, channels = channels)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "model.layers[1].trainable = True\n",
    "model.layers[2].trainable = True\n",
    "model.layers[-1].trainable = True\n",
    "model.layers[-2].trainable = True\n",
    "model.layers[-3].trainable = True\n",
    "model.layers[-4].trainable = True\n",
    "model.layers[-5].trainable = True\n",
    "model.layers[-6].trainable = True\n",
    "\n",
    "model.summary()\n",
    "# model = multi_gpu_model(model, gpus = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 299, 299, 4)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 299, 299, 4)       16        \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 299, 299, 3)       15        \n",
      "_________________________________________________________________\n",
      "inception_v3 (Model)         (None, 8, 8, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 6, 6, 128)         2359424   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              4719616   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 28)                28700     \n",
      "=================================================================\n",
      "Total params: 28,910,555\n",
      "Trainable params: 7,107,763\n",
      "Non-trainable params: 21,802,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=focal_loss(), \n",
    "    optimizer=Adam(1e-04),\n",
    "    metrics=['acc', f1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tg = ProteinDataGenerator(pathsTrain, labelsTrain, batch_size, SHAPE, channels, use_cache=use_cache)\n",
    "vg = ProteinDataGenerator(pathsVal, labelsVal, batch_size, SHAPE, channels, use_cache=use_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "437/437 [==============================] - 377s 862ms/step - loss: 22.3764 - acc: 0.2192 - f1: 0.0897 - val_loss: 16.7986 - val_acc: 0.3412 - val_f1: 0.0830\n",
      "\n",
      "Epoch 00001: val_f1 improved from -inf to 0.08297, saving model to ../working/InceptionV3.h5\n",
      "Epoch 2/20\n",
      "437/437 [==============================] - 416s 953ms/step - loss: 17.4284 - acc: 0.2928 - f1: 0.0950 - val_loss: 16.7833 - val_acc: 0.3540 - val_f1: 0.0780\n",
      "\n",
      "Epoch 00002: val_f1 did not improve from 0.08297\n",
      "Epoch 3/20\n",
      "437/437 [==============================] - 137s 313ms/step - loss: 16.3589 - acc: 0.3216 - f1: 0.1001 - val_loss: 16.3250 - val_acc: 0.3112 - val_f1: 0.0926\n",
      "\n",
      "Epoch 00003: val_f1 improved from 0.08297 to 0.09257, saving model to ../working/InceptionV3.h5\n",
      "Epoch 4/20\n",
      "437/437 [==============================] - 197s 451ms/step - loss: 15.9319 - acc: 0.3369 - f1: 0.1018 - val_loss: 17.1436 - val_acc: 0.3546 - val_f1: 0.0775\n",
      "\n",
      "Epoch 00004: val_f1 did not improve from 0.09257\n",
      "Epoch 5/20\n",
      "437/437 [==============================] - 136s 310ms/step - loss: 15.6029 - acc: 0.3413 - f1: 0.1056 - val_loss: 17.3573 - val_acc: 0.2309 - val_f1: 0.0885\n",
      "\n",
      "Epoch 00005: val_f1 did not improve from 0.09257\n",
      "Epoch 6/20\n",
      "437/437 [==============================] - 201s 461ms/step - loss: 15.4277 - acc: 0.3583 - f1: 0.1061 - val_loss: 17.3513 - val_acc: 0.3756 - val_f1: 0.0921\n",
      "\n",
      "Epoch 00006: val_f1 did not improve from 0.09257\n",
      "Epoch 7/20\n",
      "437/437 [==============================] - 135s 308ms/step - loss: 15.0807 - acc: 0.3609 - f1: 0.1121 - val_loss: 17.0887 - val_acc: 0.3157 - val_f1: 0.0832\n",
      "\n",
      "Epoch 00007: val_f1 did not improve from 0.09257\n",
      "Epoch 8/20\n",
      "437/437 [==============================] - 185s 423ms/step - loss: 15.1019 - acc: 0.3615 - f1: 0.1117 - val_loss: 16.6671 - val_acc: 0.2679 - val_f1: 0.0794\n",
      "\n",
      "Epoch 00008: val_f1 did not improve from 0.09257\n",
      "Epoch 9/20\n",
      "437/437 [==============================] - 146s 333ms/step - loss: 14.7565 - acc: 0.3785 - f1: 0.1156 - val_loss: 17.1462 - val_acc: 0.3036 - val_f1: 0.0943\n",
      "\n",
      "Epoch 00009: val_f1 improved from 0.09257 to 0.09428, saving model to ../working/InceptionV3.h5\n",
      "Epoch 10/20\n",
      "437/437 [==============================] - 209s 478ms/step - loss: 14.7609 - acc: 0.3695 - f1: 0.1148 - val_loss: 17.1745 - val_acc: 0.3017 - val_f1: 0.0995\n",
      "\n",
      "Epoch 00010: val_f1 improved from 0.09428 to 0.09947, saving model to ../working/InceptionV3.h5\n",
      "Epoch 11/20\n",
      "437/437 [==============================] - 144s 329ms/step - loss: 14.4630 - acc: 0.3809 - f1: 0.1224 - val_loss: 17.0233 - val_acc: 0.2513 - val_f1: 0.1005\n",
      "\n",
      "Epoch 00011: val_f1 improved from 0.09947 to 0.10052, saving model to ../working/InceptionV3.h5\n",
      "Epoch 12/20\n",
      "437/437 [==============================] - 185s 423ms/step - loss: 14.5039 - acc: 0.3742 - f1: 0.1201 - val_loss: 17.7939 - val_acc: 0.3552 - val_f1: 0.0948\n",
      "\n",
      "Epoch 00012: val_f1 did not improve from 0.10052\n",
      "Epoch 13/20\n",
      "437/437 [==============================] - 139s 317ms/step - loss: 14.2012 - acc: 0.3857 - f1: 0.1264 - val_loss: 17.1092 - val_acc: 0.2577 - val_f1: 0.0961\n",
      "\n",
      "Epoch 00013: val_f1 did not improve from 0.10052\n",
      "Epoch 14/20\n",
      "437/437 [==============================] - 140s 321ms/step - loss: 14.2599 - acc: 0.3781 - f1: 0.1260 - val_loss: 17.2298 - val_acc: 0.2800 - val_f1: 0.1044\n",
      "\n",
      "Epoch 00014: val_f1 improved from 0.10052 to 0.10443, saving model to ../working/InceptionV3.h5\n",
      "Epoch 15/20\n",
      "437/437 [==============================] - 169s 388ms/step - loss: 13.8913 - acc: 0.3943 - f1: 0.1315 - val_loss: 17.1019 - val_acc: 0.2940 - val_f1: 0.0959\n",
      "\n",
      "Epoch 00015: val_f1 did not improve from 0.10443\n",
      "Epoch 16/20\n",
      "437/437 [==============================] - 136s 312ms/step - loss: 14.1162 - acc: 0.3882 - f1: 0.1297 - val_loss: 17.1434 - val_acc: 0.2468 - val_f1: 0.0994\n",
      "\n",
      "Epoch 00016: val_f1 did not improve from 0.10443\n",
      "Epoch 17/20\n",
      "437/437 [==============================] - 136s 312ms/step - loss: 13.7538 - acc: 0.3971 - f1: 0.1369 - val_loss: 17.4827 - val_acc: 0.2806 - val_f1: 0.0963\n",
      "\n",
      "Epoch 00017: val_f1 did not improve from 0.10443\n",
      "Epoch 18/20\n",
      "437/437 [==============================] - 216s 495ms/step - loss: 13.6832 - acc: 0.3995 - f1: 0.1385 - val_loss: 17.0507 - val_acc: 0.2761 - val_f1: 0.0942\n",
      "\n",
      "Epoch 00018: val_f1 did not improve from 0.10443\n",
      "Epoch 19/20\n",
      "437/437 [==============================] - 137s 314ms/step - loss: 13.3707 - acc: 0.4137 - f1: 0.1439 - val_loss: 17.3021 - val_acc: 0.3438 - val_f1: 0.0988\n",
      "\n",
      "Epoch 00019: val_f1 did not improve from 0.10443\n",
      "Epoch 20/20\n",
      "437/437 [==============================] - 164s 376ms/step - loss: 13.3864 - acc: 0.4081 - f1: 0.1425 - val_loss: 17.4696 - val_acc: 0.3004 - val_f1: 0.0991\n",
      "\n",
      "Epoch 00020: val_f1 did not improve from 0.10443\n"
     ]
    }
   ],
   "source": [
    "hist =  model.fit_generator(\n",
    "        tg,\n",
    "        steps_per_epoch=np.ceil(float(len(pathsTrain)) / float(batch_size))/2,\n",
    "        validation_data=vg,\n",
    "        validation_steps=np.ceil(float(len(pathsVal)) / float(batch_size))/2,\n",
    "        epochs=20, \n",
    "        verbose=1,\n",
    "        callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x00000116E045D048>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001201A4D8908>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001201A52AD30>\n",
      "<keras.engine.training.Model object at 0x000001201A4D8C50>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000012022570C18>\n",
      "<keras.layers.core.Flatten object at 0x0000012020C3A588>\n",
      "<keras.layers.core.Dropout object at 0x000001201A67E978>\n",
      "<keras.layers.core.Dense object at 0x000001201A71FB00>\n",
      "<keras.layers.core.Dropout object at 0x00000120205AE6A0>\n",
      "<keras.layers.core.Dense object at 0x00000120205AE4A8>\n"
     ]
    }
   ],
   "source": [
    "# train all layers\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    layer.trainable = True\n",
    "model.compile(loss=focal_loss(),\n",
    "            optimizer=Adam(lr=1e-4),\n",
    "            metrics=['accuracy', f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1166/1165 [==============================] - 606s 520ms/step - loss: 13.8179 - acc: 0.4125 - f1: 0.1311 - val_loss: 13.0988 - val_acc: 0.4613 - val_f1: 0.1407\n",
      "\n",
      "Epoch 00001: val_f1 improved from 0.10443 to 0.14066, saving model to ../working/InceptionV3.h5\n",
      "Epoch 2/200\n",
      "1166/1165 [==============================] - 530s 455ms/step - loss: 12.4071 - acc: 0.4781 - f1: 0.1634 - val_loss: 12.4184 - val_acc: 0.5031 - val_f1: 0.1635\n",
      "\n",
      "Epoch 00002: val_f1 improved from 0.14066 to 0.16350, saving model to ../working/InceptionV3.h5\n",
      "Epoch 3/200\n",
      "1166/1165 [==============================] - 554s 475ms/step - loss: 11.2627 - acc: 0.5278 - f1: 0.1934 - val_loss: 12.4274 - val_acc: 0.4550 - val_f1: 0.1691\n",
      "\n",
      "Epoch 00003: val_f1 improved from 0.16350 to 0.16911, saving model to ../working/InceptionV3.h5\n",
      "Epoch 4/200\n",
      "1166/1165 [==============================] - 593s 508ms/step - loss: 9.4958 - acc: 0.5981 - f1: 0.2390 - val_loss: 13.9004 - val_acc: 0.4100 - val_f1: 0.1862\n",
      "\n",
      "Epoch 00004: val_f1 improved from 0.16911 to 0.18621, saving model to ../working/InceptionV3.h5\n",
      "Epoch 5/200\n",
      "1166/1165 [==============================] - 588s 504ms/step - loss: 8.0883 - acc: 0.6450 - f1: 0.2783 - val_loss: 14.0686 - val_acc: 0.5065 - val_f1: 0.1976\n",
      "\n",
      "Epoch 00005: val_f1 improved from 0.18621 to 0.19758, saving model to ../working/InceptionV3.h5\n",
      "Epoch 6/200\n",
      "1166/1165 [==============================] - 588s 504ms/step - loss: 6.6948 - acc: 0.6852 - f1: 0.3171 - val_loss: 14.5782 - val_acc: 0.4610 - val_f1: 0.2054\n",
      "\n",
      "Epoch 00006: val_f1 improved from 0.19758 to 0.20538, saving model to ../working/InceptionV3.h5\n",
      "Epoch 7/200\n",
      "1166/1165 [==============================] - 576s 494ms/step - loss: 5.0948 - acc: 0.7253 - f1: 0.3681 - val_loss: 17.3627 - val_acc: 0.4627 - val_f1: 0.2089\n",
      "\n",
      "Epoch 00007: val_f1 improved from 0.20538 to 0.20888, saving model to ../working/InceptionV3.h5\n",
      "Epoch 8/200\n",
      "1166/1165 [==============================] - 582s 499ms/step - loss: 4.3031 - acc: 0.7365 - f1: 0.3967 - val_loss: 17.2160 - val_acc: 0.4584 - val_f1: 0.2162\n",
      "\n",
      "Epoch 00008: val_f1 improved from 0.20888 to 0.21622, saving model to ../working/InceptionV3.h5\n",
      "Epoch 9/200\n",
      "1166/1165 [==============================] - 566s 486ms/step - loss: 3.6838 - acc: 0.7471 - f1: 0.4214 - val_loss: 17.6754 - val_acc: 0.5322 - val_f1: 0.2329\n",
      "\n",
      "Epoch 00009: val_f1 improved from 0.21622 to 0.23285, saving model to ../working/InceptionV3.h5\n",
      "Epoch 10/200\n",
      "1166/1165 [==============================] - 555s 476ms/step - loss: 2.9088 - acc: 0.7613 - f1: 0.4488 - val_loss: 20.8786 - val_acc: 0.5211 - val_f1: 0.2147\n",
      "\n",
      "Epoch 00010: val_f1 did not improve from 0.23285\n",
      "Epoch 11/200\n",
      "1166/1165 [==============================] - 526s 451ms/step - loss: 2.6502 - acc: 0.7521 - f1: 0.4586 - val_loss: 21.8898 - val_acc: 0.4736 - val_f1: 0.2152\n",
      "\n",
      "Epoch 00011: val_f1 did not improve from 0.23285\n",
      "Epoch 12/200\n",
      "1166/1165 [==============================] - 594s 509ms/step - loss: 2.4071 - acc: 0.7600 - f1: 0.4721 - val_loss: 20.0585 - val_acc: 0.4927 - val_f1: 0.2233\n",
      "\n",
      "Epoch 00012: val_f1 did not improve from 0.23285\n",
      "Epoch 13/200\n",
      "  34/1165 [..............................] - ETA: 9:11 - loss: 2.0660 - acc: 0.7831 - f1: 0.4790"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-322f0ce0c041>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         callbacks=callbacks_list)\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1424\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1425\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1426\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    189\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    190\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1218\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1220\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1221\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2661\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2662\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m                                 session)\n\u001b[1;32m-> 2631\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2632\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 12\n",
    "hist =  model.fit_generator(\n",
    "        tg,\n",
    "        steps_per_epoch=np.ceil(float(len(pathsTrain)) / float(batch_size))/2,\n",
    "        validation_data=vg,\n",
    "        validation_steps=np.ceil(float(len(pathsVal)) / float(batch_size))/2,\n",
    "        epochs=200, \n",
    "        verbose=1,\n",
    "        callbacks=callbacks_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss=f1_loss,\n",
    "#             optimizer=Adam(lr=1e-4),\n",
    "#             metrics=['accuracy', f1])\n",
    "# hist =  model.fit_generator(\n",
    "#         tg,\n",
    "#         steps_per_epoch=np.ceil(float(len(pathsTrain)) / float(batch_size))/2,\n",
    "#         validation_data=vg,\n",
    "#         validation_steps=np.ceil(float(len(pathsVal)) / float(batch_size))/2,\n",
    "#         epochs=200, \n",
    "#         verbose=1,\n",
    "#         callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax[0].set_title('loss')\n",
    "ax[0].plot(hist.epoch, hist.history[\"loss\"], label=\"Train loss\")\n",
    "ax[0].plot(hist.epoch, hist.history[\"val_loss\"], label=\"Validation loss\")\n",
    "ax[1].set_title('acc')\n",
    "ax[1].plot(hist.epoch, hist.history[\"f1\"], label=\"Train F1\")\n",
    "ax[1].plot(hist.epoch, hist.history[\"val_f1\"], label=\"Validation F1\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "bestModel = load_model('../working/InceptionV3.h5', custom_objects={'f1': f1, 'f1_loss': f1_loss, 'focal_loss_fixed':focal_loss()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "lastFullValPred = np.empty((0, 28))\n",
    "lastFullValLabels = np.empty((0, 28))\n",
    "for i in tqdm(range(len(vg))): \n",
    "    im, lbl = vg[i]\n",
    "    scores = bestModel.predict(im)\n",
    "    lastFullValPred = np.append(lastFullValPred, scores, axis=0)\n",
    "    lastFullValLabels = np.append(lastFullValLabels, lbl, axis=0)\n",
    "print(lastFullValPred.shape, lastFullValLabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score as off1\n",
    "rng = np.arange(0, 1, 0.001)\n",
    "f1s = np.zeros((rng.shape[0], 28))\n",
    "for j,t in enumerate(tqdm(rng)):\n",
    "    for i in range(28):\n",
    "        p = np.array(lastFullValPred[:,i]>t, dtype=np.int8)\n",
    "        scoref1 = off1(lastFullValLabels[:,i], p, average='binary')\n",
    "        f1s[j,i] = scoref1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Individual F1-scores for each class:')\n",
    "print(np.max(f1s, axis=0))\n",
    "print('Macro F1-score CV =', np.mean(np.max(f1s, axis=0)))\n",
    "plt.plot(rng, f1s)\n",
    "T = np.empty(28)\n",
    "for i in range(28):\n",
    "    T[i] = rng[np.where(f1s[:,i] == np.max(f1s[:,i]))[0][0]]\n",
    "print('Probability threshold maximizing CV F1-score for each class:')\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathsTest, labelsTest = getTestDataset()\n",
    "\n",
    "testg = ProteinDataGenerator(pathsTest, labelsTest, batch_size, SHAPE, channels)\n",
    "submit = pd.read_csv(DIR + '/sample_submission.csv')\n",
    "P = np.zeros((pathsTest.shape[0], 28))\n",
    "for i in tqdm(range(len(testg))):\n",
    "    images, labels = testg[i]\n",
    "    score = bestModel.predict(images)\n",
    "    P[i*batch_size:i*batch_size+score.shape[0]] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP = np.array(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "\n",
    "for row in tqdm(range(submit.shape[0])):\n",
    "    \n",
    "    str_label = ''\n",
    "    \n",
    "    for col in range(PP.shape[1]):\n",
    "        if(PP[row, col] < T[col]):\n",
    "            str_label += ''\n",
    "        else:\n",
    "            str_label += str(col) + ' '\n",
    "    prediction.append(str_label.strip())\n",
    "    \n",
    "submit['Predicted'] = np.array(prediction)\n",
    "submit.to_csv('transfer_1x1conv_aug_focal_loss.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# pathsTest, labelsTest = getTestDataset()\n",
    "\n",
    "# testg = ProteinDataGenerator(pathsTest, labelsTest, batch_size, SHAPE)\n",
    "# submit = pd.read_csv(DIR + '/sample_submission.csv')\n",
    "# P = np.zeros((pathsTest.shape[0], 28))\n",
    "# for i in tqdm(range(len(testg))):\n",
    "#     images, labels = testg[i]\n",
    "#     score = bestModel.predict(images)\n",
    "#     P[i*batch_size:i*batch_size+score.shape[0]] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PP = np.array(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = []\n",
    "\n",
    "# for row in tqdm(range(submit.shape[0])):\n",
    "    \n",
    "#     str_label = ''\n",
    "    \n",
    "#     for col in range(PP.shape[1]):\n",
    "#         if(PP[row, col] < .2):   # to account for losing TP is more costly than decreasing FP\n",
    "#             #print(PP[row])\n",
    "#             str_label += ''\n",
    "#         else:\n",
    "#             str_label += str(col) + ' '\n",
    "#     prediction.append(str_label.strip())\n",
    "    \n",
    "# submit['Predicted'] = np.array(prediction)\n",
    "# submit.to_csv('datagenerator_model_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
