{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "import keras\n",
    "import warnings\n",
    "from keras.utils import Sequence\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SIZE = 299\n",
    "SEED = 777\n",
    "THRESHOLD = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset info\n",
    "DIR = '../input/'\n",
    "data = pd.read_csv('../input/train.csv')\n",
    "\n",
    "# train_dataset_info = []\n",
    "# for name, labels in zip(data['Id'], data['Target'].str.split(' ')):\n",
    "#     train_dataset_info.append({\n",
    "#         'path':os.path.join(path_to_train, name),\n",
    "#         'labels':np.array([int(label) for label in labels])})\n",
    "# train_dataset_info = np.array(train_dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainDataset():\n",
    "    \n",
    "    path_to_train = DIR + '/train/'\n",
    "    data = pd.read_csv(DIR + '/train.csv')\n",
    "\n",
    "    paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for name, lbl in zip(data['Id'], data['Target'].str.split(' ')):\n",
    "        y = np.zeros(28)\n",
    "        for key in lbl:\n",
    "            y[int(key)] = 1\n",
    "        paths.append(os.path.join(path_to_train, name))\n",
    "        labels.append(y)\n",
    "\n",
    "    return np.array(paths), np.array(labels)\n",
    "\n",
    "def getTestDataset():\n",
    "    \n",
    "    path_to_test = DIR + '/test/'\n",
    "    data = pd.read_csv(DIR + '/sample_submission.csv')\n",
    "\n",
    "    paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for name in data['Id']:\n",
    "        y = np.ones(28)\n",
    "        paths.append(os.path.join(path_to_test, name))\n",
    "        labels.append(y)\n",
    "\n",
    "    return np.array(paths), np.array(labels)\n",
    "paths, labels = getTrainDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credits: https://github.com/keras-team/keras/blob/master/keras/utils/data_utils.py#L302\n",
    "# credits: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "\n",
    "class ProteinDataGenerator(keras.utils.Sequence):\n",
    "            \n",
    "    def __init__(self, paths, labels, batch_size, shape, shuffle = False, use_cache = False):\n",
    "        self.paths, self.labels = paths, labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shape = shape\n",
    "        self.shuffle = shuffle\n",
    "        self.use_cache = use_cache\n",
    "        if use_cache == True:\n",
    "            self.cache = np.zeros((paths.shape[0], shape[0], shape[1], shape[2]))\n",
    "            self.is_cached = np.zeros((paths.shape[0]))\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.paths) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        indexes = self.indexes[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "\n",
    "        paths = self.paths[indexes]\n",
    "        X = np.zeros((paths.shape[0], self.shape[0], self.shape[1], self.shape[2]))\n",
    "        # Generate data\n",
    "        if self.use_cache == True:\n",
    "            X = self.cache[indexes]\n",
    "            for i, path in enumerate(paths[np.where(self.is_cached[indexes] == 0)]):\n",
    "                image = self.__load_image(path)\n",
    "                self.is_cached[indexes[i]] = 1\n",
    "                self.cache[indexes[i]] = image\n",
    "                X[i] = image\n",
    "        else:\n",
    "            for i, path in enumerate(paths):\n",
    "                X[i] = self.__load_image(path)\n",
    "\n",
    "        y = self.labels[indexes]\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        # Updates indexes after each epoch\n",
    "        self.indexes = np.arange(len(self.paths))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Create a generator that iterate over the Sequence.\"\"\"\n",
    "        for item in (self[i] for i in range(len(self))):\n",
    "            yield item\n",
    "            \n",
    "    def __load_image(self, path):\n",
    "        R = Image.open(path + '_red.png')\n",
    "        G = Image.open(path + '_green.png')\n",
    "        B = Image.open(path + '_blue.png')\n",
    "        Y = Image.open(path + '_yellow.png')\n",
    "\n",
    "        im = np.stack((\n",
    "            np.array(R), \n",
    "            np.array(G), \n",
    "            np.array(B),\n",
    "            np.array(Y)\n",
    "        ), -1)\n",
    "        im = cv2.resize(im, (SIZE,SIZE))\n",
    "        im = np.divide(im, 255)\n",
    "        im = self.augment(im)\n",
    "        return im\n",
    "    def augment(self, image):\n",
    "        augment_img = iaa.Sequential([\n",
    "            iaa.OneOf([\n",
    "                iaa.Affine(rotate=0),\n",
    "                iaa.Affine(rotate=90),\n",
    "                iaa.Affine(rotate=180),\n",
    "                iaa.Affine(rotate=270),\n",
    "                iaa.Fliplr(0.5),\n",
    "                iaa.Flipud(0.5),\n",
    "            ])], random_order=True)\n",
    "\n",
    "        image_aug = augment_img.augment_image(image)\n",
    "        return image_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE = (299, 299, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class data_generator:\n",
    "    \n",
    "#     def create_train(dataset_info, batch_size, shape, augument=True):\n",
    "#         assert shape[2] == 3\n",
    "#         while True:\n",
    "#             dataset_info = shuffle(dataset_info)\n",
    "#             for start in range(0, len(dataset_info), batch_size):\n",
    "#                 end = min(start + batch_size, len(dataset_info))\n",
    "#                 batch_images = []\n",
    "#                 X_train_batch = dataset_info[start:end]\n",
    "#                 batch_labels = np.zeros((len(X_train_batch), 28))\n",
    "#                 for i in range(len(X_train_batch)):\n",
    "#                     image = data_generator.load_image(\n",
    "#                         X_train_batch[i]['path'], shape)   \n",
    "#                     if augument:\n",
    "#                         image = data_generator.augment(image)\n",
    "#                     batch_images.append(image/255.)\n",
    "#                     batch_labels[i][X_train_batch[i]['labels']] = 1\n",
    "#                 yield np.array(batch_images, np.float32), batch_labels\n",
    "\n",
    "#     def load_image(path, shape):\n",
    "#         image_red_ch = Image.open(path+'_red.png')\n",
    "#         image_yellow_ch = Image.open(path+'_yellow.png')\n",
    "#         image_green_ch = Image.open(path+'_green.png')\n",
    "#         image_blue_ch = Image.open(path+'_blue.png')\n",
    "#         image = np.stack((\n",
    "#         np.array(image_red_ch), \n",
    "#         np.array(image_green_ch), \n",
    "#         np.array(image_blue_ch)), -1)\n",
    "#         image = cv2.resize(image, (shape[0], shape[1]))\n",
    "#         return image\n",
    "\n",
    "#     def augment(image):\n",
    "#         augment_img = iaa.Sequential([\n",
    "#             iaa.OneOf([\n",
    "#                 iaa.Affine(rotate=0),\n",
    "#                 iaa.Affine(rotate=90),\n",
    "#                 iaa.Affine(rotate=180),\n",
    "#                 iaa.Affine(rotate=270),\n",
    "#                 iaa.Fliplr(0.5),\n",
    "#                 iaa.Flipud(0.5),\n",
    "#             ])], random_order=True)\n",
    "\n",
    "#         image_aug = augment_img.augment_image(image)\n",
    "#         return image_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D, BatchNormalization, Input, Conv2D, MaxPooling2D\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam \n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_out):\n",
    "    input_tensor = Input(shape=(299,299,4))\n",
    "\n",
    "    base_model = InceptionV3(include_top=False,\n",
    "                   weights='imagenet',\n",
    "                   input_shape=(299,299,3)\n",
    "                            )\n",
    "    bn = BatchNormalization()(input_tensor)\n",
    "    x = Conv2D(3, kernel_size=(3,3), activation='relu', padding = \"same\")(bn)\n",
    "    x = base_model(x)\n",
    "    x = Conv2D(128, kernel_size=(3,3), activation='relu')(x)\n",
    "    x = Conv2D(256, kernel_size=(3,3), activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(2048, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(n_out, activation='sigmoid')(x)\n",
    "    model = Model(input_tensor, output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    #y_pred = K.round(y_pred)\n",
    "    y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), THRESHOLD), K.floatx())\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31072,) (31072, 28)\n",
      "(27964,) (27964, 28) (3108,) (3108, 28)\n"
     ]
    }
   ],
   "source": [
    "# create callbacks list\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "epochs = 10; batch_size = 64;VAL_RATIO = .1;DEBUG = False\n",
    "# split data into train, valid\n",
    "paths, labels = getTrainDataset()\n",
    "\n",
    "# divide to \n",
    "keys = np.arange(paths.shape[0], dtype=np.int)  \n",
    "np.random.seed(SEED)\n",
    "np.random.shuffle(keys)\n",
    "lastTrainIndex = int((1-VAL_RATIO) * paths.shape[0])\n",
    "\n",
    "if DEBUG == True:  # use only small subset for debugging, Kaggle's RAM is limited\n",
    "    pathsTrain = paths[0:256]\n",
    "    labelsTrain = labels[0:256]\n",
    "    pathsVal = paths[lastTrainIndex:lastTrainIndex+256]\n",
    "    labelsVal = labels[lastTrainIndex:lastTrainIndex+256]\n",
    "    use_cache = True\n",
    "else:\n",
    "    pathsTrain = paths[0:lastTrainIndex]\n",
    "    labelsTrain = labels[0:lastTrainIndex]\n",
    "    pathsVal = paths[lastTrainIndex:]\n",
    "    labelsVal = labels[lastTrainIndex:]\n",
    "    use_cache = False\n",
    "\n",
    "print(paths.shape, labels.shape)\n",
    "print(pathsTrain.shape, labelsTrain.shape, pathsVal.shape, labelsVal.shape)\n",
    "use_cache = True\n",
    "tg = ProteinDataGenerator(pathsTrain, labelsTrain, batch_size, SHAPE, use_cache=use_cache)\n",
    "vg = ProteinDataGenerator(pathsVal, labelsVal, batch_size, SHAPE, use_cache=use_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and valid datagens\n",
    "# train_generator = data_generator.create_train(\n",
    "#     train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=True)\n",
    "# validation_generator = data_generator.create_train(\n",
    "#     train_dataset_info[valid_indexes], 32, (SIZE,SIZE,3), augument=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('../working/InceptionV3.h5', monitor='val_f1', verbose=1, \n",
    "                             save_best_only=True, mode='max', save_weights_only = False)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_f1', factor=0.1, patience=3, \n",
    "                                   verbose=1, mode='max', epsilon=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_f1\", \n",
    "                      mode=\"max\", \n",
    "                      patience=6)\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 299, 299, 4)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_665 (Bat (None, 299, 299, 4)       16        \n",
      "_________________________________________________________________\n",
      "conv2d_676 (Conv2D)          (None, 299, 299, 3)       111       \n",
      "_________________________________________________________________\n",
      "inception_v3 (Model)         (None, 8, 8, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "conv2d_677 (Conv2D)          (None, 6, 6, 128)         2359424   \n",
      "_________________________________________________________________\n",
      "conv2d_678 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2048)              8390656   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 28)                57372     \n",
      "=================================================================\n",
      "Total params: 32,905,531\n",
      "Trainable params: 11,102,731\n",
      "Non-trainable params: 21,802,800\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           (None, 299, 299, 4)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 299, 299, 4)  0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 299, 299, 4)  0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_7 (Model)                 (None, 28)           32905531    lambda_7[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Concatenate)           (None, 28)           0           model_7[1][0]                    \n",
      "                                                                 model_7[2][0]                    \n",
      "==================================================================================================\n",
      "Total params: 32,905,531\n",
      "Trainable params: 11,102,731\n",
      "Non-trainable params: 21,802,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# warm up model\n",
    "import tensorflow as tf\n",
    "with tf.device('/cpu:0'):\n",
    "    model = create_model(\n",
    "        input_shape=(SIZE,SIZE,4), \n",
    "        n_out=28)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "model.layers[2].trainable = True\n",
    "model.layers[-1].trainable = True\n",
    "model.layers[-2].trainable = True\n",
    "model.layers[-3].trainable = True\n",
    "model.layers[-4].trainable = True\n",
    "model.layers[-5].trainable = True\n",
    "model.layers[-6].trainable = True\n",
    "model.layers[-7].trainable = True\n",
    "\n",
    "model.summary()\n",
    "model = multi_gpu_model(model, gpus = 2)\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer=Adam(1e-03),\n",
    "    metrics=['acc', f1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg = ProteinDataGenerator(pathsTrain, labelsTrain, batch_size, SHAPE, use_cache=use_cache)\n",
    "vg = ProteinDataGenerator(pathsVal, labelsVal, batch_size, SHAPE, use_cache=use_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "437/437 [==============================] - 1172s 3s/step - loss: 0.1795 - acc: 0.9398 - f1: 0.0944 - val_loss: 0.1786 - val_acc: 0.9411 - val_f1: 0.0933\n",
      "Epoch 2/5\n",
      "437/437 [==============================] - 291s 666ms/step - loss: 0.1670 - acc: 0.9446 - f1: 0.1079 - val_loss: 0.1786 - val_acc: 0.9421 - val_f1: 0.0961\n",
      "Epoch 3/5\n",
      "437/437 [==============================] - 277s 634ms/step - loss: 0.1635 - acc: 0.9458 - f1: 0.1142 - val_loss: 0.1897 - val_acc: 0.9414 - val_f1: 0.0916\n",
      "Epoch 4/5\n",
      "437/437 [==============================] - 272s 622ms/step - loss: 0.1614 - acc: 0.9466 - f1: 0.1171 - val_loss: 0.1773 - val_acc: 0.9434 - val_f1: 0.0994\n",
      "Epoch 5/5\n",
      "437/437 [==============================] - 278s 636ms/step - loss: 0.1595 - acc: 0.9469 - f1: 0.1195 - val_loss: 0.1787 - val_acc: 0.9431 - val_f1: 0.1009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2f4f6d257f0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    tg,\n",
    "    steps_per_epoch=np.ceil(float(len(pathsTrain)) / float(batch_size)),\n",
    "    validation_data=vg,\n",
    "    validation_steps=np.ceil(float(len(pathsVal)) / float(batch_size)),\n",
    "    epochs=5, \n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = model.layers[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x000002F573166358>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000002F57123BE48>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000002F5B4BFFA90>\n",
      "<keras.engine.training.Model object at 0x000002F57124F048>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000002F5B4E657B8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000002F5B40BFF98>\n",
      "<keras.layers.core.Flatten object at 0x000002F56360B588>\n",
      "<keras.layers.core.Dropout object at 0x000002F5D37DB438>\n",
      "<keras.layers.core.Dense object at 0x000002F5D37DBCF8>\n",
      "<keras.layers.core.Dropout object at 0x000002F5D3805AC8>\n",
      "<keras.layers.core.Dense object at 0x000002F5D3805E80>\n"
     ]
    }
   ],
   "source": [
    "# train all layers\n",
    "\n",
    "for layer in model1.layers:\n",
    "    print(layer)\n",
    "    layer.trainable = True\n",
    "model1 = multi_gpu_model(model1, gpus = 2)\n",
    "model1.compile(loss='binary_crossentropy',\n",
    "            optimizer=Adam(lr=1e-4),\n",
    "            metrics=['accuracy', f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "437/437 [==============================] - 463s 1s/step - loss: 0.1572 - acc: 0.9473 - f1: 0.1235 - val_loss: 0.1539 - val_acc: 0.9481 - val_f1: 0.1275\n",
      "\n",
      "Epoch 00001: val_f1 improved from -inf to 0.12750, saving model to ../working/InceptionV3.h5\n",
      "Epoch 2/10\n",
      "437/437 [==============================] - 344s 787ms/step - loss: 0.1501 - acc: 0.9494 - f1: 0.1346 - val_loss: 0.1496 - val_acc: 0.9491 - val_f1: 0.1348\n",
      "\n",
      "Epoch 00002: val_f1 improved from 0.12750 to 0.13483, saving model to ../working/InceptionV3.h5\n",
      "Epoch 3/10\n",
      "437/437 [==============================] - 313s 716ms/step - loss: 0.1435 - acc: 0.9515 - f1: 0.1493 - val_loss: 0.1469 - val_acc: 0.9497 - val_f1: 0.1542\n",
      "\n",
      "Epoch 00003: val_f1 improved from 0.13483 to 0.15421, saving model to ../working/InceptionV3.h5\n",
      "Epoch 4/10\n",
      "437/437 [==============================] - 357s 818ms/step - loss: 0.1355 - acc: 0.9542 - f1: 0.1696 - val_loss: 0.1519 - val_acc: 0.9490 - val_f1: 0.1650\n",
      "\n",
      "Epoch 00004: val_f1 improved from 0.15421 to 0.16503, saving model to ../working/InceptionV3.h5\n",
      "Epoch 5/10\n",
      "437/437 [==============================] - 637s 1s/step - loss: 0.1262 - acc: 0.9576 - f1: 0.1911 - val_loss: 0.1461 - val_acc: 0.9493 - val_f1: 0.1629\n",
      "\n",
      "Epoch 00005: val_f1 did not improve from 0.16503\n",
      "Epoch 6/10\n",
      "437/437 [==============================] - 354s 810ms/step - loss: 0.1163 - acc: 0.9612 - f1: 0.2124 - val_loss: 0.1446 - val_acc: 0.9515 - val_f1: 0.1863\n",
      "\n",
      "Epoch 00006: val_f1 improved from 0.16503 to 0.18626, saving model to ../working/InceptionV3.h5\n",
      "Epoch 7/10\n",
      "437/437 [==============================] - 334s 765ms/step - loss: 0.1059 - acc: 0.9648 - f1: 0.2361 - val_loss: 0.1534 - val_acc: 0.9492 - val_f1: 0.1733\n",
      "\n",
      "Epoch 00007: val_f1 did not improve from 0.18626\n",
      "Epoch 8/10\n",
      "437/437 [==============================] - 342s 782ms/step - loss: 0.0956 - acc: 0.9684 - f1: 0.2586 - val_loss: 0.1536 - val_acc: 0.9515 - val_f1: 0.1948\n",
      "\n",
      "Epoch 00008: val_f1 improved from 0.18626 to 0.19475, saving model to ../working/InceptionV3.h5\n",
      "Epoch 9/10\n",
      "437/437 [==============================] - 399s 913ms/step - loss: 0.0860 - acc: 0.9715 - f1: 0.2847 - val_loss: 0.1647 - val_acc: 0.9513 - val_f1: 0.2088\n",
      "\n",
      "Epoch 00009: val_f1 improved from 0.19475 to 0.20878, saving model to ../working/InceptionV3.h5\n",
      "Epoch 10/10\n",
      "437/437 [==============================] - 351s 803ms/step - loss: 0.0765 - acc: 0.9747 - f1: 0.3101 - val_loss: 0.1617 - val_acc: 0.9507 - val_f1: 0.1952\n",
      "\n",
      "Epoch 00010: val_f1 did not improve from 0.20878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2f622c1db00>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit_generator(\n",
    "    tg,\n",
    "    steps_per_epoch=np.ceil(float(len(pathsTrain)) / float(batch_size)),\n",
    "    validation_data=vg,\n",
    "    validation_steps=np.ceil(float(len(pathsVal)) / float(batch_size)),\n",
    "    epochs=epochs, \n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "# bestModel = load_model('../working/InceptionV3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fullValGen = ProteinDataGenerator(paths[lastTrainIndex:], labels[lastTrainIndex:], BATCH_SIZE, SHAPE)\n",
    "#fullValPred = np.zeros((paths[lastTrainIndex:].shape[0], 28))\n",
    "#for i in tqdm(range(len(fullValGen))):\n",
    "bestModel = model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 183/183 [09:35<00:00,  3.15s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "pathsTest, labelsTest = getTestDataset()\n",
    "\n",
    "testg = ProteinDataGenerator(pathsTest, labelsTest, batch_size, SHAPE)\n",
    "submit = pd.read_csv(DIR + '/sample_submission.csv')\n",
    "P = np.zeros((pathsTest.shape[0], 28))\n",
    "for i in tqdm(range(len(testg))):\n",
    "    images, labels = testg[i]\n",
    "    score = bestModel.predict(images)\n",
    "    P[i*batch_size:i*batch_size+score.shape[0]] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP = np.array(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 11702/11702 [00:00<00:00, 43522.72it/s]\n"
     ]
    }
   ],
   "source": [
    "prediction = []\n",
    "\n",
    "for row in tqdm(range(submit.shape[0])):\n",
    "    \n",
    "    str_label = ''\n",
    "    \n",
    "    for col in range(PP.shape[1]):\n",
    "        if(PP[row, col] < THRESHOLD):   # to account for losing TP is more costly than decreasing FP\n",
    "            #print(PP[row])\n",
    "            str_label += ''\n",
    "        else:\n",
    "            str_label += str(col) + ' '\n",
    "    prediction.append(str_label.strip())\n",
    "    \n",
    "submit['Predicted'] = np.array(prediction)\n",
    "submit.to_csv('datagenerator_model_v1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
